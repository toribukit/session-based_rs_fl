{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerEncoderLayer, Module\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_tr_data = np.load(f'./train_data_diginetica.npy', allow_pickle=True)\n",
    "# raw_val_data = np.load(f'./test_data_diginetica.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 21\n",
      "len validation: 21\n"
     ]
    }
   ],
   "source": [
    "raw_tr_data = []\n",
    "raw_val_data = []\n",
    "list_valid_users = []\n",
    "\n",
    "for i in range(45):\n",
    "  if os.path.isfile(f'./SR_SAN_Diginetica/train_{i}.txt'):\n",
    "    # print(i)\n",
    "    list_valid_users.append(i)\n",
    "    tr_data = pickle.load(open(f'./SR_SAN_Diginetica/train_{i}.txt', 'rb'))\n",
    "    ts_data = pickle.load(open(f'./SR_SAN_Diginetica/test_{i}.txt', 'rb'))\n",
    "\n",
    "    raw_tr_data.append(tr_data)\n",
    "    raw_val_data.append(ts_data)\n",
    "\n",
    "print(f\"len train: {len(raw_tr_data)}\")\n",
    "print(f\"len validation: {len(raw_val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 7, 8, 9, 16, 21, 23, 24, 25, 28, 31, 32, 35, 36, 37, 39, 41, 42, 43, 44]\n"
     ]
    }
   ],
   "source": [
    "print(list_valid_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'diginetica'\n",
    "attack_type = 'B' # A1: label_poison, A2: gaussian_attack, A3: scaling_attack, A4: reverse_attack\n",
    "local_learning_rate = 0.01\n",
    "local_steps= 1\n",
    "data_path= f\".\"\n",
    "learning_rate_decay_gamma= 0.99\n",
    "learning_rate_decay= False\n",
    "future_test= False\n",
    "mu= 1\n",
    "global_rounds= 50\n",
    "num_clients= len(raw_val_data)\n",
    "join_ratio= 1.0\n",
    "attack_ratio= 0.0\n",
    "algorithm= \"FedCHAR\"\n",
    "future_ratio= 0.0\n",
    "finetune_rounds= 0\n",
    "eval_gap= 1\n",
    "detailed_info= False\n",
    "partition= \"nature\"\n",
    "initial_rounds= 10\n",
    "n_clusters= 3\n",
    "metric= 'cosine'\n",
    "linkage= 'complete'\n",
    "output_size = 889\n",
    "n_node = 889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter for recommender system\n",
    "# input_size = 889\n",
    "# hidden_size = 400\n",
    "# num_layers = 3\n",
    "# output_size = input_size\n",
    "# batch_size = 10\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diginetica\n"
     ]
    }
   ],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "      self.dataset = 'diginetica'\n",
    "      self.batchSize = 32\n",
    "      self.hiddenSize = 200\n",
    "      self.nhead = 2\n",
    "      self.layer = 3\n",
    "      self.feedforward = 4\n",
    "      self.epoch = 12\n",
    "      self.lr = 0.001\n",
    "      self.lr_dc = 0.1\n",
    "      self.lr_dc_step = 3\n",
    "      self.l2 = 1e-5\n",
    "      self.patience = 12\n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# Now you can access parameters like this:\n",
    "print(opt.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_masks(all_usr_pois, item_tail):\n",
    "    if not all_usr_pois or all(len(upois) == 0 for upois in all_usr_pois):\n",
    "        raise ValueError(\"Input all_usr_pois is empty or contains only empty lists\")\n",
    "\n",
    "    us_lens = [len(upois) for upois in all_usr_pois]\n",
    "    len_max = max(us_lens)\n",
    "    us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
    "    us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
    "    return us_pois, us_msks, len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, data, shuffle=False, graph=None):\n",
    "      inputs = data[0]\n",
    "      inputs, mask, len_max = data_masks(inputs, [0])\n",
    "      self.inputs = np.asarray(inputs)\n",
    "      self.mask = np.asarray(mask)\n",
    "      self.len_max = len_max\n",
    "      self.targets = np.asarray(data[1])\n",
    "      self.length = len(inputs)\n",
    "      self.shuffle = shuffle\n",
    "      self.graph = graph\n",
    "\n",
    "    def generate_batch(self, batch_size):\n",
    "      if self.shuffle:\n",
    "        shuffled_arg = np.arange(self.length)\n",
    "        np.random.shuffle(shuffled_arg)\n",
    "        self.inputs = self.inputs[shuffled_arg]\n",
    "        self.mask = self.mask[shuffled_arg]\n",
    "        self.targets = self.targets[shuffled_arg]\n",
    "      n_batch = int(self.length / batch_size)\n",
    "      if self.length % batch_size != 0:\n",
    "        n_batch += 1\n",
    "      slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
    "      slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))]\n",
    "      return slices\n",
    "\n",
    "    def get_slice(self, i):\n",
    "      inputs, mask, targets = self.inputs[i], self.mask[i], self.targets[i]\n",
    "      items, n_node, A, alias_inputs = [], [], [], []\n",
    "      for u_input in inputs:\n",
    "        n_node.append(len(np.unique(u_input)))\n",
    "      max_n_node = np.max(n_node)\n",
    "      for u_input in inputs:\n",
    "        node = np.unique(u_input)\n",
    "        items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
    "        u_A = np.zeros((max_n_node, max_n_node))\n",
    "        for i in np.arange(len(u_input) - 1):\n",
    "          if u_input[i + 1] == 0:\n",
    "            break\n",
    "          u = np.where(node == u_input[i])[0][0]\n",
    "          v = np.where(node == u_input[i + 1])[0][0]\n",
    "          u_A[u][v] = 1\n",
    "        u_sum_in = np.sum(u_A, 0)\n",
    "        u_sum_in[np.where(u_sum_in == 0)] = 1\n",
    "        u_A_in = np.divide(u_A, u_sum_in)\n",
    "        u_sum_out = np.sum(u_A, 1)\n",
    "        u_sum_out[np.where(u_sum_out == 0)] = 1\n",
    "        u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
    "        u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
    "        A.append(u_A)\n",
    "        alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
    "      return alias_inputs, A, items, mask, targets\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.length  # or return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedGradientDescent(Optimizer):\n",
    "  def __init__(self, params, lr=0.01, mu=0.0):\n",
    "    default = dict(lr=lr, mu=mu)\n",
    "    super().__init__(params, default)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def step(self, global_params, device):\n",
    "    for group in self.param_groups:\n",
    "      for p, g in zip(group['params'], global_params):\n",
    "        g = g.to(device)\n",
    "        # print(p.grad)\n",
    "        d_p = p.grad.data + group['mu'] * (p.data - g.data)\n",
    "        p.data.add_(d_p, alpha=-group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionNetwork(Module):\n",
    "  def __init__(self, opt, n_node):\n",
    "    super(SelfAttentionNetwork, self).__init__()\n",
    "    self.hidden_size = opt.hiddenSize\n",
    "    self.n_node = n_node\n",
    "    self.batch_size = opt.batchSize\n",
    "    self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
    "    self.transformerEncoderLayer = TransformerEncoderLayer(d_model=self.hidden_size, nhead=opt.nhead,dim_feedforward=self.hidden_size * opt.feedforward)\n",
    "    self.transformerEncoder = TransformerEncoder(self.transformerEncoderLayer, opt.layer)\n",
    "    self.loss_function = nn.CrossEntropyLoss()\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr, weight_decay=opt.l2)\n",
    "    self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt.lr_dc_step, gamma=opt.lr_dc)\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "  def compute_scores(self, hidden, mask):\n",
    "    ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
    "    b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
    "    scores = torch.matmul(ht, b.transpose(1, 0))\n",
    "    return scores\n",
    "\n",
    "  def forward(self, inputs, A):\n",
    "    hidden = self.embedding(inputs)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    hidden = self.transformerEncoder(hidden)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cuda(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cuda()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cpu(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cpu()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, i, data):\n",
    "  alias_inputs, A, items, mask, targets = data.get_slice(i)\n",
    "  alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
    "  items = trans_to_cuda(torch.Tensor(items).long())\n",
    "  A = trans_to_cuda(torch.Tensor(A).float())\n",
    "  mask = trans_to_cuda(torch.Tensor(mask).long())\n",
    "  hidden = model(items, A)\n",
    "  get = lambda i: hidden[i][alias_inputs[i]]\n",
    "  seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
    "  return targets, model.compute_scores(seq_hidden, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(scores, targets, k=K):\n",
    "    recall_at_k = []\n",
    "    top_k_scores = scores.topk(k)[1]\n",
    "    for score, target in zip(top_k_scores, targets):\n",
    "        recall_at_k.append((target - 1) in score)\n",
    "    return np.mean(recall_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "  \"\"\"\n",
    "  Base class for clients in federated learning.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, model, id, malicious, **kwargs):\n",
    "    self.model = copy.deepcopy(model)\n",
    "    self.dataset = dataset\n",
    "    self.device = DEVICE\n",
    "    self.id = id\n",
    "    self.malicious = malicious\n",
    "    self.attack_type = attack_type\n",
    "    self.num_classes = output_size\n",
    "    self.batch_size = opt.batchSize\n",
    "    self.learning_rate = local_learning_rate\n",
    "    self.local_steps = local_steps\n",
    "    self.data_path = data_path\n",
    "    self.learning_rate_decay = learning_rate_decay\n",
    "    self.future_test = future_test\n",
    "\n",
    "\n",
    "    # check BatchNorm\n",
    "    self.has_BatchNorm = False\n",
    "    for layer in self.model.children():\n",
    "      if isinstance(layer, nn.BatchNorm2d):\n",
    "        self.has_BatchNorm = True\n",
    "        break\n",
    "\n",
    "    self.loss = nn.CrossEntropyLoss()  # Replace with your loss function\n",
    "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate) # momentum=0.9, weight_decay=1e-4\n",
    "    self.learning_rate_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "      optimizer=self.optimizer,\n",
    "      gamma=learning_rate_decay_gamma\n",
    "    )\n",
    "\n",
    "  def load_train_data(self, batch_size=None):\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    train_data = Data(raw_tr_data[self.id], shuffle=True)\n",
    "\n",
    "    # label poison attack\n",
    "    if self.malicious and self.attack_type == 'A1':\n",
    "      for idx in range(len(train_data)):\n",
    "        train_data[idx][1] = self.num_classes - train_data[idx][1] - 1\n",
    "    self.train_samples = len(train_data)\n",
    "    return train_data\n",
    "\n",
    "  def load_test_data(self, batch_size=None):\n",
    "    \"\"\"\n",
    "    fine-tunes the model using the loaded training data\n",
    "    \"\"\"\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    test_data = Data(raw_val_data[self.id], shuffle=False)\n",
    "    return test_data\n",
    "  \n",
    "  def set_parameters(self, model):\n",
    "    for new_param, old_param in zip(model.parameters(), self.model.parameters()):\n",
    "      old_param.data = new_param.data.clone()\n",
    "\n",
    "  def fine_tuning(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.train()\n",
    "    slices = trainloader.generate_batch(self.model.batch_size)\n",
    "    num_batches = len(slices)\n",
    "\n",
    "    for i, j in zip(slices, np.arange(num_batches)):\n",
    "      # if type(x) == type([]):\n",
    "      #   x[0] = x[0].to(self.device)\n",
    "      # else:\n",
    "      #   x = x.to(self.device)\n",
    "      self.optimizer.zero_grad()\n",
    "      targets, scores = forward(self.model, i, trainloader)\n",
    "      targets = trans_to_cuda(torch.Tensor(targets).long())\n",
    "      # output = self.model(x)\n",
    "      loss = self.loss(scores, targets - 1)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "  def new_test_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's performance on test data, particularly its accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    testloaderfull = self.load_test_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    slices = testloaderfull.generate_batch(self.model.batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model, i, testloaderfull)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "\n",
    "        sub_scores = scores.topk(K)[1] #top-k items\n",
    "        sub_scores = sub_scores.cpu().detach().numpy()  # Move to CPU if necessary\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        targets_np = targets.cpu().numpy()\n",
    "        for score, target_np, mask in zip(sub_scores, targets_np, testloaderfull.mask):\n",
    "          mrr_index = np.where(score == target_np - 1)[0]\n",
    "          # total_mrr.append(0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1))\n",
    "          total_mrr += 0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1)\n",
    "\n",
    "        recall = calculate_recall_at_k(scores, targets, k=5)\n",
    "        # total_recall.append(recall)\n",
    "        total_recall += recall          \n",
    "        \n",
    "    test_num = len(slices)\n",
    "    # total_recall = np.mean(total_recall)\n",
    "    # total_mrr = np.mean(total_mrr)\n",
    "\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def new_train_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's loss on the training data.\n",
    "    \"\"\"\n",
    "\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0.0\n",
    "    slices = trainloader.generate_batch(self.model.batch_size)\n",
    "    train_num = len(slices)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model, i, trainloader)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "        # output = self.model(x)\n",
    "        # calculate losses\n",
    "        loss = self.loss(scores, targets - 1)\n",
    "        losses += loss.item()\n",
    "        # loss = self.loss(output, y)\n",
    "        # train_num += y.shape[0]\n",
    "        # losses += loss.item() * y.shape[0]\n",
    "\n",
    "    return losses, train_num\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    testloaderfull = self.load_test_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    # y_prob = []\n",
    "    # y_true = []\n",
    "    slices = testloaderfull.generate_batch(self.model.batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model, i, testloaderfull)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "        #output = self.model(x)\n",
    "        sub_scores = scores.topk(K)[1] #top-k items\n",
    "        sub_scores = sub_scores.cpu().detach().numpy()\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        targets_np = targets.cpu().numpy()\n",
    "        # Calculate recall and MRR for each batch\n",
    "        for score, target_np, mask in zip(sub_scores, targets_np, testloaderfull.mask):\n",
    "          mrr_index = np.where(score == target_np - 1)[0]\n",
    "          # total_mrr.append(0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1))\n",
    "          total_mrr += 0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1)\n",
    "\n",
    "        recall = calculate_recall_at_k(scores, targets, k=5)\n",
    "        # total_recall.append(recall)\n",
    "        total_recall += recall\n",
    "\n",
    "        # y_prob.append(output.detach().cpu().numpy())\n",
    "        # nc = self.num_classes\n",
    "        # if self.num_classes == 2:\n",
    "        #   nc += 1\n",
    "        # lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))\n",
    "        # if self.num_classes == 2:\n",
    "        #   lb = lb[:, :2]\n",
    "        # y_true.append(lb)\n",
    "\n",
    "    # y_prob = np.concatenate(y_prob, axis=0)\n",
    "    # y_true = np.concatenate(y_true, axis=0)\n",
    "    test_num = len(slices)\n",
    "    # total_recall = np.mean(total_recall)\n",
    "    # total_mrr = np.mean(total_mrr)\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    trainloader = self.load_train_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0.0\n",
    "    slices = trainloader.generate_batch(self.model.batch_size)\n",
    "    train_num = len(slices)\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model, i, trainloader)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "\n",
    "        # output = self.model(x)\n",
    "        loss = self.loss(scores, targets - 1)\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses, train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clientCHAR(Client):\n",
    "  def __init__(self, model, id, malicious, **kwargs):\n",
    "    super().__init__(model, id, malicious, **kwargs)\n",
    "    self.mu = mu\n",
    "    self.model_per = copy.deepcopy(self.model)\n",
    "    self.optimizer_per = PerturbedGradientDescent(self.model_per.parameters(), lr=self.learning_rate, mu=self.mu)\n",
    "    self.learning_rate_scheduler_per = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer=self.optimizer_per,\n",
    "        gamma=learning_rate_decay_gamma\n",
    "        )\n",
    "\n",
    "  def dtrain(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    model = copy.deepcopy(self.model)\n",
    "    self.model.train()\n",
    "    self.model_per.train()\n",
    "\n",
    "    max_local_steps = self.local_steps\n",
    "    slices = trainloader.generate_batch(model.batch_size)\n",
    "    num_batches = len(slices)\n",
    "\n",
    "    for step in range(max_local_steps):\n",
    "      for i, j in zip(slices, np.arange(num_batches)):\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        print(j)\n",
    "        targets_p, scores_p = forward(self.model_per, i, trainloader)\n",
    "        targets_p = trans_to_cuda(torch.Tensor(targets_p).long())\n",
    "        # out_p = self.model_per(x)\n",
    "        loss = self.model_per.loss_function(scores_p, targets_p - 1)\n",
    "        self.optimizer_per.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f\"loss: {loss}\")\n",
    "        for name, param in self.model_per.named_parameters():\n",
    "          if param.grad is None:\n",
    "            print(f\"Parameter name: {name}\")\n",
    "            print(f\"Parameter shape: {param.shape}\")\n",
    "            print(f\"Gradient: {param.grad}\")\n",
    "            print(\"=\" * 20)\n",
    "        \n",
    "\n",
    "        self.optimizer_per.step(model.parameters(), self.device)\n",
    "\n",
    "        targets_g, scores_g = forward(self.model, i, trainloader)\n",
    "        targets_g = torch.Tensor(targets_g).long().to(DEVICE)\n",
    "        # out_g = self.model(x)\n",
    "        loss = self.loss(scores_g, targets_g - 1)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    if self.learning_rate_decay:\n",
    "      self.learning_rate_scheduler.step()\n",
    "      self.learning_rate_scheduler_per.step()\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    testloaderfull = self.load_test_data()\n",
    "    self.model_per.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    # y_prob = []\n",
    "    # y_true = []\n",
    "    slices = testloaderfull.generate_batch(self.model_per.batch_size)\n",
    "    test_num = len(slices)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model_per, i, testloaderfull)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "        # output = self.model_per(x)\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        # Select top-k items\n",
    "        sub_scores = scores.topk(K)[1] #top-k items\n",
    "        sub_scores = sub_scores.cpu().detach().numpy()  # Move to CPU if necessary\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        targets_np = targets.cpu().numpy()\n",
    "        for score, target_np, mask in zip(sub_scores, targets_np, testloaderfull.mask):\n",
    "          mrr_index = np.where(score == target_np - 1)[0]\n",
    "          # total_mrr.append(0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1))\n",
    "          total_mrr += 0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1)\n",
    "\n",
    "        recall = calculate_recall_at_k(scores, targets, k=K)\n",
    "        # total_recall.append(recall)\n",
    "        total_recall += recall\n",
    "\n",
    "    #     y_prob.append(F.softmax(output).detach().cpu().numpy())\n",
    "    #     y_true.append(label_binarize(y.detach().cpu().numpy(), classes=np.arange(self.num_classes)))\n",
    "\n",
    "    # y_prob = np.concatenate(y_prob, axis=0)\n",
    "    # y_true = np.concatenate(y_true, axis=0)\n",
    "    # total_recall = np.mean(total_recall)\n",
    "    # total_mrr = np.mean(total_mrr)\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  # need to investigate the loss calculation\n",
    "  def train_metrics_personalized(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model_per.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0\n",
    "    slices = trainloader.generate_batch(self.model_per.batch_size)\n",
    "    train_num = len(slices)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model_per, i, trainloader)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "        # output = self.model_per(x)\n",
    "        loss = self.loss(scores, targets - 1)\n",
    "\n",
    "        #add a regularization term to the loss\n",
    "        # ensure that the personalized model doesn't deviate too far from the global model.\n",
    "        # The strength of this regularization is controlled by the parameter self.mu\n",
    "        gm = torch.cat([p.data.view(-1) for p in self.model.parameters()], dim=0)\n",
    "        pm = torch.cat([p.data.view(-1) for p in self.model_per.parameters()], dim=0)\n",
    "        loss += 0.5 * self.mu * torch.norm(pm-gm, p=2) #element-wise difference using L2 norm\n",
    "\n",
    "        # losses += loss.item() * y.shape[0]\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses, train_num\n",
    "\n",
    "  def get_update(self, global_model):\n",
    "    trainloader = self.load_train_data()\n",
    "    model = copy.deepcopy(self.model) #old model\n",
    "    self.set_parameters(global_model)\n",
    "    self.model.train()\n",
    "\n",
    "    max_local_steps = self.local_steps\n",
    "    slices = trainloader.generate_batch(self.model.batch_size)\n",
    "\n",
    "    for step in range(max_local_steps):\n",
    "      for i in slices:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        targets, scores = forward(self.model, i, trainloader)\n",
    "        targets = torch.Tensor(targets).long().to(DEVICE)\n",
    "        # output = self.model(x)\n",
    "        loss = self.loss(scores, targets - 1)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    model_update = [c_param.data - s_param.data for c_param, s_param in zip(self.model.parameters(), global_model.parameters())]\n",
    "    self.set_parameters(model)\n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(object):\n",
    "  def __init__(self, model):\n",
    "    # Set up the main attributes\n",
    "    self.device = DEVICE\n",
    "    self.dataset = dataset\n",
    "    self.num_classes = output_size\n",
    "    self.global_rounds = global_rounds\n",
    "    self.local_steps = local_steps\n",
    "    self.batch_size = opt.batchSize\n",
    "    self.learning_rate = local_learning_rate\n",
    "    self.global_model = copy.deepcopy(model)\n",
    "    self.num_clients = num_clients\n",
    "    self.join_ratio = join_ratio\n",
    "    self.attack_ratio = attack_ratio\n",
    "    self.attack_type = attack_type\n",
    "    self.seed = seed\n",
    "    self.algorithm = algorithm\n",
    "    self.current_round = -1\n",
    "    self.future_test = future_test\n",
    "    self.future_ratio = future_ratio\n",
    "    self.num_training_clients = num_clients - int(num_clients * future_ratio)\n",
    "    self.join_clients = int(self.num_training_clients * self.join_ratio)\n",
    "    self.finetune_rounds = finetune_rounds\n",
    "    self.eval_gap = eval_gap\n",
    "    self.detailed_info = detailed_info\n",
    "    self.partition = partition\n",
    "    self.data_path = data_path\n",
    "\n",
    "    self.clients = []\n",
    "    self.training_clients = []\n",
    "    self.malicious_ids = []\n",
    "    self.selected_clients = []\n",
    "\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_models = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    self.rs_test_recall_g = []\n",
    "    self.rs_test_mrr_g = []\n",
    "    self.rs_train_loss_g = []\n",
    "    self.rs_test_recalls_g = []\n",
    "    self.rs_test_mrrs_g = []\n",
    "    self.rs_test_recall_p = []\n",
    "    self.rs_test_mrr_p = []\n",
    "    self.rs_train_loss_p = []\n",
    "    self.rs_test_recalls_p = []\n",
    "    self.rs_test_mrrs_p = []\n",
    "    self.ft_train_loss = []\n",
    "    self.ft_test_recall = []\n",
    "    self.ft_std_recall = []\n",
    "    self.ft_test_mrr = []\n",
    "    self.ft_std_mrr = []\n",
    "\n",
    "  def set_clients(self, model, clientObj):\n",
    "\n",
    "    if self.future_test == False:\n",
    "      if self.attack_type == 'B':\n",
    "        self.malicious_ids = []\n",
    "        self.attack_ratio = 0.0\n",
    "      else:\n",
    "        self.malicious_ids = np.sort(np.random.choice(np.arange(self.num_clients), int(self.num_clients * self.attack_ratio), replace=False))\n",
    "\n",
    "\n",
    "      for i in range(self.num_clients):\n",
    "        client = clientObj(model=model, id=i,\n",
    "                        malicious=True if i in self.malicious_ids else False)\n",
    "        self.clients.append(client)\n",
    "\n",
    "      self.training_clients = self.clients\n",
    "      self.training_clients_ids = np.arange(self.num_clients)\n",
    "\n",
    "    else:\n",
    "      if self.algorithm != 'FedCHAR_DC':\n",
    "        print('{} do not support future testing'.format(self.algorithm))\n",
    "        raise NotImplementedError\n",
    "\n",
    "      self.training_clients_ids = np.sort(np.random.choice(np.arange(self.num_clients), self.num_training_clients, replace=False))\n",
    "\n",
    "      if self.attack_type == 'B':\n",
    "        self.malicious_ids = []\n",
    "        self.attack_ratio = 0.0\n",
    "      else:\n",
    "        self.malicious_ids = np.sort(np.random.choice(self.training_clients_ids, int(self.num_training_clients * self.attack_ratio),\n",
    "                                                      replace=False))\n",
    "\n",
    "      for i in range(self.num_clients):\n",
    "        client = clientObj(model=model, id=i,\n",
    "                        malicious=True if i in self.malicious_ids else False)\n",
    "        self.clients.append(client)\n",
    "\n",
    "        if i in self.training_clients_ids:\n",
    "          self.training_clients.append(client)\n",
    "\n",
    "    print('Malicious Clients: {}'.format(list(self.malicious_ids)))\n",
    "    print('Future Clients: {}'.format(list(np.sort(np.setdiff1d(np.arange(self.num_clients), self.training_clients_ids)))))\n",
    "\n",
    "  def select_clients(self):\n",
    "    selected_clients = list(np.random.choice(self.training_clients, self.join_clients, replace=False))\n",
    "    return selected_clients\n",
    "\n",
    "  def send_models(self):\n",
    "    for client in self.selected_clients:\n",
    "      client.set_parameters(self.global_model)\n",
    "\n",
    "  def send_models_to_future_clients(self):\n",
    "    for client in self.selected_clients:\n",
    "      client.set_parameters(self.global_model)\n",
    "\n",
    "  def receive_models(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = [] #weight based on the fraction of client's data\n",
    "    self.uploaded_models = []\n",
    "\n",
    "    tot_samples = 0\n",
    "    for client in self.selected_clients:\n",
    "      tot_samples += client.train_samples\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      self.uploaded_models.append(client.model)\n",
    "\n",
    "    for i, w in enumerate(self.uploaded_weights):\n",
    "      self.uploaded_weights[i] = w / tot_samples\n",
    "\n",
    "  def load_model(self):\n",
    "    model_path = os.path.join(f\"./models\", self.dataset)\n",
    "    model_path = os.path.join(model_path, self.algorithm + \"_server\" + \".pt\")\n",
    "    assert (os.path.exists(model_path))\n",
    "    self.global_model = torch.load(model_path)\n",
    "\n",
    "  def model_exists(self):\n",
    "    model_path = os.path.join(f\"./models\", self.dataset)\n",
    "    model_path = os.path.join(model_path, self.algorithm + \"_server\" + \".pt\")\n",
    "    return os.path.exists(model_path)\n",
    "\n",
    "  def save_results(self):\n",
    "    filename = \"{}_{}_{}_{}_{}_bz{}_lr{}_gr{}_ep{}_jr{}_nc{}_fur{}_ntc{}_ftr{}_seed{}\".format(self.dataset, self.partition, self.algorithm,\n",
    "                                                                                        self.attack_type, self.attack_ratio, self.batch_size,\n",
    "                                                                                        self.learning_rate, self.global_rounds, self.local_steps,\n",
    "                                                                                        self.join_ratio, self.num_clients, self.future_ratio,\n",
    "                                                                                        self.num_training_clients, self.finetune_rounds,\n",
    "                                                                                        self.seed)\n",
    "\n",
    "    if self.algorithm == 'FedCHAR':\n",
    "      filename = filename + '_ir{}_ng{}_mtrc{}_lkg{}'.format(self.initial_rounds, self.n_clusters, self.metric, self.linkage)\n",
    "\n",
    "    elif self.algorithm == 'FedCHAR_DC':\n",
    "      filename = filename + '_ir{}_ng{}_mtrc{}_lkg{}_rr{}'.format(self.initial_rounds, self.n_clusters, self.metric, self.linkage,\n",
    "                                                                  self.recluster_rounds)\n",
    "\n",
    "    result_path = f\"./results/npz/\"\n",
    "    if not os.path.exists(result_path):\n",
    "      os.makedirs(result_path)\n",
    "\n",
    "    if len(self.rs_test_acc_g) or len(self.rs_test_acc_p):\n",
    "      file_path = result_path + \"{}.npz\".format(filename)\n",
    "      print(\"Result path: \" + file_path)\n",
    "\n",
    "      np.savez(file_path, test_acc_g=self.rs_test_acc_g,\n",
    "              test_acc_p=self.rs_test_acc_p, test_accs_g=self.rs_test_accs_g,\n",
    "              test_accs_p=self.rs_test_accs_p, train_loss_g=self.rs_train_loss_g,\n",
    "              train_loss_p=self.rs_train_loss_p, ft_train_loss=self.ft_train_loss,\n",
    "              ft_test_acc=self.ft_test_acc, ft_std_acc=self.ft_std_acc)\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def test_metrics_for_future_clients(self):\n",
    "    num_samples = []\n",
    "    tot_correct = []\n",
    "\n",
    "    for c in self.selected_clients:\n",
    "      ct, ns = c.new_test_metrics()\n",
    "      tot_correct.append(ct*1.0)\n",
    "      num_samples.append(ns)\n",
    "\n",
    "    ids = [c.id for c in self.selected_clients]\n",
    "    return ids, num_samples, tot_correct\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def train_metrics_for_future_clients(self):\n",
    "    num_samples = []\n",
    "    losses = []\n",
    "    for c in self.selected_clients:\n",
    "      cl, ns = c.new_train_metrics()\n",
    "      num_samples.append(ns)\n",
    "      losses.append(cl*1.0)\n",
    "\n",
    "    ids = [c.id for c in self.selected_clients]\n",
    "    return ids, num_samples, losses\n",
    "\n",
    "  def evaluate_personalized(self, rec=None, loss=None, mrr=None):\n",
    "    stats = self.test_metrics_personalized()\n",
    "    stats_train = self.train_metrics_personalized()\n",
    "\n",
    "    if self.malicious_ids != []: # skip this for now\n",
    "      relative_malicious_ids = np.array([stats[0].index(i) for i in self.malicious_ids])\n",
    "\n",
    "      stats_A = np.array(stats)[:, relative_malicious_ids].tolist()\n",
    "      stats_train_A = np.array(stats_train)[:, relative_malicious_ids].tolist()\n",
    "\n",
    "      test_acc_A = sum(stats_A[2])*1.0 / sum(stats_A[1])\n",
    "      train_loss_A = sum(stats_train_A[2])*1.0 / sum(stats_train_A[1])\n",
    "      accs_A = [a / n for a, n in zip(stats_A[2], stats_A[1])]\n",
    "      losses_A = [a / n for a, n in zip(stats_train_A[2], stats_train_A[1])]\n",
    "\n",
    "    else:\n",
    "      test_acc_A = -1\n",
    "      train_loss_A = -1\n",
    "      accs_A = []\n",
    "      losses_A = []\n",
    "\n",
    "    benign_ids = np.sort(np.setdiff1d(self.training_clients_ids, self.malicious_ids))\n",
    "    relative_benign_ids = np.array([stats[0].index(i) for i in benign_ids])\n",
    "\n",
    "    stats_B = np.array(stats)[:, relative_benign_ids].tolist()\n",
    "    stats_train_B = np.array(stats_train)[:, relative_benign_ids].tolist()\n",
    "\n",
    "    stats = None\n",
    "    stats_train = None\n",
    "\n",
    "    # test_acc = sum(stats_B[2])*1.0 / sum(stats_B[1])\n",
    "    # train_loss = sum(stats_train_B[2])*1.0 / sum(stats_train_B[1])\n",
    "    # accs = [a / n for a, n in zip(stats_B[2], stats_B[1])]\n",
    "    # losses = [a / n for a, n in zip(stats_train_B[2], stats_train_B[1])]\n",
    "\n",
    "    test_recall = sum(stats_B[2])*1.0 / sum(stats_B[1])\n",
    "    test_mrr = sum(stats_B[3])*1.0 / sum(stats_B[1])\n",
    "    train_loss = sum(stats_train_B[2])*1.0 / sum(stats_train_B[1])\n",
    "    recalls = [a / n for a, n in zip(stats_B[2], stats_B[1])]\n",
    "    mrrs = [a / n for a, n in zip(stats_B[3], stats_B[1])]\n",
    "    losses = [a / n for a, n in zip(stats_train_B[2], stats_train_B[1])]\n",
    "\n",
    "    if rec == None:\n",
    "      self.rs_test_recall_p.append(test_recall)\n",
    "    else:\n",
    "      rec.append(test_recall)\n",
    "\n",
    "    if mrr == None:\n",
    "      self.rs_test_mrr_p.append(test_mrr)\n",
    "    else:\n",
    "      mrr.append(test_mrr)\n",
    "\n",
    "    if loss == None:\n",
    "      self.rs_train_loss_p.append(train_loss)\n",
    "    else:\n",
    "      loss.append(train_loss)\n",
    "\n",
    "    self.rs_test_recall_p.append(recalls)\n",
    "    self.rs_test_mrr_p.append(mrrs)\n",
    "\n",
    "    print(\"Benign Averaged Train Loss: {:.2f}\".format(train_loss))\n",
    "    # print(\"Benign Averaged Test Accurancy: {:.2f}%\".format(test_acc*100))\n",
    "    # print(\"Benign Std Test Accurancy: {:.2f}%\".format(np.std(accs)*100))\n",
    "    print(\"Benign Averaged Test Recall: {:.2f}%\".format(test_recall*100))\n",
    "    print(\"Benign Std Test Recall: {:.2f}%\".format(np.std(recalls)*100))\n",
    "    print(\"Benign Averaged Test MRR: {:.2f}%\".format(test_mrr*100))\n",
    "    print(\"Benign Std Test MRR: {:.2f}%\".format(np.std(mrrs)*100))\n",
    "\n",
    "    if self.malicious_ids != []:\n",
    "      print(\"Malicious Averaged Train Loss: {:.2f}\".format(train_loss_A))\n",
    "      print(\"Malicious Averaged Test Accurancy: {:.2f}%\".format(test_acc_A*100))\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def evaluate_for_future_clients(self):\n",
    "    stats = self.test_metrics_for_future_clients()\n",
    "    stats_train = self.train_metrics_for_future_clients()\n",
    "    stats = np.array(stats).tolist()\n",
    "    stats_train = np.array(stats_train).tolist()\n",
    "    test_acc = sum(stats[2])*1.0 / sum(stats[1])\n",
    "    train_loss = sum(stats_train[2])*1.0 / sum(stats_train[1])\n",
    "    accs = [a / n for a, n in zip(stats[2], stats[1])]\n",
    "    losses = [a / n for a, n in zip(stats_train[2], stats_train[1])]\n",
    "\n",
    "    print(\"Averaged Future Train Loss: {:.2f}\".format(train_loss))\n",
    "    print(\"Averaged Future Test Accurancy: {:.2f}%\".format(test_acc*100))\n",
    "    print(\"Std Future Test Accurancy: {:.2f}%\".format(np.std(accs)*100))\n",
    "\n",
    "    if self.detailed_info:\n",
    "      print('Future Clients Train Loss:\\n', [(int(stats[0][idx]), format(loss, '.2f')) for idx, loss in enumerate(losses)])\n",
    "      print('Future Clients Test Accuracy:\\n', [(int(stats[0][idx]), format(acc*100, '.2f')+'%') for idx, acc in enumerate(accs)])\n",
    "\n",
    "    self.ft_train_loss.append(train_loss)\n",
    "    self.ft_test_acc.append(test_acc)\n",
    "    self.ft_std_acc.append(np.std(accs))\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    num_samples = []\n",
    "    tot_recall = []\n",
    "    tot_mrr = []\n",
    "\n",
    "    for c in self.training_clients:\n",
    "      rc, mrr, ns = c.test_metrics_personalized()\n",
    "      tot_recall.append(rc)\n",
    "      tot_mrr.append(mrr)\n",
    "      num_samples.append(ns)\n",
    "\n",
    "    ids = [c.id for c in self.training_clients]\n",
    "    return ids, num_samples, tot_recall, tot_mrr\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    num_samples = []\n",
    "    losses = []\n",
    "    for c in self.training_clients:\n",
    "      cl, ns = c.train_metrics_personalized()\n",
    "      num_samples.append(ns)\n",
    "      losses.append(cl*1.0)\n",
    "\n",
    "    ids = [c.id for c in self.training_clients]\n",
    "    return ids, num_samples, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedCHAR(Server):\n",
    "  def __init__(self, model):\n",
    "    super().__init__(model)\n",
    "\n",
    "    self.set_clients(model, clientCHAR)\n",
    "\n",
    "    print(f\"\\nJoin ratio / total clients: {self.join_ratio} / {self.num_training_clients}\")\n",
    "    print(\"Finished creating server and clients.\")\n",
    "\n",
    "    self.initial_rounds = initial_rounds\n",
    "    self.n_clusters = n_clusters\n",
    "    self.metric = metric\n",
    "    self.linkage = linkage\n",
    "\n",
    "  def train(self):\n",
    "    # initial Stage\n",
    "    for i in range(self.initial_rounds):\n",
    "      self.selected_clients = self.select_clients()\n",
    "      self.send_models()\n",
    "\n",
    "      for client in self.selected_clients:\n",
    "        client.dtrain()\n",
    "\n",
    "      if i%self.eval_gap == 0:\n",
    "        print(f\"\\n-------------Round number: {i}-------------\")\n",
    "        print(\"\\nEvaluate personalized models for training clients.\")\n",
    "        self.evaluate_personalized()\n",
    "\n",
    "      self.receive_models()\n",
    "      self.aggregate_parameters()\n",
    "\n",
    "    # Clustering Stage\n",
    "    print(f\"\\n-------------Clustering-------------\")\n",
    "    clients_updates = self.collect()\n",
    "    self.cluster_identity = self.cluster(clients_updates)\n",
    "    cluster_info = [[('Malicious' if self.training_clients[idx].malicious else 'Benign', idx) for idx, g_id in enumerate(self.cluster_identity) if g_id == i] for i in range(max(self.cluster_identity)+1)]\n",
    "    for idx, info in enumerate(cluster_info):\n",
    "      print('Cluster {}: {}'.format(idx, info))\n",
    "\n",
    "    self.group_models = [copy.deepcopy(self.global_model)] * (max(self.cluster_identity) + 1)\n",
    "\n",
    "    # Remaining Stage\n",
    "    for i in range(self.global_rounds - self.initial_rounds):\n",
    "      self.selected_clients = self.select_clients()\n",
    "      self.send_models_g()\n",
    "\n",
    "      for client in self.selected_clients:\n",
    "        client.dtrain()\n",
    "\n",
    "      if i%self.eval_gap == 0:\n",
    "        print(f\"\\n-------------Round number: {i+self.initial_rounds}-------------\")\n",
    "        print(\"\\nEvaluate personalized models for training clients.\")\n",
    "        self.evaluate_personalized()\n",
    "\n",
    "      self.receive_models_g()\n",
    "      self.aggregate_parameters_g()\n",
    "\n",
    "    print(\"\\nFinal Average Personalized Recall: {}\\n\".format(self.rs_test_recall_p[-1]))\n",
    "    print(f\"Average Recall for All Users: {np.mean(self.rs_test_recall_p[-1])}\")\n",
    "    print(\"\\nFinal Average Personalized Recall: {}\\n\".format(self.rs_test_mrr_p[-1]))\n",
    "    print(f\"Average MRR for All Users: {np.mean(self.rs_test_mrr_p[-1])}\")\n",
    "\n",
    "  def receive_models(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    tot_samples = 0\n",
    "    for client in self.selected_clients:\n",
    "      tot_samples += client.train_samples\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      self.uploaded_updates.append([c_param.data - s_param.data for c_param, s_param in zip(client.model.parameters(), self.global_model.parameters())])\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.uploaded_ids) if c_id in self.malicious_ids]\n",
    "      self.uploaded_updates = eval(self.attack_type)(self.uploaded_updates, malicious_ids)\n",
    "\n",
    "    for i, w in enumerate(self.uploaded_weights):\n",
    "      self.uploaded_weights[i] = w / tot_samples\n",
    "\n",
    "  def add_parameters(self, w, client_update):\n",
    "    for server_param, client_param in zip(self.global_update, client_update):\n",
    "      server_param.data += client_param.data.clone() * w\n",
    "\n",
    "  def aggregate_parameters(self):\n",
    "    self.global_update = copy.deepcopy(self.uploaded_updates[0])\n",
    "    for param in self.global_update:\n",
    "      param.data.zero_()\n",
    "\n",
    "    for w, client_update in zip(self.uploaded_weights, self.uploaded_updates):\n",
    "      self.add_parameters(w, client_update)\n",
    "\n",
    "    for model_param, update_param in zip(self.global_model.parameters(), self.global_update):\n",
    "      model_param.data += update_param.data.clone()\n",
    "\n",
    "  def collect(self):\n",
    "    clients_updates = []\n",
    "    for client in self.training_clients:\n",
    "      clients_updates.append(client.get_update(self.global_model))\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.training_clients_ids) if c_id in self.malicious_ids]\n",
    "      clients_updates = eval(self.attack_type)(clients_updates, malicious_ids, len(self.selected_clients))\n",
    "\n",
    "    clients_updates = [torch.cat([uu.reshape(-1, 1) for uu in u], axis=0).detach().cpu().numpy().squeeze() for u in clients_updates]\n",
    "    return clients_updates\n",
    "\n",
    "  def cluster(self, clients_updates):\n",
    "    clustering = AgglomerativeClustering(n_clusters=self.n_clusters, metric=self.metric, linkage=self.linkage).fit(clients_updates)\n",
    "    return clustering.labels_\n",
    "\n",
    "  def send_models_g(self):\n",
    "    for client in self.selected_clients:\n",
    "      c_idx = list(self.training_clients_ids).index(client.id)\n",
    "      client.set_parameters(self.group_models[self.cluster_identity[c_idx]])\n",
    "\n",
    "  def receive_models_g(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    for client in self.selected_clients:\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      c_idx = list(self.training_clients_ids).index(client.id)\n",
    "      self.uploaded_updates.append([c_param.data - s_param.data for c_param, s_param in zip(client.model.parameters(), self.group_models[self.cluster_identity[c_idx]].parameters())])\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.uploaded_ids) if c_id in self.malicious_ids]\n",
    "      self.uploaded_updates = eval(self.attack_type)(self.uploaded_updates, malicious_ids)\n",
    "\n",
    "  def aggregate_parameters_g(self):\n",
    "    for i in range(len(self.group_models)):\n",
    "      self.global_update = copy.deepcopy(self.uploaded_updates[0])\n",
    "      for param in self.global_update:\n",
    "        param.data.zero_()\n",
    "\n",
    "      user_idx_in_same_group = np.array([r_id for r_id, c_id in enumerate(self.uploaded_ids) if self.cluster_identity[list(self.training_clients_ids).index(c_id)] == i])\n",
    "      uploaded_weights = [self.uploaded_weights[u_id] for u_id in range(len(self.uploaded_weights)) if u_id in user_idx_in_same_group]\n",
    "      uploaded_weights = [weight / sum(uploaded_weights) for weight in uploaded_weights]\n",
    "      uploaded_updates = [self.uploaded_updates[u_id] for u_id in range(len(self.uploaded_updates)) if u_id in user_idx_in_same_group]\n",
    "\n",
    "      for w, client_update in zip(uploaded_weights, uploaded_updates):\n",
    "        self.add_parameters(w, client_update)\n",
    "\n",
    "      for model_param, update_param in zip(self.group_models[i].parameters(), self.global_update):\n",
    "        model_param.data += update_param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating server and clients ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAttentionNetwork(\n",
      "  (embedding): Embedding(889, 200)\n",
      "  (transformerEncoderLayer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=200, out_features=800, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=800, out_features=200, bias=True)\n",
      "    (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformerEncoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=200, out_features=800, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=800, out_features=200, bias=True)\n",
      "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\n",
      "Malicious Clients: []\n",
      "Future Clients: []\n",
      "\n",
      "Join ratio / total clients: 1.0 / 21\n",
      "Finished creating server and clients.\n",
      "0\n",
      "loss: 6.804601669311523\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\session-based_rs_fl\\fl_srsan_diginetica_clustering.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m server \u001b[39m=\u001b[39m FedCHAR(model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m server\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# server.save_results()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTime cost: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m((time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart)\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m,\u001b[39m \u001b[39m\u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39mmin.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\session-based_rs_fl\\fl_srsan_diginetica_clustering.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_models()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_clients:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   client\u001b[39m.\u001b[39;49mdtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_gap \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------Round number: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m-------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\session-based_rs_fl\\fl_srsan_diginetica_clustering.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGradient: \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m.\u001b[39mgrad\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_per\u001b[39m.\u001b[39;49mstep(model\u001b[39m.\u001b[39;49mparameters(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m targets_g, scores_g \u001b[39m=\u001b[39m forward(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, i, trainloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m targets_g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(targets_g)\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tori_rs\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tori_rs\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tori_rs\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32md:\\session-based_rs_fl\\fl_srsan_diginetica_clustering.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m g \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# print(p.grad)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m d_p \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mdata \u001b[39m+\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mmu\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m (p\u001b[39m.\u001b[39mdata \u001b[39m-\u001b[39m g\u001b[39m.\u001b[39mdata)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/session-based_rs_fl/fl_srsan_diginetica_clustering.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m p\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39madd_(d_p, alpha\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "print(\"Creating server and clients ...\")\n",
    "start = time.time()\n",
    "# model = HARCNN(in_channels=3, num_classes=num_classes, dim=3008).to(device)\n",
    "model = trans_to_cuda(SelfAttentionNetwork(opt, n_node))\n",
    "\n",
    "print(model)\n",
    "\n",
    "server = FedCHAR(model)\n",
    "server.train()\n",
    "# server.save_results()\n",
    "print(f\"\\nTime cost: {round((time.time()-start)/60, 2)}min.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
