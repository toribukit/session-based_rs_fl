{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "from torch.nn import Module, Parameter\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "      self.dataset = 'diginetica'\n",
    "      self.batchSize = 100\n",
    "      self.hiddenSize = 96\n",
    "      self.nhead = 2\n",
    "      self.layer = 1\n",
    "      self.feedforward = 4\n",
    "      self.epoch = 12\n",
    "      self.lr = 0.001\n",
    "      self.lr_dc = 0.1\n",
    "      self.lr_dc_step = 3\n",
    "      self.l2 = 1e-5\n",
    "      self.patience = 12\n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# Now you can access parameters like this:\n",
    "print(opt.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "valid_data = []\n",
    "\n",
    "for i in range(19):\n",
    "  if os.path.isfile(f'{working_dir}/SR-SAN/diginetica_client2/train_{i}.txt'):\n",
    "    print(i)\n",
    "    tr_data = pickle.load(open(f'./SR_SAN_Diginetica/train_{i}.txt', 'rb'))\n",
    "    ts_data = pickle.load(open(f'./SR_SAN_Diginetica/test_{i}.txt', 'rb'))\n",
    "\n",
    "    train_data.append(tr_data)\n",
    "    valid_data.append(ts_data)\n",
    "\n",
    "print(f\"len train: {len(train_data)}\")\n",
    "print(f\"len validation: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_masks(all_usr_pois, item_tail):\n",
    "  us_lens = [len(upois) for upois in all_usr_pois]\n",
    "  len_max = max(us_lens)\n",
    "  us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
    "  us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
    "  return us_pois, us_msks, len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, data, shuffle=False, graph=None):\n",
    "      inputs = data[0]\n",
    "      inputs, mask, len_max = data_masks(inputs, [0])\n",
    "      self.inputs = np.asarray(inputs)\n",
    "      self.mask = np.asarray(mask)\n",
    "      self.len_max = len_max\n",
    "      self.targets = np.asarray(data[1])\n",
    "      self.length = len(inputs)\n",
    "      self.shuffle = shuffle\n",
    "      self.graph = graph\n",
    "\n",
    "    def generate_batch(self, batch_size):\n",
    "      if self.shuffle:\n",
    "        shuffled_arg = np.arange(self.length)\n",
    "        np.random.shuffle(shuffled_arg)\n",
    "        self.inputs = self.inputs[shuffled_arg]\n",
    "        self.mask = self.mask[shuffled_arg]\n",
    "        self.targets = self.targets[shuffled_arg]\n",
    "      n_batch = int(self.length / batch_size)\n",
    "      if self.length % batch_size != 0:\n",
    "        n_batch += 1\n",
    "      slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
    "      slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))]\n",
    "      return slices\n",
    "\n",
    "    def get_slice(self, i):\n",
    "      inputs, mask, targets = self.inputs[i], self.mask[i], self.targets[i]\n",
    "      items, n_node, A, alias_inputs = [], [], [], []\n",
    "      for u_input in inputs:\n",
    "        n_node.append(len(np.unique(u_input)))\n",
    "      max_n_node = np.max(n_node)\n",
    "      for u_input in inputs:\n",
    "        node = np.unique(u_input)\n",
    "        items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
    "        u_A = np.zeros((max_n_node, max_n_node))\n",
    "        for i in np.arange(len(u_input) - 1):\n",
    "          if u_input[i + 1] == 0:\n",
    "            break\n",
    "          u = np.where(node == u_input[i])[0][0]\n",
    "          v = np.where(node == u_input[i + 1])[0][0]\n",
    "          u_A[u][v] = 1\n",
    "        u_sum_in = np.sum(u_A, 0)\n",
    "        u_sum_in[np.where(u_sum_in == 0)] = 1\n",
    "        u_A_in = np.divide(u_A, u_sum_in)\n",
    "        u_sum_out = np.sum(u_A, 1)\n",
    "        u_sum_out[np.where(u_sum_out == 0)] = 1\n",
    "        u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
    "        u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
    "        A.append(u_A)\n",
    "        alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
    "      return alias_inputs, A, items, mask, targets\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.length  # or return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionNetwork(Module):\n",
    "  def __init__(self, opt, n_node):\n",
    "    super(SelfAttentionNetwork, self).__init__()\n",
    "    self.hidden_size = opt.hiddenSize\n",
    "    self.n_node = n_node\n",
    "    self.batch_size = opt.batchSize\n",
    "    self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
    "    self.transformerEncoderLayer = TransformerEncoderLayer(d_model=self.hidden_size, nhead=opt.nhead,dim_feedforward=self.hidden_size * opt.feedforward)\n",
    "    self.transformerEncoder = TransformerEncoder(self.transformerEncoderLayer, opt.layer)\n",
    "    self.loss_function = nn.CrossEntropyLoss()\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr, weight_decay=opt.l2)\n",
    "    self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt.lr_dc_step, gamma=opt.lr_dc)\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "  def compute_scores(self, hidden, mask):\n",
    "    ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
    "    b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
    "    scores = torch.matmul(ht, b.transpose(1, 0))\n",
    "    return scores\n",
    "\n",
    "  def forward(self, inputs, A):\n",
    "    hidden = self.embedding(inputs)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    hidden = self.transformerEncoder(hidden)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cuda(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cuda()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cpu(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cpu()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, i, data):\n",
    "  alias_inputs, A, items, mask, targets = data.get_slice(i)\n",
    "  alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
    "  items = trans_to_cuda(torch.Tensor(items).long())\n",
    "  A = trans_to_cuda(torch.Tensor(A).float())\n",
    "  mask = trans_to_cuda(torch.Tensor(mask).long())\n",
    "  hidden = model(items, A)\n",
    "  get = lambda i: hidden[i][alias_inputs[i]]\n",
    "  seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
    "  return targets, model.compute_scores(seq_hidden, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, train_data, test_data):\n",
    "  print('start training: ', datetime.datetime.now())\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "  slices = train_data.generate_batch(model.batch_size)\n",
    "  for i, j in zip(slices, np.arange(len(slices))):\n",
    "    model.optimizer.zero_grad()\n",
    "    targets, scores = forward(model, i, train_data)\n",
    "    targets = trans_to_cuda(torch.Tensor(targets).long())\n",
    "    loss = model.loss_function(scores, targets - 1)\n",
    "    loss.backward()\n",
    "    model.optimizer.step()\n",
    "    total_loss += loss\n",
    "    if j % int(len(slices) / 5 + 1) == 0:\n",
    "      print('[%d/%d] Loss: %.4f' % (j, len(slices), loss.item()))\n",
    "  print('\\tLoss:\\t%.3f' % total_loss)\n",
    "\n",
    "  print('start predicting: ', datetime.datetime.now())\n",
    "  model.eval()\n",
    "  hit, mrr = [], []\n",
    "  slices = test_data.generate_batch(model.batch_size)\n",
    "  for i in slices:\n",
    "    targets, scores = forward(model, i, test_data)\n",
    "    sub_scores = scores.topk(5)[1]\n",
    "    sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "    for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "      hit.append(np.isin(target - 1, score))\n",
    "      if len(np.where(score == target - 1)[0]) == 0:\n",
    "        mrr.append(0)\n",
    "      else:\n",
    "        mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "  hit = np.mean(hit) * 100\n",
    "  mrr = np.mean(mrr) * 100\n",
    "  model.scheduler.step()\n",
    "  return hit, mrr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
