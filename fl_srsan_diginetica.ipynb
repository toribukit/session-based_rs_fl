{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "from torch.nn import Module, Parameter\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diginetica\n"
     ]
    }
   ],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "      self.dataset = 'diginetica'\n",
    "      self.batchSize = 32\n",
    "      self.hiddenSize = 200\n",
    "      self.nhead = 2\n",
    "      self.layer = 3\n",
    "      self.feedforward = 4\n",
    "      self.epoch = 12\n",
    "      self.lr = 0.001\n",
    "      self.lr_dc = 0.1\n",
    "      self.lr_dc_step = 3\n",
    "      self.l2 = 1e-5\n",
    "      self.patience = 12\n",
    "\n",
    "opt = Options()\n",
    "\n",
    "# Now you can access parameters like this:\n",
    "print(opt.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "7\n",
      "8\n",
      "9\n",
      "16\n",
      "21\n",
      "23\n",
      "24\n",
      "25\n",
      "28\n",
      "31\n",
      "32\n",
      "35\n",
      "36\n",
      "37\n",
      "39\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "len train: 21\n",
      "len validation: 21\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "valid_data = []\n",
    "list_valid_users = []\n",
    "\n",
    "for i in range(45):\n",
    "  if os.path.isfile(f'./SR_SAN_Diginetica/train_{i}.txt'):\n",
    "    print(i)\n",
    "    list_valid_users.append(i)\n",
    "    tr_data = pickle.load(open(f'./SR_SAN_Diginetica/train_{i}.txt', 'rb'))\n",
    "    ts_data = pickle.load(open(f'./SR_SAN_Diginetica/test_{i}.txt', 'rb'))\n",
    "\n",
    "    train_data.append(tr_data)\n",
    "    valid_data.append(ts_data)\n",
    "\n",
    "print(f\"len train: {len(train_data)}\")\n",
    "print(f\"len validation: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 7, 8, 9, 16, 21, 23, 24, 25, 28, 31, 32, 35, 36, 37, 39, 41, 42, 43, 44]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_valid_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_masks(all_usr_pois, item_tail):\n",
    "#   us_lens = [len(upois) for upois in all_usr_pois]\n",
    "#   len_max = max(us_lens)\n",
    "#   us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
    "#   us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
    "#   return us_pois, us_msks, len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_masks(all_usr_pois, item_tail):\n",
    "    if not all_usr_pois or all(len(upois) == 0 for upois in all_usr_pois):\n",
    "        raise ValueError(\"Input all_usr_pois is empty or contains only empty lists\")\n",
    "\n",
    "    us_lens = [len(upois) for upois in all_usr_pois]\n",
    "    len_max = max(us_lens)\n",
    "    us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
    "    us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
    "    return us_pois, us_msks, len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, data, shuffle=False, graph=None):\n",
    "      inputs = data[0]\n",
    "      inputs, mask, len_max = data_masks(inputs, [0])\n",
    "      self.inputs = np.asarray(inputs)\n",
    "      self.mask = np.asarray(mask)\n",
    "      self.len_max = len_max\n",
    "      self.targets = np.asarray(data[1])\n",
    "      self.length = len(inputs)\n",
    "      self.shuffle = shuffle\n",
    "      self.graph = graph\n",
    "\n",
    "    def generate_batch(self, batch_size):\n",
    "      if self.shuffle:\n",
    "        shuffled_arg = np.arange(self.length)\n",
    "        np.random.shuffle(shuffled_arg)\n",
    "        self.inputs = self.inputs[shuffled_arg]\n",
    "        self.mask = self.mask[shuffled_arg]\n",
    "        self.targets = self.targets[shuffled_arg]\n",
    "      n_batch = int(self.length / batch_size)\n",
    "      if self.length % batch_size != 0:\n",
    "        n_batch += 1\n",
    "      slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
    "      slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))]\n",
    "      return slices\n",
    "\n",
    "    def get_slice(self, i):\n",
    "      inputs, mask, targets = self.inputs[i], self.mask[i], self.targets[i]\n",
    "      items, n_node, A, alias_inputs = [], [], [], []\n",
    "      for u_input in inputs:\n",
    "        n_node.append(len(np.unique(u_input)))\n",
    "      max_n_node = np.max(n_node)\n",
    "      for u_input in inputs:\n",
    "        node = np.unique(u_input)\n",
    "        items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
    "        u_A = np.zeros((max_n_node, max_n_node))\n",
    "        for i in np.arange(len(u_input) - 1):\n",
    "          if u_input[i + 1] == 0:\n",
    "            break\n",
    "          u = np.where(node == u_input[i])[0][0]\n",
    "          v = np.where(node == u_input[i + 1])[0][0]\n",
    "          u_A[u][v] = 1\n",
    "        u_sum_in = np.sum(u_A, 0)\n",
    "        u_sum_in[np.where(u_sum_in == 0)] = 1\n",
    "        u_A_in = np.divide(u_A, u_sum_in)\n",
    "        u_sum_out = np.sum(u_A, 1)\n",
    "        u_sum_out[np.where(u_sum_out == 0)] = 1\n",
    "        u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
    "        u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
    "        A.append(u_A)\n",
    "        alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
    "      return alias_inputs, A, items, mask, targets\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.length  # or return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionNetwork(Module):\n",
    "  def __init__(self, opt, n_node):\n",
    "    super(SelfAttentionNetwork, self).__init__()\n",
    "    self.hidden_size = opt.hiddenSize\n",
    "    self.n_node = n_node\n",
    "    self.batch_size = opt.batchSize\n",
    "    self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
    "    self.transformerEncoderLayer = TransformerEncoderLayer(d_model=self.hidden_size, nhead=opt.nhead,dim_feedforward=self.hidden_size * opt.feedforward)\n",
    "    self.transformerEncoder = TransformerEncoder(self.transformerEncoderLayer, opt.layer)\n",
    "    self.loss_function = nn.CrossEntropyLoss()\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr, weight_decay=opt.l2)\n",
    "    self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt.lr_dc_step, gamma=opt.lr_dc)\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self):\n",
    "    stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "    for weight in self.parameters():\n",
    "      weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "  def compute_scores(self, hidden, mask):\n",
    "    ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
    "    b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
    "    scores = torch.matmul(ht, b.transpose(1, 0))\n",
    "    return scores\n",
    "\n",
    "  def forward(self, inputs, A):\n",
    "    hidden = self.embedding(inputs)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    hidden = self.transformerEncoder(hidden)\n",
    "    hidden = hidden.transpose(0,1).contiguous()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cuda(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cuda()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_cpu(variable):\n",
    "  if torch.cuda.is_available():\n",
    "    return variable.cpu()\n",
    "  else:\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, i, data):\n",
    "  alias_inputs, A, items, mask, targets = data.get_slice(i)\n",
    "  alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
    "  items = trans_to_cuda(torch.Tensor(items).long())\n",
    "  A = trans_to_cuda(torch.Tensor(A).float())\n",
    "  mask = trans_to_cuda(torch.Tensor(mask).long())\n",
    "  hidden = model(items, A)\n",
    "  get = lambda i: hidden[i][alias_inputs[i]]\n",
    "  seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
    "  return targets, model.compute_scores(seq_hidden, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(scores, targets, k=5):\n",
    "    recall_at_k = []\n",
    "    top_k_scores = scores.topk(k)[1]\n",
    "    for score, target in zip(top_k_scores, targets):\n",
    "        recall_at_k.append((target - 1) in score)\n",
    "    return np.mean(recall_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, device):\n",
    "    print('start predicting: ', datetime.datetime.now())\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    hit, mrr, total_loss = [], [], 0.0\n",
    "    recall_list = []\n",
    "    slices = test_data.generate_batch(model.batch_size)\n",
    "\n",
    "    for i in slices:\n",
    "        targets, scores = forward(model, i, test_data)\n",
    "        targets = torch.Tensor(targets).long().to(device)  # Convert targets to a PyTorch tensor and move to the correct device\n",
    "\n",
    "        loss = model.loss_function(scores, targets - 1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        sub_scores = scores.topk(5)[1] #top-k items\n",
    "        sub_scores = sub_scores.cpu().detach().numpy()  # Move to CPU if necessary\n",
    "\n",
    "        targets_np = targets.cpu().numpy()  # Convert targets to NumPy array for use with NumPy functions\n",
    "        for score, target_np, mask in zip(sub_scores, targets_np, test_data.mask):\n",
    "            hit.append(np.isin(target_np - 1, score))\n",
    "            mrr_index = np.where(score == target_np - 1)[0]\n",
    "            mrr.append(0 if len(mrr_index) == 0 else 1 / (mrr_index[0] + 1))\n",
    "\n",
    "        recall = calculate_recall_at_k(scores, targets)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "    hit = np.mean(hit) * 100\n",
    "    mrr = np.mean(mrr) * 100\n",
    "    recall = np.mean(recall_list) * 100\n",
    "    average_loss = total_loss / len(slices)\n",
    "\n",
    "    results = {'recall': recall, 'hit': hit, 'mrr': mrr}\n",
    "\n",
    "    return average_loss, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, test_data, epochs, device):\n",
    "    print('start training: ', datetime.datetime.now())\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        slices = train_data.generate_batch(model.batch_size)\n",
    "        num_batches = len(slices)\n",
    "\n",
    "        for i, j in zip(slices, np.arange(num_batches)):\n",
    "            model.optimizer.zero_grad()\n",
    "            targets, scores = forward(model, i, train_data)\n",
    "            targets = trans_to_cuda(torch.Tensor(targets).long())\n",
    "            # targets = targets.to(device)  # Ensure targets are on the correct device\n",
    "            loss = model.loss_function(scores, targets - 1)\n",
    "            loss.backward()\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is None:\n",
    "                    print(f\"Parameter name: {name}\")\n",
    "                    print(f\"Parameter shape: {param.shape}\")\n",
    "                    print(f\"Gradient: {param.grad}\")\n",
    "                    print(\"=\" * 20)\n",
    "                    model.optimizer.step()\n",
    "                    total_loss += loss.item()  # Use .item() to get the scalar value\n",
    "\n",
    "            if j % int(num_batches / 5 + 1) == 0:\n",
    "                print(f'[{j}/{num_batches}] Loss: {loss.item():.4f}')\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch: {epoch}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_loss, val_results = test(model, test_data, device)\n",
    "\n",
    "        model.scheduler.step()\n",
    "    \n",
    "    return val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tori_rs\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training:  2023-12-10 03:08:07.690211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IME-LAB\\AppData\\Local\\Temp\\ipykernel_14420\\569402041.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  A = trans_to_cuda(torch.Tensor(A).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8011\n",
      "Epoch: 0, Average Loss: 81.6137\n",
      "start predicting:  2023-12-10 03:08:08.621719\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5184\n",
      "Epoch: 1, Average Loss: 78.2203\n",
      "start predicting:  2023-12-10 03:08:08.661583\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0111\n",
      "Epoch: 2, Average Loss: 72.1330\n",
      "start predicting:  2023-12-10 03:08:08.698483\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3184\n",
      "Epoch: 3, Average Loss: 63.8203\n",
      "start predicting:  2023-12-10 03:08:08.733390\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2130\n",
      "Epoch: 4, Average Loss: 62.5563\n",
      "start predicting:  2023-12-10 03:08:08.768297\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0976\n",
      "Epoch: 5, Average Loss: 61.1711\n",
      "start predicting:  2023-12-10 03:08:08.805198\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9885\n",
      "Epoch: 6, Average Loss: 59.8617\n",
      "start predicting:  2023-12-10 03:08:08.840105\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9780\n",
      "Epoch: 7, Average Loss: 59.7364\n",
      "start predicting:  2023-12-10 03:08:08.874015\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9679\n",
      "Epoch: 8, Average Loss: 59.6146\n",
      "start predicting:  2023-12-10 03:08:08.908921\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9580\n",
      "Epoch: 9, Average Loss: 59.4956\n",
      "start predicting:  2023-12-10 03:08:08.943828\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9570\n",
      "Epoch: 10, Average Loss: 59.4839\n",
      "start predicting:  2023-12-10 03:08:08.976739\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9560\n",
      "Epoch: 11, Average Loss: 59.4724\n",
      "start predicting:  2023-12-10 03:08:09.009651\n",
      "start predicting:  2023-12-10 03:08:09.016633\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 1\n",
      "start training:  2023-12-10 03:08:09.050542\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7873\n",
      "Epoch: 0, Average Loss: 81.4478\n",
      "start predicting:  2023-12-10 03:08:09.087443\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5171\n",
      "Epoch: 1, Average Loss: 78.2055\n",
      "start predicting:  2023-12-10 03:08:09.127336\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9943\n",
      "Epoch: 2, Average Loss: 71.9317\n",
      "start predicting:  2023-12-10 03:08:09.167231\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2803\n",
      "Epoch: 3, Average Loss: 63.3632\n",
      "start predicting:  2023-12-10 03:08:09.206126\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1799\n",
      "Epoch: 4, Average Loss: 62.1589\n",
      "start predicting:  2023-12-10 03:08:09.247017\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0719\n",
      "Epoch: 5, Average Loss: 60.8627\n",
      "start predicting:  2023-12-10 03:08:09.285913\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9689\n",
      "Epoch: 6, Average Loss: 59.6262\n",
      "start predicting:  2023-12-10 03:08:09.323811\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9589\n",
      "Epoch: 7, Average Loss: 59.5073\n",
      "start predicting:  2023-12-10 03:08:09.363156\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9493\n",
      "Epoch: 8, Average Loss: 59.3916\n",
      "start predicting:  2023-12-10 03:08:09.402963\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9399\n",
      "Epoch: 9, Average Loss: 59.2783\n",
      "start predicting:  2023-12-10 03:08:09.443854\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9389\n",
      "Epoch: 10, Average Loss: 59.2672\n",
      "start predicting:  2023-12-10 03:08:09.484485\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9380\n",
      "Epoch: 11, Average Loss: 59.2562\n",
      "start predicting:  2023-12-10 03:08:09.524422\n",
      "start predicting:  2023-12-10 03:08:09.530391\n",
      "Hit: 25.0000\n",
      "MRR: 12.5000\n",
      "Recall: 25.0000\n",
      "Client 2\n",
      "start training:  2023-12-10 03:08:09.562276\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7579\n",
      "Epoch: 0, Average Loss: 81.0944\n",
      "start predicting:  2023-12-10 03:08:09.591199\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3380\n",
      "Epoch: 1, Average Loss: 76.0557\n",
      "start predicting:  2023-12-10 03:08:09.623115\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7512\n",
      "Epoch: 2, Average Loss: 69.0139\n",
      "start predicting:  2023-12-10 03:08:09.677968\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9812\n",
      "Epoch: 3, Average Loss: 59.7739\n",
      "start predicting:  2023-12-10 03:08:09.711877\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8523\n",
      "Epoch: 4, Average Loss: 58.2279\n",
      "start predicting:  2023-12-10 03:08:09.746806\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7175\n",
      "Epoch: 5, Average Loss: 56.6102\n",
      "start predicting:  2023-12-10 03:08:09.773734\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5953\n",
      "Epoch: 6, Average Loss: 55.1440\n",
      "start predicting:  2023-12-10 03:08:09.799670\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5838\n",
      "Epoch: 7, Average Loss: 55.0051\n",
      "start predicting:  2023-12-10 03:08:09.829591\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5725\n",
      "Epoch: 8, Average Loss: 54.8700\n",
      "start predicting:  2023-12-10 03:08:09.861477\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5615\n",
      "Epoch: 9, Average Loss: 54.7379\n",
      "start predicting:  2023-12-10 03:08:09.905388\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5604\n",
      "Epoch: 10, Average Loss: 54.7250\n",
      "start predicting:  2023-12-10 03:08:09.935308\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5593\n",
      "Epoch: 11, Average Loss: 54.7122\n",
      "start predicting:  2023-12-10 03:08:09.966212\n",
      "start predicting:  2023-12-10 03:08:09.971214\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 3\n",
      "start training:  2023-12-10 03:08:10.002100\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8052\n",
      "Epoch: 0, Average Loss: 81.6624\n",
      "start predicting:  2023-12-10 03:08:10.031023\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5071\n",
      "Epoch: 1, Average Loss: 78.0856\n",
      "start predicting:  2023-12-10 03:08:10.062938\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0033\n",
      "Epoch: 2, Average Loss: 72.0396\n",
      "start predicting:  2023-12-10 03:08:10.094852\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3189\n",
      "Epoch: 3, Average Loss: 63.8266\n",
      "start predicting:  2023-12-10 03:08:10.125769\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2097\n",
      "Epoch: 4, Average Loss: 62.5160\n",
      "start predicting:  2023-12-10 03:08:10.157684\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0914\n",
      "Epoch: 5, Average Loss: 61.0965\n",
      "start predicting:  2023-12-10 03:08:10.189600\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9814\n",
      "Epoch: 6, Average Loss: 59.7770\n",
      "start predicting:  2023-12-10 03:08:10.219551\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9709\n",
      "Epoch: 7, Average Loss: 59.6512\n",
      "start predicting:  2023-12-10 03:08:10.249467\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9607\n",
      "Epoch: 8, Average Loss: 59.5289\n",
      "start predicting:  2023-12-10 03:08:10.281381\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9508\n",
      "Epoch: 9, Average Loss: 59.4093\n",
      "start predicting:  2023-12-10 03:08:10.310306\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9498\n",
      "Epoch: 10, Average Loss: 59.3976\n",
      "start predicting:  2023-12-10 03:08:10.340196\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9488\n",
      "Epoch: 11, Average Loss: 59.3860\n",
      "start predicting:  2023-12-10 03:08:10.371386\n",
      "start predicting:  2023-12-10 03:08:10.377370\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 4\n",
      "start training:  2023-12-10 03:08:10.405295\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7989\n",
      "Epoch: 0, Average Loss: 81.5867\n",
      "start predicting:  2023-12-10 03:08:10.435215\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5089\n",
      "Epoch: 1, Average Loss: 78.1064\n",
      "start predicting:  2023-12-10 03:08:10.466133\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9998\n",
      "Epoch: 2, Average Loss: 71.9971\n",
      "start predicting:  2023-12-10 03:08:10.501040\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2822\n",
      "Epoch: 3, Average Loss: 63.3869\n",
      "start predicting:  2023-12-10 03:08:10.531956\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1756\n",
      "Epoch: 4, Average Loss: 62.1077\n",
      "start predicting:  2023-12-10 03:08:10.565865\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0603\n",
      "Epoch: 5, Average Loss: 60.7237\n",
      "start predicting:  2023-12-10 03:08:10.598806\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9519\n",
      "Epoch: 6, Average Loss: 59.4233\n",
      "start predicting:  2023-12-10 03:08:10.629695\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9416\n",
      "Epoch: 7, Average Loss: 59.2988\n",
      "start predicting:  2023-12-10 03:08:10.662635\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9315\n",
      "Epoch: 8, Average Loss: 59.1776\n",
      "start predicting:  2023-12-10 03:08:10.690577\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9216\n",
      "Epoch: 9, Average Loss: 59.0591\n",
      "start predicting:  2023-12-10 03:08:10.722477\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9206\n",
      "Epoch: 10, Average Loss: 59.0475\n",
      "start predicting:  2023-12-10 03:08:10.753393\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9197\n",
      "Epoch: 11, Average Loss: 59.0360\n",
      "start predicting:  2023-12-10 03:08:10.785279\n",
      "start predicting:  2023-12-10 03:08:10.790266\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 5\n",
      "start training:  2023-12-10 03:08:10.821183\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8066\n",
      "Epoch: 0, Average Loss: 81.6788\n",
      "start predicting:  2023-12-10 03:08:10.849108\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4381\n",
      "Epoch: 1, Average Loss: 77.2577\n",
      "start predicting:  2023-12-10 03:08:10.880025\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9002\n",
      "Epoch: 2, Average Loss: 70.8018\n",
      "start predicting:  2023-12-10 03:08:10.911940\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1725\n",
      "Epoch: 3, Average Loss: 62.0699\n",
      "start predicting:  2023-12-10 03:08:10.941860\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0525\n",
      "Epoch: 4, Average Loss: 60.6295\n",
      "start predicting:  2023-12-10 03:08:10.972778\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9240\n",
      "Epoch: 5, Average Loss: 59.0883\n",
      "start predicting:  2023-12-10 03:08:11.002697\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8066\n",
      "Epoch: 6, Average Loss: 57.6787\n",
      "start predicting:  2023-12-10 03:08:11.032646\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7954\n",
      "Epoch: 7, Average Loss: 57.5450\n",
      "start predicting:  2023-12-10 03:08:11.062562\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7846\n",
      "Epoch: 8, Average Loss: 57.4151\n",
      "start predicting:  2023-12-10 03:08:11.090488\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7740\n",
      "Epoch: 9, Average Loss: 57.2881\n",
      "start predicting:  2023-12-10 03:08:11.121432\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7730\n",
      "Epoch: 10, Average Loss: 57.2757\n",
      "start predicting:  2023-12-10 03:08:11.151325\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7719\n",
      "Epoch: 11, Average Loss: 57.2634\n",
      "start predicting:  2023-12-10 03:08:11.181272\n",
      "start predicting:  2023-12-10 03:08:11.187228\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 6\n",
      "start training:  2023-12-10 03:08:11.216150\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7885\n",
      "Epoch: 0, Average Loss: 81.4621\n",
      "start predicting:  2023-12-10 03:08:11.243078\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2561\n",
      "Epoch: 1, Average Loss: 75.0736\n",
      "start predicting:  2023-12-10 03:08:11.272001\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6359\n",
      "Epoch: 2, Average Loss: 67.6310\n",
      "start predicting:  2023-12-10 03:08:11.300925\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9039\n",
      "Epoch: 3, Average Loss: 58.8472\n",
      "start predicting:  2023-12-10 03:08:11.329846\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7403\n",
      "Epoch: 4, Average Loss: 56.8830\n",
      "start predicting:  2023-12-10 03:08:11.359766\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5832\n",
      "Epoch: 5, Average Loss: 54.9979\n",
      "start predicting:  2023-12-10 03:08:11.388689\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4572\n",
      "Epoch: 6, Average Loss: 53.4860\n",
      "start predicting:  2023-12-10 03:08:11.415641\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4457\n",
      "Epoch: 7, Average Loss: 53.3483\n",
      "start predicting:  2023-12-10 03:08:11.444568\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4345\n",
      "Epoch: 8, Average Loss: 53.2144\n",
      "start predicting:  2023-12-10 03:08:11.474488\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4236\n",
      "Epoch: 9, Average Loss: 53.0835\n",
      "start predicting:  2023-12-10 03:08:11.502385\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4226\n",
      "Epoch: 10, Average Loss: 53.0706\n",
      "start predicting:  2023-12-10 03:08:11.532305\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4215\n",
      "Epoch: 11, Average Loss: 53.0579\n",
      "start predicting:  2023-12-10 03:08:11.561247\n",
      "start predicting:  2023-12-10 03:08:11.566243\n",
      "Hit: 100.0000\n",
      "MRR: 50.0000\n",
      "Recall: 100.0000\n",
      "Client 7\n",
      "start training:  2023-12-10 03:08:11.595137\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7744\n",
      "Epoch: 0, Average Loss: 81.2926\n",
      "start predicting:  2023-12-10 03:08:11.631041\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5258\n",
      "Epoch: 1, Average Loss: 78.3091\n",
      "start predicting:  2023-12-10 03:08:11.669937\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9938\n",
      "Epoch: 2, Average Loss: 71.9258\n",
      "start predicting:  2023-12-10 03:08:11.708833\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3072\n",
      "Epoch: 3, Average Loss: 63.6859\n",
      "start predicting:  2023-12-10 03:08:11.747729\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2073\n",
      "Epoch: 4, Average Loss: 62.4879\n",
      "start predicting:  2023-12-10 03:08:11.786653\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1017\n",
      "Epoch: 5, Average Loss: 61.2206\n",
      "start predicting:  2023-12-10 03:08:11.824553\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0028\n",
      "Epoch: 6, Average Loss: 60.0334\n",
      "start predicting:  2023-12-10 03:08:11.863448\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9934\n",
      "Epoch: 7, Average Loss: 59.9203\n",
      "start predicting:  2023-12-10 03:08:11.901320\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9842\n",
      "Epoch: 8, Average Loss: 59.8105\n",
      "start predicting:  2023-12-10 03:08:11.939245\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9753\n",
      "Epoch: 9, Average Loss: 59.7031\n",
      "start predicting:  2023-12-10 03:08:11.980139\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9744\n",
      "Epoch: 10, Average Loss: 59.6925\n",
      "start predicting:  2023-12-10 03:08:12.017010\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9735\n",
      "Epoch: 11, Average Loss: 59.6821\n",
      "start predicting:  2023-12-10 03:08:12.054936\n",
      "start predicting:  2023-12-10 03:08:12.060891\n",
      "Hit: 100.0000\n",
      "MRR: 25.0000\n",
      "Recall: 100.0000\n",
      "Client 8\n",
      "start training:  2023-12-10 03:08:12.090811\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7867\n",
      "Epoch: 0, Average Loss: 81.4406\n",
      "start predicting:  2023-12-10 03:08:12.122726\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4721\n",
      "Epoch: 1, Average Loss: 77.6654\n",
      "start predicting:  2023-12-10 03:08:12.156635\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9163\n",
      "Epoch: 2, Average Loss: 70.9960\n",
      "start predicting:  2023-12-10 03:08:12.191542\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1644\n",
      "Epoch: 3, Average Loss: 61.9722\n",
      "start predicting:  2023-12-10 03:08:12.226448\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0540\n",
      "Epoch: 4, Average Loss: 60.6479\n",
      "start predicting:  2023-12-10 03:08:12.260358\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9360\n",
      "Epoch: 5, Average Loss: 59.2315\n",
      "start predicting:  2023-12-10 03:08:12.294267\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8249\n",
      "Epoch: 6, Average Loss: 57.8990\n",
      "start predicting:  2023-12-10 03:08:12.327208\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8143\n",
      "Epoch: 7, Average Loss: 57.7716\n",
      "start predicting:  2023-12-10 03:08:12.360114\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8040\n",
      "Epoch: 8, Average Loss: 57.6477\n",
      "start predicting:  2023-12-10 03:08:12.392433\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7939\n",
      "Epoch: 9, Average Loss: 57.5267\n",
      "start predicting:  2023-12-10 03:08:12.450249\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7929\n",
      "Epoch: 10, Average Loss: 57.5147\n",
      "start predicting:  2023-12-10 03:08:12.490142\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7919\n",
      "Epoch: 11, Average Loss: 57.5030\n",
      "start predicting:  2023-12-10 03:08:12.528069\n",
      "start predicting:  2023-12-10 03:08:12.534025\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 9\n",
      "start training:  2023-12-10 03:08:12.565940\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8227\n",
      "Epoch: 0, Average Loss: 81.8719\n",
      "start predicting:  2023-12-10 03:08:12.595861\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4444\n",
      "Epoch: 1, Average Loss: 77.3322\n",
      "start predicting:  2023-12-10 03:08:12.648718\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9274\n",
      "Epoch: 2, Average Loss: 71.1283\n",
      "start predicting:  2023-12-10 03:08:12.680632\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1769\n",
      "Epoch: 3, Average Loss: 62.1226\n",
      "start predicting:  2023-12-10 03:08:12.710553\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0657\n",
      "Epoch: 4, Average Loss: 60.7886\n",
      "start predicting:  2023-12-10 03:08:12.743464\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9467\n",
      "Epoch: 5, Average Loss: 59.3600\n",
      "start predicting:  2023-12-10 03:08:12.773385\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8344\n",
      "Epoch: 6, Average Loss: 58.0122\n",
      "start predicting:  2023-12-10 03:08:12.806320\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8235\n",
      "Epoch: 7, Average Loss: 57.8823\n",
      "start predicting:  2023-12-10 03:08:12.835247\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8130\n",
      "Epoch: 8, Average Loss: 57.7557\n",
      "start predicting:  2023-12-10 03:08:12.864170\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8026\n",
      "Epoch: 9, Average Loss: 57.6318\n",
      "start predicting:  2023-12-10 03:08:12.891070\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8016\n",
      "Epoch: 10, Average Loss: 57.6196\n",
      "start predicting:  2023-12-10 03:08:12.922985\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8006\n",
      "Epoch: 11, Average Loss: 57.6076\n",
      "start predicting:  2023-12-10 03:08:12.955897\n",
      "start predicting:  2023-12-10 03:08:12.960883\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 10\n",
      "start training:  2023-12-10 03:08:12.990803\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7706\n",
      "Epoch: 0, Average Loss: 81.2477\n",
      "start predicting:  2023-12-10 03:08:13.023715\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4433\n",
      "Epoch: 1, Average Loss: 77.3191\n",
      "start predicting:  2023-12-10 03:08:13.058621\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8730\n",
      "Epoch: 2, Average Loss: 70.4755\n",
      "start predicting:  2023-12-10 03:08:13.094525\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1350\n",
      "Epoch: 3, Average Loss: 61.6205\n",
      "start predicting:  2023-12-10 03:08:13.132425\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0178\n",
      "Epoch: 4, Average Loss: 60.2134\n",
      "start predicting:  2023-12-10 03:08:13.169326\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8911\n",
      "Epoch: 5, Average Loss: 58.6934\n",
      "start predicting:  2023-12-10 03:08:13.206227\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7728\n",
      "Epoch: 6, Average Loss: 57.2735\n",
      "start predicting:  2023-12-10 03:08:13.240136\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7615\n",
      "Epoch: 7, Average Loss: 57.1382\n",
      "start predicting:  2023-12-10 03:08:13.275043\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7506\n",
      "Epoch: 8, Average Loss: 57.0068\n",
      "start predicting:  2023-12-10 03:08:13.309951\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7399\n",
      "Epoch: 9, Average Loss: 56.8783\n",
      "start predicting:  2023-12-10 03:08:13.346851\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7388\n",
      "Epoch: 10, Average Loss: 56.8657\n",
      "start predicting:  2023-12-10 03:08:13.381470\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7378\n",
      "Epoch: 11, Average Loss: 56.8532\n",
      "start predicting:  2023-12-10 03:08:13.417348\n",
      "start predicting:  2023-12-10 03:08:13.423360\n",
      "Hit: 50.0000\n",
      "MRR: 25.0000\n",
      "Recall: 50.0000\n",
      "Client 11\n",
      "start training:  2023-12-10 03:08:13.460233\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7817\n",
      "Epoch: 0, Average Loss: 81.3805\n",
      "start predicting:  2023-12-10 03:08:13.493145\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5060\n",
      "Epoch: 1, Average Loss: 78.0725\n",
      "start predicting:  2023-12-10 03:08:13.530046\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9841\n",
      "Epoch: 2, Average Loss: 71.8094\n",
      "start predicting:  2023-12-10 03:08:13.565950\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2911\n",
      "Epoch: 3, Average Loss: 63.4931\n",
      "start predicting:  2023-12-10 03:08:13.602851\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1784\n",
      "Epoch: 4, Average Loss: 62.1404\n",
      "start predicting:  2023-12-10 03:08:13.639753\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0568\n",
      "Epoch: 5, Average Loss: 60.6812\n",
      "start predicting:  2023-12-10 03:08:13.676680\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9435\n",
      "Epoch: 6, Average Loss: 59.3215\n",
      "start predicting:  2023-12-10 03:08:13.712558\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9327\n",
      "Epoch: 7, Average Loss: 59.1921\n",
      "start predicting:  2023-12-10 03:08:13.749488\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9222\n",
      "Epoch: 8, Average Loss: 59.0667\n",
      "start predicting:  2023-12-10 03:08:13.785493\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9120\n",
      "Epoch: 9, Average Loss: 58.9441\n",
      "start predicting:  2023-12-10 03:08:13.822356\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9110\n",
      "Epoch: 10, Average Loss: 58.9321\n",
      "start predicting:  2023-12-10 03:08:13.857263\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9100\n",
      "Epoch: 11, Average Loss: 58.9202\n",
      "start predicting:  2023-12-10 03:08:13.894199\n",
      "start predicting:  2023-12-10 03:08:13.899180\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 12\n",
      "start training:  2023-12-10 03:08:13.930068\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7849\n",
      "Epoch: 0, Average Loss: 81.4191\n",
      "start predicting:  2023-12-10 03:08:13.963977\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4844\n",
      "Epoch: 1, Average Loss: 77.8132\n",
      "start predicting:  2023-12-10 03:08:13.998884\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9513\n",
      "Epoch: 2, Average Loss: 71.4162\n",
      "start predicting:  2023-12-10 03:08:14.034788\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2206\n",
      "Epoch: 3, Average Loss: 62.6466\n",
      "start predicting:  2023-12-10 03:08:14.071689\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1128\n",
      "Epoch: 4, Average Loss: 61.3534\n",
      "start predicting:  2023-12-10 03:08:14.107593\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9965\n",
      "Epoch: 5, Average Loss: 59.9579\n",
      "start predicting:  2023-12-10 03:08:14.140533\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8863\n",
      "Epoch: 6, Average Loss: 58.6357\n",
      "start predicting:  2023-12-10 03:08:14.175413\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8757\n",
      "Epoch: 7, Average Loss: 58.5086\n",
      "start predicting:  2023-12-10 03:08:14.211344\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8654\n",
      "Epoch: 8, Average Loss: 58.3850\n",
      "start predicting:  2023-12-10 03:08:14.246251\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8553\n",
      "Epoch: 9, Average Loss: 58.2640\n",
      "start predicting:  2023-12-10 03:08:14.285150\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8543\n",
      "Epoch: 10, Average Loss: 58.2521\n",
      "start predicting:  2023-12-10 03:08:14.320054\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8534\n",
      "Epoch: 11, Average Loss: 58.2404\n",
      "start predicting:  2023-12-10 03:08:14.356959\n",
      "start predicting:  2023-12-10 03:08:14.362943\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 13\n",
      "start training:  2023-12-10 03:08:14.391833\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7907\n",
      "Epoch: 0, Average Loss: 81.4879\n",
      "start predicting:  2023-12-10 03:08:14.422750\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4481\n",
      "Epoch: 1, Average Loss: 77.3777\n",
      "start predicting:  2023-12-10 03:08:14.458654\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8754\n",
      "Epoch: 2, Average Loss: 70.5049\n",
      "start predicting:  2023-12-10 03:08:14.495555\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1262\n",
      "Epoch: 3, Average Loss: 61.5145\n",
      "start predicting:  2023-12-10 03:08:14.533454\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0074\n",
      "Epoch: 4, Average Loss: 60.0885\n",
      "start predicting:  2023-12-10 03:08:14.569358\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8811\n",
      "Epoch: 5, Average Loss: 58.5736\n",
      "start predicting:  2023-12-10 03:08:14.604296\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7639\n",
      "Epoch: 6, Average Loss: 57.1666\n",
      "start predicting:  2023-12-10 03:08:14.640169\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7527\n",
      "Epoch: 7, Average Loss: 57.0324\n",
      "start predicting:  2023-12-10 03:08:14.670089\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7418\n",
      "Epoch: 8, Average Loss: 56.9020\n",
      "start predicting:  2023-12-10 03:08:14.708019\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7312\n",
      "Epoch: 9, Average Loss: 56.7745\n",
      "start predicting:  2023-12-10 03:08:14.741925\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7302\n",
      "Epoch: 10, Average Loss: 56.7620\n",
      "start predicting:  2023-12-10 03:08:14.777836\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7291\n",
      "Epoch: 11, Average Loss: 56.7497\n",
      "start predicting:  2023-12-10 03:08:14.813734\n",
      "start predicting:  2023-12-10 03:08:14.821713\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 14\n",
      "start training:  2023-12-10 03:08:14.850606\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7860\n",
      "Epoch: 0, Average Loss: 81.4319\n",
      "start predicting:  2023-12-10 03:08:14.881523\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3573\n",
      "Epoch: 1, Average Loss: 76.2873\n",
      "start predicting:  2023-12-10 03:08:14.919424\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8022\n",
      "Epoch: 2, Average Loss: 69.6260\n",
      "start predicting:  2023-12-10 03:08:14.995219\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0640\n",
      "Epoch: 3, Average Loss: 60.7685\n",
      "start predicting:  2023-12-10 03:08:15.030126\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9412\n",
      "Epoch: 4, Average Loss: 59.2949\n",
      "start predicting:  2023-12-10 03:08:15.064064\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8114\n",
      "Epoch: 5, Average Loss: 57.7371\n",
      "start predicting:  2023-12-10 03:08:15.096980\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6934\n",
      "Epoch: 6, Average Loss: 56.3213\n",
      "start predicting:  2023-12-10 03:08:15.131883\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6823\n",
      "Epoch: 7, Average Loss: 56.1871\n",
      "start predicting:  2023-12-10 03:08:15.166879\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6714\n",
      "Epoch: 8, Average Loss: 56.0566\n",
      "start predicting:  2023-12-10 03:08:15.202757\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6607\n",
      "Epoch: 9, Average Loss: 55.9290\n",
      "start predicting:  2023-12-10 03:08:15.238689\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6597\n",
      "Epoch: 10, Average Loss: 55.9164\n",
      "start predicting:  2023-12-10 03:08:15.270581\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6587\n",
      "Epoch: 11, Average Loss: 55.9040\n",
      "start predicting:  2023-12-10 03:08:15.305513\n",
      "start predicting:  2023-12-10 03:08:15.311498\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 15\n",
      "start training:  2023-12-10 03:08:15.341386\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8059\n",
      "Epoch: 0, Average Loss: 81.6702\n",
      "start predicting:  2023-12-10 03:08:15.372303\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3845\n",
      "Epoch: 1, Average Loss: 76.6140\n",
      "start predicting:  2023-12-10 03:08:15.405215\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8403\n",
      "Epoch: 2, Average Loss: 70.0834\n",
      "start predicting:  2023-12-10 03:08:15.438127\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1347\n",
      "Epoch: 3, Average Loss: 61.6166\n",
      "start predicting:  2023-12-10 03:08:15.472037\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0095\n",
      "Epoch: 4, Average Loss: 60.1136\n",
      "start predicting:  2023-12-10 03:08:15.502954\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8782\n",
      "Epoch: 5, Average Loss: 58.5389\n",
      "start predicting:  2023-12-10 03:08:15.535895\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7610\n",
      "Epoch: 6, Average Loss: 57.1316\n",
      "start predicting:  2023-12-10 03:08:15.570801\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7499\n",
      "Epoch: 7, Average Loss: 56.9991\n",
      "start predicting:  2023-12-10 03:08:15.603713\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7392\n",
      "Epoch: 8, Average Loss: 56.8704\n",
      "start predicting:  2023-12-10 03:08:15.636628\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7287\n",
      "Epoch: 9, Average Loss: 56.7446\n",
      "start predicting:  2023-12-10 03:08:15.670506\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7277\n",
      "Epoch: 10, Average Loss: 56.7322\n",
      "start predicting:  2023-12-10 03:08:15.704416\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7267\n",
      "Epoch: 11, Average Loss: 56.7200\n",
      "start predicting:  2023-12-10 03:08:15.737353\n",
      "start predicting:  2023-12-10 03:08:15.742356\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 16\n",
      "start training:  2023-12-10 03:08:15.773231\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7779\n",
      "Epoch: 0, Average Loss: 81.3343\n",
      "start predicting:  2023-12-10 03:08:15.805146\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4258\n",
      "Epoch: 1, Average Loss: 77.1093\n",
      "start predicting:  2023-12-10 03:08:15.839055\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8826\n",
      "Epoch: 2, Average Loss: 70.5911\n",
      "start predicting:  2023-12-10 03:08:15.872964\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1257\n",
      "Epoch: 3, Average Loss: 61.5079\n",
      "start predicting:  2023-12-10 03:08:15.907871\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0112\n",
      "Epoch: 4, Average Loss: 60.1344\n",
      "start predicting:  2023-12-10 03:08:15.942778\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8892\n",
      "Epoch: 5, Average Loss: 58.6708\n",
      "start predicting:  2023-12-10 03:08:15.975719\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7742\n",
      "Epoch: 6, Average Loss: 57.2908\n",
      "start predicting:  2023-12-10 03:08:16.011625\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7632\n",
      "Epoch: 7, Average Loss: 57.1580\n",
      "start predicting:  2023-12-10 03:08:16.047570\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7524\n",
      "Epoch: 8, Average Loss: 57.0287\n",
      "start predicting:  2023-12-10 03:08:16.081479\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7418\n",
      "Epoch: 9, Average Loss: 56.9022\n",
      "start predicting:  2023-12-10 03:08:16.115486\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7408\n",
      "Epoch: 10, Average Loss: 56.8897\n",
      "start predicting:  2023-12-10 03:08:16.149660\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7398\n",
      "Epoch: 11, Average Loss: 56.8775\n",
      "start predicting:  2023-12-10 03:08:16.184539\n",
      "start predicting:  2023-12-10 03:08:16.189553\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n",
      "Client 17\n",
      "start training:  2023-12-10 03:08:16.221440\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8047\n",
      "Epoch: 0, Average Loss: 81.6569\n",
      "start predicting:  2023-12-10 03:08:16.254352\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4960\n",
      "Epoch: 1, Average Loss: 77.9521\n",
      "start predicting:  2023-12-10 03:08:16.290256\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9922\n",
      "Epoch: 2, Average Loss: 71.9067\n",
      "start predicting:  2023-12-10 03:08:16.325162\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3102\n",
      "Epoch: 3, Average Loss: 63.7221\n",
      "start predicting:  2023-12-10 03:08:16.361066\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1942\n",
      "Epoch: 4, Average Loss: 62.3302\n",
      "start predicting:  2023-12-10 03:08:16.394975\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0716\n",
      "Epoch: 5, Average Loss: 60.8589\n",
      "start predicting:  2023-12-10 03:08:16.429911\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9597\n",
      "Epoch: 6, Average Loss: 59.5167\n",
      "start predicting:  2023-12-10 03:08:16.483738\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9491\n",
      "Epoch: 7, Average Loss: 59.3896\n",
      "start predicting:  2023-12-10 03:08:16.518644\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9388\n",
      "Epoch: 8, Average Loss: 59.2661\n",
      "start predicting:  2023-12-10 03:08:16.553551\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9288\n",
      "Epoch: 9, Average Loss: 59.1455\n",
      "start predicting:  2023-12-10 03:08:16.588988\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9278\n",
      "Epoch: 10, Average Loss: 59.1336\n",
      "start predicting:  2023-12-10 03:08:16.623925\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9268\n",
      "Epoch: 11, Average Loss: 59.1219\n",
      "start predicting:  2023-12-10 03:08:16.658829\n",
      "start predicting:  2023-12-10 03:08:16.665796\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 18\n",
      "start training:  2023-12-10 03:08:16.703681\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8063\n",
      "Epoch: 0, Average Loss: 81.6758\n",
      "start predicting:  2023-12-10 03:08:16.740582\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5590\n",
      "Epoch: 1, Average Loss: 78.7084\n",
      "start predicting:  2023-12-10 03:08:16.783467\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0870\n",
      "Epoch: 2, Average Loss: 73.0446\n",
      "start predicting:  2023-12-10 03:08:16.823360\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4468\n",
      "Epoch: 3, Average Loss: 65.3614\n",
      "start predicting:  2023-12-10 03:08:16.866246\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3447\n",
      "Epoch: 4, Average Loss: 64.1364\n",
      "start predicting:  2023-12-10 03:08:16.909132\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2356\n",
      "Epoch: 5, Average Loss: 62.8275\n",
      "start predicting:  2023-12-10 03:08:16.951021\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1350\n",
      "Epoch: 6, Average Loss: 61.6204\n",
      "start predicting:  2023-12-10 03:08:16.991939\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1255\n",
      "Epoch: 7, Average Loss: 61.5058\n",
      "start predicting:  2023-12-10 03:08:17.033798\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1162\n",
      "Epoch: 8, Average Loss: 61.3944\n",
      "start predicting:  2023-12-10 03:08:17.072722\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1071\n",
      "Epoch: 9, Average Loss: 61.2856\n",
      "start predicting:  2023-12-10 03:08:17.114610\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1062\n",
      "Epoch: 10, Average Loss: 61.2749\n",
      "start predicting:  2023-12-10 03:08:17.158465\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1054\n",
      "Epoch: 11, Average Loss: 61.2644\n",
      "start predicting:  2023-12-10 03:08:17.208332\n",
      "start predicting:  2023-12-10 03:08:17.214316\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 19\n",
      "start training:  2023-12-10 03:08:17.264182\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7874\n",
      "Epoch: 0, Average Loss: 81.4491\n",
      "start predicting:  2023-12-10 03:08:17.297094\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5318\n",
      "Epoch: 1, Average Loss: 78.3817\n",
      "start predicting:  2023-12-10 03:08:17.336987\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0116\n",
      "Epoch: 2, Average Loss: 72.1392\n",
      "start predicting:  2023-12-10 03:08:17.376880\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3697\n",
      "Epoch: 3, Average Loss: 64.4368\n",
      "start predicting:  2023-12-10 03:08:17.414779\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2553\n",
      "Epoch: 4, Average Loss: 63.0637\n",
      "start predicting:  2023-12-10 03:08:17.451682\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1333\n",
      "Epoch: 5, Average Loss: 61.5998\n",
      "start predicting:  2023-12-10 03:08:17.486587\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0225\n",
      "Epoch: 6, Average Loss: 60.2699\n",
      "start predicting:  2023-12-10 03:08:17.522524\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0121\n",
      "Epoch: 7, Average Loss: 60.1451\n",
      "start predicting:  2023-12-10 03:08:17.558421\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0020\n",
      "Epoch: 8, Average Loss: 60.0243\n",
      "start predicting:  2023-12-10 03:08:17.586348\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9922\n",
      "Epoch: 9, Average Loss: 59.9063\n",
      "start predicting:  2023-12-10 03:08:17.626242\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9912\n",
      "Epoch: 10, Average Loss: 59.8947\n",
      "start predicting:  2023-12-10 03:08:17.662146\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9903\n",
      "Epoch: 11, Average Loss: 59.8833\n",
      "start predicting:  2023-12-10 03:08:17.699047\n",
      "start predicting:  2023-12-10 03:08:17.706029\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Client 20\n",
      "start training:  2023-12-10 03:08:17.742902\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7678\n",
      "Epoch: 0, Average Loss: 81.2137\n",
      "start predicting:  2023-12-10 03:08:17.774817\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3888\n",
      "Epoch: 1, Average Loss: 76.6658\n",
      "start predicting:  2023-12-10 03:08:17.810720\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8223\n",
      "Epoch: 2, Average Loss: 69.8670\n",
      "start predicting:  2023-12-10 03:08:17.844629\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0529\n",
      "Epoch: 3, Average Loss: 60.6346\n",
      "start predicting:  2023-12-10 03:08:17.878498\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9323\n",
      "Epoch: 4, Average Loss: 59.1876\n",
      "start predicting:  2023-12-10 03:08:17.914402\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8028\n",
      "Epoch: 5, Average Loss: 57.6333\n",
      "start predicting:  2023-12-10 03:08:17.948312\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6823\n",
      "Epoch: 6, Average Loss: 56.1876\n",
      "start predicting:  2023-12-10 03:08:17.983246\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6708\n",
      "Epoch: 7, Average Loss: 56.0497\n",
      "start predicting:  2023-12-10 03:08:18.016159\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6596\n",
      "Epoch: 8, Average Loss: 55.9158\n",
      "start predicting:  2023-12-10 03:08:18.052620\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6487\n",
      "Epoch: 9, Average Loss: 55.7848\n",
      "start predicting:  2023-12-10 03:08:18.087527\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6477\n",
      "Epoch: 10, Average Loss: 55.7720\n",
      "start predicting:  2023-12-10 03:08:18.121619\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6466\n",
      "Epoch: 11, Average Loss: 55.7593\n",
      "start predicting:  2023-12-10 03:08:18.156440\n",
      "start predicting:  2023-12-10 03:08:18.162425\n",
      "Hit: 0.0000\n",
      "MRR: 0.0000\n",
      "Recall: 0.0000\n",
      "Average Hit: 41.6667\n",
      "Average MRR: 33.9286\n",
      "Average Recall: 41.6667\n"
     ]
    }
   ],
   "source": [
    "hit_list = []\n",
    "mrr_list = []\n",
    "recall_list = []\n",
    "\n",
    "if opt.dataset == 'diginetica':\n",
    "  n_node = 889\n",
    "else:\n",
    "  n_node = 37484\n",
    "\n",
    "#iterate over all clients\n",
    "for i in range(len(train_data)):\n",
    "  print(f\"Client {i}\")\n",
    "  train_data_i = Data(train_data[i], shuffle=True)\n",
    "  test_data_i = Data(valid_data[i], shuffle=False)\n",
    "  model = trans_to_cuda(SelfAttentionNetwork(opt, n_node))\n",
    "  train_res = train(model, train_data_i, test_data_i, opt.epoch, DEVICE)\n",
    "  loss, results = test(model, test_data_i, DEVICE)\n",
    "  hit_list.append(results['hit'])\n",
    "  mrr_list.append(results['mrr'])\n",
    "  recall_list.append(results['recall'])\n",
    "\n",
    "  #print hit and mrr for each client\n",
    "  print(f\"Hit: {results['hit']:.4f}\")\n",
    "  print(f\"MRR: {results['mrr']:.4f}\")\n",
    "  print(f\"Recall: {results['recall']:.4f}\")\n",
    "\n",
    "#print average hit and mrr over all clients\n",
    "print(f\"Average Hit: {np.mean(hit_list):.4f}\")\n",
    "print(f\"Average MRR: {np.mean(mrr_list):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(recall_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training:  2023-12-10 03:08:18.205281\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7869\n",
      "Epoch: 0, Average Loss: 81.4425\n",
      "start predicting:  2023-12-10 03:08:18.240188\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4627\n",
      "Epoch: 1, Average Loss: 77.5523\n",
      "start predicting:  2023-12-10 03:08:18.275095\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9220\n",
      "Epoch: 2, Average Loss: 71.0636\n",
      "start predicting:  2023-12-10 03:08:18.311996\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2023\n",
      "Epoch: 3, Average Loss: 62.4273\n",
      "start predicting:  2023-12-10 03:08:18.346903\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0848\n",
      "Epoch: 4, Average Loss: 61.0174\n",
      "start predicting:  2023-12-10 03:08:18.385800\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9606\n",
      "Epoch: 5, Average Loss: 59.5272\n",
      "start predicting:  2023-12-10 03:08:18.420706\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8456\n",
      "Epoch: 6, Average Loss: 58.1476\n",
      "start predicting:  2023-12-10 03:08:18.458631\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8347\n",
      "Epoch: 7, Average Loss: 58.0160\n",
      "start predicting:  2023-12-10 03:08:18.490548\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8240\n",
      "Epoch: 8, Average Loss: 57.8881\n",
      "start predicting:  2023-12-10 03:08:18.525454\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8136\n",
      "Epoch: 9, Average Loss: 57.7631\n",
      "start predicting:  2023-12-10 03:08:18.561693\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8126\n",
      "Epoch: 10, Average Loss: 57.7508\n",
      "start predicting:  2023-12-10 03:08:18.596598\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8116\n",
      "Epoch: 11, Average Loss: 57.7387\n",
      "start predicting:  2023-12-10 03:08:18.631506\n",
      "start predicting:  2023-12-10 03:08:18.637492\n",
      "Hit: 100.0000\n",
      "MRR: 100.0000\n",
      "Recall: 100.0000\n"
     ]
    }
   ],
   "source": [
    "# combine all clients train and test data\n",
    "train_data_all = []\n",
    "test_data_all = []\n",
    "for i in range(len(train_data)):\n",
    "  train_data_all += train_data[i]\n",
    "  test_data_all += valid_data[i]\n",
    "\n",
    "train_data_all = Data(train_data_all, shuffle=True)\n",
    "test_data_all = Data(test_data_all, shuffle=False)\n",
    "\n",
    "#initiate model\n",
    "model = trans_to_cuda(SelfAttentionNetwork(opt, n_node))\n",
    "\n",
    "#train model on all clients\n",
    "train_res = train(model, train_data_all, test_data_all, opt.epoch, DEVICE)\n",
    "\n",
    "#test model on all clients\n",
    "loss, results = test(model, test_data_all, DEVICE)\n",
    "\n",
    "#print hit and mrr for all clients\n",
    "print(f\"Hit: {results['hit']:.4f}\")\n",
    "print(f\"MRR: {results['mrr']:.4f}\")\n",
    "print(f\"Recall: {results['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "  def __init__(self, client_config:dict):\n",
    "    # client config as dict to make configuration dynamic\n",
    "    self.id = client_config[\"id\"]\n",
    "    self.config = client_config\n",
    "    self.__model = None\n",
    "\n",
    "    # check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "      self.device = 'cuda'\n",
    "    else:\n",
    "       self.device = 'cpu'\n",
    "\n",
    "    self.train_loader = self.config[\"train_data\"]\n",
    "    self.valid_loader = self.config[\"test_data\"]\n",
    "\n",
    "  @property\n",
    "  def model(self):\n",
    "    return self.__model\n",
    "\n",
    "  @model.setter\n",
    "  def model(self, model):\n",
    "    self.__model = model\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"Return a total size of the client's local data.\"\"\"\n",
    "    return len(self.train_loader.sampler)\n",
    "\n",
    "  def train(self):\n",
    "    model = trans_to_cuda(self.model)\n",
    "    results = train(model, self.train_loader, self.valid_loader, 1, self.device)\n",
    "    print(f\"Train result client {self.id}: {results}\")\n",
    "\n",
    "  def test(self):\n",
    "    loss,result = test(self.model, self.valid_loader, self.device)\n",
    "    print(f\"Test result client {self.id}: {loss, result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvg():\n",
    "  def __init__(self):\n",
    "    self.globalmodel = trans_to_cuda(SelfAttentionNetwork(opt, n_node))\n",
    "    self.rounds = 0\n",
    "    self.params = {}\n",
    "\n",
    "    # check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "      self.device = 'cuda'\n",
    "    else:\n",
    "       self.device = 'cpu'\n",
    "\n",
    "\n",
    "  def aggregate(self, round):\n",
    "    #v1:update the aggregate to save the model with round and date indicator\n",
    "    modelparams = []\n",
    "    for i in self.params.keys():\n",
    "      modelparams.append(self.params[i])\n",
    "\n",
    "    avg_weights = {}\n",
    "    for name in modelparams[0].keys():\n",
    "      avg_weights[name] = torch.mean(torch.stack([w[name] for w in modelparams]), dim = 0)\n",
    "\n",
    "    self.globalmodel.load_state_dict(avg_weights)\n",
    "\n",
    "    #current timestamp\n",
    "    current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    # filename = f\"{path_glob_m}/global_model_round_{round}_{current_time}.pth\"\n",
    "    # torch.save(self.globalmodel.state_dict(), filename)\n",
    "\n",
    "  def clientstrain(self, clientconfig):\n",
    "    clients = clientconfig\n",
    "    for i in clients.keys():\n",
    "      test_client = Client(clients[i])\n",
    "      test_client.model = copy.deepcopy(self.globalmodel)\n",
    "      test_client.model = trans_to_cuda(test_client.model)\n",
    "      test_client.train()\n",
    "      # test_client.test()\n",
    "      self.params[i] = test_client.model.state_dict()\n",
    "\n",
    "  def initiate_FL(self, clientconfig, serverdata):\n",
    "    clients = clientconfig\n",
    "    print(\"Round: {}\".format(self.rounds))\n",
    "\n",
    "    print(\"Obtaining Weights!!\")\n",
    "    self.clientstrain(clients)\n",
    "\n",
    "    #### Aggregate model\n",
    "    print(\"Aggregating Model!!\")\n",
    "    self.aggregate(self.rounds)\n",
    "\n",
    "    #### Replace parameters with global model parameters\n",
    "    for i in self.params.keys():\n",
    "        self.params[i] = self.globalmodel.state_dict()\n",
    "\n",
    "\n",
    "    servertest = serverdata\n",
    "    loss, results = test(self.globalmodel, servertest, self.device)\n",
    "    print(\"Round {} metrics:\".format(self.rounds))\n",
    "    print(\"Server Loss = {}\".format(loss))\n",
    "    print(\"Server Recall = {}\".format(results['recall']))\n",
    "    print(\"Round {} finished!\".format(self.rounds))\n",
    "    self.rounds += 1\n",
    "    return clients, results['recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrounds = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client: 0\n",
      "Number of batches in the dataloader train: 6\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 1\n",
      "Number of batches in the dataloader train: 18\n",
      "Number of batches in the dataloader test: 4\n",
      "client: 2\n",
      "Number of batches in the dataloader train: 2\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 3\n",
      "Number of batches in the dataloader train: 6\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 4\n",
      "Number of batches in the dataloader train: 7\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 5\n",
      "Number of batches in the dataloader train: 2\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 6\n",
      "Number of batches in the dataloader train: 1\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 7\n",
      "Number of batches in the dataloader train: 26\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 8\n",
      "Number of batches in the dataloader train: 10\n",
      "Number of batches in the dataloader test: 2\n",
      "client: 9\n",
      "Number of batches in the dataloader train: 3\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 10\n",
      "Number of batches in the dataloader train: 10\n",
      "Number of batches in the dataloader test: 2\n",
      "client: 11\n",
      "Number of batches in the dataloader train: 8\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 12\n",
      "Number of batches in the dataloader train: 7\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 13\n",
      "Number of batches in the dataloader train: 7\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 14\n",
      "Number of batches in the dataloader train: 2\n",
      "Number of batches in the dataloader test: 2\n",
      "client: 15\n",
      "Number of batches in the dataloader train: 2\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 16\n",
      "Number of batches in the dataloader train: 5\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 17\n",
      "Number of batches in the dataloader train: 5\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 18\n",
      "Number of batches in the dataloader train: 24\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 19\n",
      "Number of batches in the dataloader train: 11\n",
      "Number of batches in the dataloader test: 1\n",
      "client: 20\n",
      "Number of batches in the dataloader train: 3\n",
      "Number of batches in the dataloader test: 1\n",
      "Round: 0\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:18.779082\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7959\n",
      "Epoch: 0, Average Loss: 81.5509\n",
      "start predicting:  2023-12-10 03:08:18.819973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:18.834933\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7923\n",
      "Epoch: 0, Average Loss: 81.5077\n",
      "start predicting:  2023-12-10 03:08:18.875823\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:18.889786\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7751\n",
      "Epoch: 0, Average Loss: 81.3011\n",
      "start predicting:  2023-12-10 03:08:18.924693\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:18.937658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tori_rs\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:129: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8024\n",
      "Epoch: 0, Average Loss: 81.6292\n",
      "start predicting:  2023-12-10 03:08:18.973564\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:18.986528\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7869\n",
      "Epoch: 0, Average Loss: 81.4433\n",
      "start predicting:  2023-12-10 03:08:19.021435\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.036395\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7847\n",
      "Epoch: 0, Average Loss: 81.4167\n",
      "start predicting:  2023-12-10 03:08:19.096234\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:19.112192\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7670\n",
      "Epoch: 0, Average Loss: 81.2036\n",
      "start predicting:  2023-12-10 03:08:19.143109\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.158069\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7948\n",
      "Epoch: 0, Average Loss: 81.5379\n",
      "start predicting:  2023-12-10 03:08:19.198994\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.210959\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7924\n",
      "Epoch: 0, Average Loss: 81.5091\n",
      "start predicting:  2023-12-10 03:08:19.248858\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.261823\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7935\n",
      "Epoch: 0, Average Loss: 81.5217\n",
      "start predicting:  2023-12-10 03:08:19.295704\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.309668\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7763\n",
      "Epoch: 0, Average Loss: 81.3157\n",
      "start predicting:  2023-12-10 03:08:19.346598\n",
      "Train result client 10: {'recall': 50.0, 'hit': 50.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:19.360561\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8074\n",
      "Epoch: 0, Average Loss: 81.6885\n",
      "start predicting:  2023-12-10 03:08:19.397460\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.410426\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7889\n",
      "Epoch: 0, Average Loss: 81.4665\n",
      "start predicting:  2023-12-10 03:08:19.445337\n",
      "Train result client 12: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:19.458298\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.8006\n",
      "Epoch: 0, Average Loss: 81.6067\n",
      "start predicting:  2023-12-10 03:08:19.492179\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.505144\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7900\n",
      "Epoch: 0, Average Loss: 81.4798\n",
      "start predicting:  2023-12-10 03:08:19.536096\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:19.549055\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7749\n",
      "Epoch: 0, Average Loss: 81.2986\n",
      "start predicting:  2023-12-10 03:08:19.583934\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:19.596900\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7908\n",
      "Epoch: 0, Average Loss: 81.4896\n",
      "start predicting:  2023-12-10 03:08:19.630838\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:19.643802\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7823\n",
      "Epoch: 0, Average Loss: 81.3879\n",
      "start predicting:  2023-12-10 03:08:19.676717\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.688682\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7848\n",
      "Epoch: 0, Average Loss: 81.4175\n",
      "start predicting:  2023-12-10 03:08:19.729572\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.743507\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7913\n",
      "Epoch: 0, Average Loss: 81.4953\n",
      "start predicting:  2023-12-10 03:08:19.776448\n",
      "Train result client 19: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:19.790382\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7785\n",
      "Epoch: 0, Average Loss: 81.3422\n",
      "start predicting:  2023-12-10 03:08:19.823322\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:19.840277\n",
      "Round 0 metrics:\n",
      "Server Loss = 6.765383243560791\n",
      "Server Recall = 0.0\n",
      "Round 0 finished!\n",
      "Round: 1\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:19.852216\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7495\n",
      "Epoch: 0, Average Loss: 80.9937\n",
      "start predicting:  2023-12-10 03:08:19.884624\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:19.896620\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7382\n",
      "Epoch: 0, Average Loss: 80.8584\n",
      "start predicting:  2023-12-10 03:08:19.935516\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:19.952478\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6702\n",
      "Epoch: 0, Average Loss: 80.0424\n",
      "start predicting:  2023-12-10 03:08:19.982394\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.074145\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7143\n",
      "Epoch: 0, Average Loss: 80.5714\n",
      "start predicting:  2023-12-10 03:08:20.108026\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:20.120027\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7208\n",
      "Epoch: 0, Average Loss: 80.6496\n",
      "start predicting:  2023-12-10 03:08:20.154932\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.167868\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7007\n",
      "Epoch: 0, Average Loss: 80.4080\n",
      "start predicting:  2023-12-10 03:08:20.196819\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:20.210780\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6228\n",
      "Epoch: 0, Average Loss: 79.4734\n",
      "start predicting:  2023-12-10 03:08:20.241669\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.253637\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7515\n",
      "Epoch: 0, Average Loss: 81.0185\n",
      "start predicting:  2023-12-10 03:08:20.292561\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.308515\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7485\n",
      "Epoch: 0, Average Loss: 80.9820\n",
      "start predicting:  2023-12-10 03:08:20.343425\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.357391\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7247\n",
      "Epoch: 0, Average Loss: 80.6960\n",
      "start predicting:  2023-12-10 03:08:20.391038\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.404005\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6875\n",
      "Epoch: 0, Average Loss: 80.2502\n",
      "start predicting:  2023-12-10 03:08:20.438882\n",
      "Train result client 10: {'recall': 50.0, 'hit': 50.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:20.451876\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7654\n",
      "Epoch: 0, Average Loss: 81.1853\n",
      "start predicting:  2023-12-10 03:08:20.485758\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.499720\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7307\n",
      "Epoch: 0, Average Loss: 80.7685\n",
      "start predicting:  2023-12-10 03:08:20.539621\n",
      "Train result client 12: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:20.552606\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7744\n",
      "Epoch: 0, Average Loss: 81.2924\n",
      "start predicting:  2023-12-10 03:08:20.589961\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.602908\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7043\n",
      "Epoch: 0, Average Loss: 80.4516\n",
      "start predicting:  2023-12-10 03:08:20.635793\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:20.649755\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6372\n",
      "Epoch: 0, Average Loss: 79.6465\n",
      "start predicting:  2023-12-10 03:08:20.681703\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:20.694665\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6803\n",
      "Epoch: 0, Average Loss: 80.1641\n",
      "start predicting:  2023-12-10 03:08:20.727547\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:20.742507\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6988\n",
      "Epoch: 0, Average Loss: 80.3853\n",
      "start predicting:  2023-12-10 03:08:20.792373\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.805339\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6968\n",
      "Epoch: 0, Average Loss: 80.3613\n",
      "start predicting:  2023-12-10 03:08:20.845233\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.857228\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7345\n",
      "Epoch: 0, Average Loss: 80.8145\n",
      "start predicting:  2023-12-10 03:08:20.891138\n",
      "Train result client 19: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:20.907095\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6881\n",
      "Epoch: 0, Average Loss: 80.2567\n",
      "start predicting:  2023-12-10 03:08:20.940007\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:20.958958\n",
      "Round 1 metrics:\n",
      "Server Loss = 6.720951557159424\n",
      "Server Recall = 0.0\n",
      "Round 1 finished!\n",
      "Round: 2\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:20.970924\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7018\n",
      "Epoch: 0, Average Loss: 80.4215\n",
      "start predicting:  2023-12-10 03:08:21.005803\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:21.018769\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6737\n",
      "Epoch: 0, Average Loss: 80.0841\n",
      "start predicting:  2023-12-10 03:08:21.055698\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:21.071655\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5676\n",
      "Epoch: 0, Average Loss: 78.8106\n",
      "start predicting:  2023-12-10 03:08:21.103575\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.116506\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6073\n",
      "Epoch: 0, Average Loss: 79.2870\n",
      "start predicting:  2023-12-10 03:08:21.150473\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:21.163438\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6510\n",
      "Epoch: 0, Average Loss: 79.8123\n",
      "start predicting:  2023-12-10 03:08:21.197376\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.210341\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6145\n",
      "Epoch: 0, Average Loss: 79.3736\n",
      "start predicting:  2023-12-10 03:08:21.244222\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:21.258185\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5189\n",
      "Epoch: 0, Average Loss: 78.2264\n",
      "start predicting:  2023-12-10 03:08:21.288105\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.300073\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7110\n",
      "Epoch: 0, Average Loss: 80.5323\n",
      "start predicting:  2023-12-10 03:08:21.338985\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.351918\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6980\n",
      "Epoch: 0, Average Loss: 80.3766\n",
      "start predicting:  2023-12-10 03:08:21.387784\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.402747\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6472\n",
      "Epoch: 0, Average Loss: 79.7661\n",
      "start predicting:  2023-12-10 03:08:21.435630\n",
      "Train result client 9: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:21.447629\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6049\n",
      "Epoch: 0, Average Loss: 79.2592\n",
      "start predicting:  2023-12-10 03:08:21.483502\n",
      "Train result client 10: {'recall': 50.0, 'hit': 50.0, 'mrr': 16.666666666666664}\n",
      "start training:  2023-12-10 03:08:21.496487\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7355\n",
      "Epoch: 0, Average Loss: 80.8259\n",
      "start predicting:  2023-12-10 03:08:21.530377\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.544368\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6681\n",
      "Epoch: 0, Average Loss: 80.0168\n",
      "start predicting:  2023-12-10 03:08:21.580243\n",
      "Train result client 12: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:21.619166\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.7345\n",
      "Epoch: 0, Average Loss: 80.8137\n",
      "start predicting:  2023-12-10 03:08:21.654046\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.670034\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6195\n",
      "Epoch: 0, Average Loss: 79.4341\n",
      "start predicting:  2023-12-10 03:08:21.699924\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:21.715881\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5262\n",
      "Epoch: 0, Average Loss: 78.3139\n",
      "start predicting:  2023-12-10 03:08:21.745801\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:21.760761\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5881\n",
      "Epoch: 0, Average Loss: 79.0568\n",
      "start predicting:  2023-12-10 03:08:21.792675\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:21.805641\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6363\n",
      "Epoch: 0, Average Loss: 79.6356\n",
      "start predicting:  2023-12-10 03:08:21.838202\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.852167\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6303\n",
      "Epoch: 0, Average Loss: 79.5631\n",
      "start predicting:  2023-12-10 03:08:21.893056\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:21.904995\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6805\n",
      "Epoch: 0, Average Loss: 80.1656\n",
      "start predicting:  2023-12-10 03:08:21.938904\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:21.954068\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6317\n",
      "Epoch: 0, Average Loss: 79.5801\n",
      "start predicting:  2023-12-10 03:08:21.987007\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:22.005932\n",
      "Round 2 metrics:\n",
      "Server Loss = 6.695115566253662\n",
      "Server Recall = 0.0\n",
      "Round 2 finished!\n",
      "Round: 3\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:22.017901\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6542\n",
      "Epoch: 0, Average Loss: 79.8503\n",
      "start predicting:  2023-12-10 03:08:22.052807\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:22.064775\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6087\n",
      "Epoch: 0, Average Loss: 79.3039\n",
      "start predicting:  2023-12-10 03:08:22.103032\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 31.25}\n",
      "start training:  2023-12-10 03:08:22.117992\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4620\n",
      "Epoch: 0, Average Loss: 77.5438\n",
      "start predicting:  2023-12-10 03:08:22.152905\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.165869\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5102\n",
      "Epoch: 0, Average Loss: 78.1228\n",
      "start predicting:  2023-12-10 03:08:22.198813\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:22.213741\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5838\n",
      "Epoch: 0, Average Loss: 79.0060\n",
      "start predicting:  2023-12-10 03:08:22.248677\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.260645\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5221\n",
      "Epoch: 0, Average Loss: 78.2652\n",
      "start predicting:  2023-12-10 03:08:22.293529\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:22.306494\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3981\n",
      "Epoch: 0, Average Loss: 76.7775\n",
      "start predicting:  2023-12-10 03:08:22.335417\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.347414\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6619\n",
      "Epoch: 0, Average Loss: 79.9424\n",
      "start predicting:  2023-12-10 03:08:22.389302\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.402267\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6466\n",
      "Epoch: 0, Average Loss: 79.7588\n",
      "start predicting:  2023-12-10 03:08:22.440172\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.453130\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5739\n",
      "Epoch: 0, Average Loss: 78.8871\n",
      "start predicting:  2023-12-10 03:08:22.487742\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.501706\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5060\n",
      "Epoch: 0, Average Loss: 78.0719\n",
      "start predicting:  2023-12-10 03:08:22.541599\n",
      "Train result client 10: {'recall': 50.0, 'hit': 50.0, 'mrr': 16.666666666666664}\n",
      "start training:  2023-12-10 03:08:22.560577\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6936\n",
      "Epoch: 0, Average Loss: 80.3232\n",
      "start predicting:  2023-12-10 03:08:22.597449\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.610415\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6004\n",
      "Epoch: 0, Average Loss: 79.2048\n",
      "start predicting:  2023-12-10 03:08:22.645801\n",
      "Train result client 12: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:22.659735\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6877\n",
      "Epoch: 0, Average Loss: 80.2519\n",
      "start predicting:  2023-12-10 03:08:22.695639\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.707635\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5392\n",
      "Epoch: 0, Average Loss: 78.4701\n",
      "start predicting:  2023-12-10 03:08:22.739551\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:22.754482\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4422\n",
      "Epoch: 0, Average Loss: 77.3060\n",
      "start predicting:  2023-12-10 03:08:22.785427\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:22.800390\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4849\n",
      "Epoch: 0, Average Loss: 77.8186\n",
      "start predicting:  2023-12-10 03:08:22.831276\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:22.845240\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5666\n",
      "Epoch: 0, Average Loss: 78.7995\n",
      "start predicting:  2023-12-10 03:08:22.879176\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.892142\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5476\n",
      "Epoch: 0, Average Loss: 78.5717\n",
      "start predicting:  2023-12-10 03:08:22.931039\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:22.944972\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6382\n",
      "Epoch: 0, Average Loss: 79.6586\n",
      "start predicting:  2023-12-10 03:08:22.992873\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:23.004812\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5330\n",
      "Epoch: 0, Average Loss: 78.3964\n",
      "start predicting:  2023-12-10 03:08:23.038750\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:23.056712\n",
      "Round 3 metrics:\n",
      "Server Loss = 6.641557693481445\n",
      "Server Recall = 0.0\n",
      "Round 3 finished!\n",
      "Round: 4\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:23.070668\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5967\n",
      "Epoch: 0, Average Loss: 79.1598\n",
      "start predicting:  2023-12-10 03:08:23.103576\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:23.115545\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5302\n",
      "Epoch: 0, Average Loss: 78.3629\n",
      "start predicting:  2023-12-10 03:08:23.158430\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:23.172399\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3399\n",
      "Epoch: 0, Average Loss: 76.0788\n",
      "start predicting:  2023-12-10 03:08:23.204308\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.217244\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3618\n",
      "Epoch: 0, Average Loss: 76.3415\n",
      "start predicting:  2023-12-10 03:08:23.250238\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:23.264172\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4832\n",
      "Epoch: 0, Average Loss: 77.7983\n",
      "start predicting:  2023-12-10 03:08:23.298081\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.311047\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4165\n",
      "Epoch: 0, Average Loss: 76.9982\n",
      "start predicting:  2023-12-10 03:08:23.343988\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:23.356956\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2445\n",
      "Epoch: 0, Average Loss: 74.9337\n",
      "start predicting:  2023-12-10 03:08:23.388867\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.401804\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6000\n",
      "Epoch: 0, Average Loss: 79.2002\n",
      "start predicting:  2023-12-10 03:08:23.439985\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.451954\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5792\n",
      "Epoch: 0, Average Loss: 78.9499\n",
      "start predicting:  2023-12-10 03:08:23.487827\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.500792\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4735\n",
      "Epoch: 0, Average Loss: 77.6821\n",
      "start predicting:  2023-12-10 03:08:23.533777\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.546711\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3765\n",
      "Epoch: 0, Average Loss: 76.5179\n",
      "start predicting:  2023-12-10 03:08:23.583641\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 26.666666666666668}\n",
      "start training:  2023-12-10 03:08:23.597604\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6254\n",
      "Epoch: 0, Average Loss: 79.5046\n",
      "start predicting:  2023-12-10 03:08:23.633479\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.646444\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5160\n",
      "Epoch: 0, Average Loss: 78.1919\n",
      "start predicting:  2023-12-10 03:08:23.682756\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.696718\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.6204\n",
      "Epoch: 0, Average Loss: 79.4448\n",
      "start predicting:  2023-12-10 03:08:23.729659\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.743624\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4353\n",
      "Epoch: 0, Average Loss: 77.2233\n",
      "start predicting:  2023-12-10 03:08:23.774511\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:23.788473\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2929\n",
      "Epoch: 0, Average Loss: 75.5146\n",
      "start predicting:  2023-12-10 03:08:23.823413\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:23.835376\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3344\n",
      "Epoch: 0, Average Loss: 76.0126\n",
      "start predicting:  2023-12-10 03:08:23.869286\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:23.881254\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4853\n",
      "Epoch: 0, Average Loss: 77.8239\n",
      "start predicting:  2023-12-10 03:08:23.915134\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.928132\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4522\n",
      "Epoch: 0, Average Loss: 77.4270\n",
      "start predicting:  2023-12-10 03:08:23.969018\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:23.982953\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5742\n",
      "Epoch: 0, Average Loss: 78.8900\n",
      "start predicting:  2023-12-10 03:08:24.045784\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:24.060745\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4272\n",
      "Epoch: 0, Average Loss: 77.1263\n",
      "start predicting:  2023-12-10 03:08:24.119587\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:24.136542\n",
      "Round 4 metrics:\n",
      "Server Loss = 6.590841293334961\n",
      "Server Recall = 0.0\n",
      "Round 4 finished!\n",
      "Round: 5\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:24.148510\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5145\n",
      "Epoch: 0, Average Loss: 78.1745\n",
      "start predicting:  2023-12-10 03:08:24.181421\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:24.194388\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4244\n",
      "Epoch: 0, Average Loss: 77.0929\n",
      "start predicting:  2023-12-10 03:08:24.238270\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:24.251235\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1987\n",
      "Epoch: 0, Average Loss: 74.3838\n",
      "start predicting:  2023-12-10 03:08:24.287139\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.299136\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2006\n",
      "Epoch: 0, Average Loss: 74.4070\n",
      "start predicting:  2023-12-10 03:08:24.333016\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:24.349998\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3631\n",
      "Epoch: 0, Average Loss: 76.3574\n",
      "start predicting:  2023-12-10 03:08:24.382116\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.397105\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2433\n",
      "Epoch: 0, Average Loss: 74.9198\n",
      "start predicting:  2023-12-10 03:08:24.432981\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:24.446973\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0548\n",
      "Epoch: 0, Average Loss: 72.6573\n",
      "start predicting:  2023-12-10 03:08:24.479855\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.493817\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5292\n",
      "Epoch: 0, Average Loss: 78.3509\n",
      "start predicting:  2023-12-10 03:08:24.537700\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.550665\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4934\n",
      "Epoch: 0, Average Loss: 77.9212\n",
      "start predicting:  2023-12-10 03:08:24.589590\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.602555\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3680\n",
      "Epoch: 0, Average Loss: 76.4162\n",
      "start predicting:  2023-12-10 03:08:24.636464\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.648404\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2286\n",
      "Epoch: 0, Average Loss: 74.7437\n",
      "start predicting:  2023-12-10 03:08:24.684402\n",
      "Train result client 10: {'recall': 50.0, 'hit': 50.0, 'mrr': 16.666666666666664}\n",
      "start training:  2023-12-10 03:08:24.697395\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5605\n",
      "Epoch: 0, Average Loss: 78.7259\n",
      "start predicting:  2023-12-10 03:08:24.732273\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.745264\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4204\n",
      "Epoch: 0, Average Loss: 77.0445\n",
      "start predicting:  2023-12-10 03:08:24.780145\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.794137\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.5483\n",
      "Epoch: 0, Average Loss: 78.5800\n",
      "start predicting:  2023-12-10 03:08:24.830012\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:24.843975\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3096\n",
      "Epoch: 0, Average Loss: 75.7155\n",
      "start predicting:  2023-12-10 03:08:24.880876\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:24.895836\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1210\n",
      "Epoch: 0, Average Loss: 73.4522\n",
      "start predicting:  2023-12-10 03:08:24.928748\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:24.941713\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1540\n",
      "Epoch: 0, Average Loss: 73.8484\n",
      "start predicting:  2023-12-10 03:08:24.972732\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:24.984700\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3700\n",
      "Epoch: 0, Average Loss: 76.4397\n",
      "start predicting:  2023-12-10 03:08:25.017612\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.030576\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3157\n",
      "Epoch: 0, Average Loss: 75.7882\n",
      "start predicting:  2023-12-10 03:08:25.071495\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.084433\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4949\n",
      "Epoch: 0, Average Loss: 77.9383\n",
      "start predicting:  2023-12-10 03:08:25.121363\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:25.133330\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2946\n",
      "Epoch: 0, Average Loss: 75.5355\n",
      "start predicting:  2023-12-10 03:08:25.170202\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:25.189181\n",
      "Round 5 metrics:\n",
      "Server Loss = 6.491121768951416\n",
      "Server Recall = 0.0\n",
      "Round 5 finished!\n",
      "Round: 6\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:25.202117\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4212\n",
      "Epoch: 0, Average Loss: 77.0543\n",
      "start predicting:  2023-12-10 03:08:25.237053\n",
      "Train result client 0: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:25.249020\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2976\n",
      "Epoch: 0, Average Loss: 75.5715\n",
      "start predicting:  2023-12-10 03:08:25.291908\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:25.307863\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0123\n",
      "Epoch: 0, Average Loss: 72.1478\n",
      "start predicting:  2023-12-10 03:08:25.337755\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.352715\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9832\n",
      "Epoch: 0, Average Loss: 71.7989\n",
      "start predicting:  2023-12-10 03:08:25.383663\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:25.398617\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2079\n",
      "Epoch: 0, Average Loss: 74.4943\n",
      "start predicting:  2023-12-10 03:08:25.436518\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.449488\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0907\n",
      "Epoch: 0, Average Loss: 73.0883\n",
      "start predicting:  2023-12-10 03:08:25.483396\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:25.497327\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7849\n",
      "Epoch: 0, Average Loss: 69.4193\n",
      "start predicting:  2023-12-10 03:08:25.528275\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.541239\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4270\n",
      "Epoch: 0, Average Loss: 77.1236\n",
      "start predicting:  2023-12-10 03:08:25.579139\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.595066\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3919\n",
      "Epoch: 0, Average Loss: 76.7033\n",
      "start predicting:  2023-12-10 03:08:25.633963\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.662886\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1887\n",
      "Epoch: 0, Average Loss: 74.2645\n",
      "start predicting:  2023-12-10 03:08:25.698790\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.731701\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0372\n",
      "Epoch: 0, Average Loss: 72.4464\n",
      "start predicting:  2023-12-10 03:08:25.770628\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 26.666666666666668}\n",
      "start training:  2023-12-10 03:08:25.786554\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4582\n",
      "Epoch: 0, Average Loss: 77.4988\n",
      "start predicting:  2023-12-10 03:08:25.823456\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.836422\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2880\n",
      "Epoch: 0, Average Loss: 75.4560\n",
      "start predicting:  2023-12-10 03:08:25.874351\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.887314\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.4556\n",
      "Epoch: 0, Average Loss: 77.4666\n",
      "start predicting:  2023-12-10 03:08:25.922222\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:25.935158\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1356\n",
      "Epoch: 0, Average Loss: 73.6267\n",
      "start predicting:  2023-12-10 03:08:25.968069\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:25.981060\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9077\n",
      "Epoch: 0, Average Loss: 70.8919\n",
      "start predicting:  2023-12-10 03:08:26.012974\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:26.027938\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9159\n",
      "Epoch: 0, Average Loss: 70.9906\n",
      "start predicting:  2023-12-10 03:08:26.062870\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:26.078859\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2512\n",
      "Epoch: 0, Average Loss: 75.0144\n",
      "start predicting:  2023-12-10 03:08:26.112032\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.125994\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1741\n",
      "Epoch: 0, Average Loss: 74.0891\n",
      "start predicting:  2023-12-10 03:08:26.166857\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.179849\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3882\n",
      "Epoch: 0, Average Loss: 76.6584\n",
      "start predicting:  2023-12-10 03:08:26.214757\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:26.227723\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1411\n",
      "Epoch: 0, Average Loss: 73.6927\n",
      "start predicting:  2023-12-10 03:08:26.259607\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:26.277588\n",
      "Round 6 metrics:\n",
      "Server Loss = 6.412519454956055\n",
      "Server Recall = 0.0\n",
      "Round 6 finished!\n",
      "Round: 7\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:26.289556\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3038\n",
      "Epoch: 0, Average Loss: 75.6458\n",
      "start predicting:  2023-12-10 03:08:26.324463\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.337400\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1491\n",
      "Epoch: 0, Average Loss: 73.7892\n",
      "start predicting:  2023-12-10 03:08:26.378290\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:26.395244\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8031\n",
      "Epoch: 0, Average Loss: 69.6377\n",
      "start predicting:  2023-12-10 03:08:26.427159\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.439127\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7463\n",
      "Epoch: 0, Average Loss: 68.9552\n",
      "start predicting:  2023-12-10 03:08:26.475031\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:26.487996\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0331\n",
      "Epoch: 0, Average Loss: 72.3967\n",
      "start predicting:  2023-12-10 03:08:26.524927\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.539858\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8638\n",
      "Epoch: 0, Average Loss: 70.3656\n",
      "start predicting:  2023-12-10 03:08:26.571772\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:26.584739\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5515\n",
      "Epoch: 0, Average Loss: 66.6181\n",
      "start predicting:  2023-12-10 03:08:26.616683\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.630616\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3223\n",
      "Epoch: 0, Average Loss: 75.8681\n",
      "start predicting:  2023-12-10 03:08:26.673529\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.686466\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2628\n",
      "Epoch: 0, Average Loss: 75.1540\n",
      "start predicting:  2023-12-10 03:08:26.724394\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.737359\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0083\n",
      "Epoch: 0, Average Loss: 72.0995\n",
      "start predicting:  2023-12-10 03:08:26.771269\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.783238\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8190\n",
      "Epoch: 0, Average Loss: 69.8279\n",
      "start predicting:  2023-12-10 03:08:26.816119\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 29.166666666666664}\n",
      "start training:  2023-12-10 03:08:26.830111\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3518\n",
      "Epoch: 0, Average Loss: 76.2218\n",
      "start predicting:  2023-12-10 03:08:26.863991\n",
      "Train result client 11: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.879978\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1277\n",
      "Epoch: 0, Average Loss: 73.5326\n",
      "start predicting:  2023-12-10 03:08:26.916849\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.929840\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.3513\n",
      "Epoch: 0, Average Loss: 76.2152\n",
      "start predicting:  2023-12-10 03:08:26.963753\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:26.977687\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9848\n",
      "Epoch: 0, Average Loss: 71.8176\n",
      "start predicting:  2023-12-10 03:08:27.010599\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:27.024590\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6621\n",
      "Epoch: 0, Average Loss: 67.9452\n",
      "start predicting:  2023-12-10 03:08:27.055508\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:27.067454\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6661\n",
      "Epoch: 0, Average Loss: 67.9931\n",
      "start predicting:  2023-12-10 03:08:27.099499\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:27.114460\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0922\n",
      "Epoch: 0, Average Loss: 73.1070\n",
      "start predicting:  2023-12-10 03:08:27.190257\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.204220\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9824\n",
      "Epoch: 0, Average Loss: 71.7884\n",
      "start predicting:  2023-12-10 03:08:27.247105\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.261067\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2766\n",
      "Epoch: 0, Average Loss: 75.3195\n",
      "start predicting:  2023-12-10 03:08:27.295974\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:27.308939\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9230\n",
      "Epoch: 0, Average Loss: 71.0760\n",
      "start predicting:  2023-12-10 03:08:27.340854\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:27.357808\n",
      "Round 7 metrics:\n",
      "Server Loss = 6.333868026733398\n",
      "Server Recall = 0.0\n",
      "Round 7 finished!\n",
      "Round: 8\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:27.370774\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1622\n",
      "Epoch: 0, Average Loss: 73.9462\n",
      "start predicting:  2023-12-10 03:08:27.406678\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.419644\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9802\n",
      "Epoch: 0, Average Loss: 71.7625\n",
      "start predicting:  2023-12-10 03:08:27.459565\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:27.472531\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5455\n",
      "Epoch: 0, Average Loss: 66.5462\n",
      "start predicting:  2023-12-10 03:08:27.506440\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.519405\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4452\n",
      "Epoch: 0, Average Loss: 65.3425\n",
      "start predicting:  2023-12-10 03:08:27.554309\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:27.567249\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8388\n",
      "Epoch: 0, Average Loss: 70.0653\n",
      "start predicting:  2023-12-10 03:08:27.603152\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.616118\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6360\n",
      "Epoch: 0, Average Loss: 67.6323\n",
      "start predicting:  2023-12-10 03:08:27.649030\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:27.664009\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1701\n",
      "Epoch: 0, Average Loss: 62.0410\n",
      "start predicting:  2023-12-10 03:08:27.692912\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.705907\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2005\n",
      "Epoch: 0, Average Loss: 74.4055\n",
      "start predicting:  2023-12-10 03:08:27.746802\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.760760\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1180\n",
      "Epoch: 0, Average Loss: 73.4163\n",
      "start predicting:  2023-12-10 03:08:27.798660\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.812592\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8082\n",
      "Epoch: 0, Average Loss: 69.6990\n",
      "start predicting:  2023-12-10 03:08:27.847499\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:27.863485\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5606\n",
      "Epoch: 0, Average Loss: 66.7271\n",
      "start predicting:  2023-12-10 03:08:27.897395\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 29.166666666666664}\n",
      "start training:  2023-12-10 03:08:27.914349\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2382\n",
      "Epoch: 0, Average Loss: 74.8579\n",
      "start predicting:  2023-12-10 03:08:27.949256\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:27.963219\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9409\n",
      "Epoch: 0, Average Loss: 71.2910\n",
      "start predicting:  2023-12-10 03:08:27.998096\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.011062\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.2322\n",
      "Epoch: 0, Average Loss: 74.7858\n",
      "start predicting:  2023-12-10 03:08:28.045000\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.057968\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7454\n",
      "Epoch: 0, Average Loss: 68.9450\n",
      "start predicting:  2023-12-10 03:08:28.088854\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:28.102845\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4021\n",
      "Epoch: 0, Average Loss: 64.8252\n",
      "start predicting:  2023-12-10 03:08:28.132773\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:28.144732\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3684\n",
      "Epoch: 0, Average Loss: 64.4212\n",
      "start predicting:  2023-12-10 03:08:28.175621\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:28.188587\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9337\n",
      "Epoch: 0, Average Loss: 71.2044\n",
      "start predicting:  2023-12-10 03:08:28.221528\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.234464\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7939\n",
      "Epoch: 0, Average Loss: 69.5270\n",
      "start predicting:  2023-12-10 03:08:28.275355\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.288346\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1694\n",
      "Epoch: 0, Average Loss: 74.0325\n",
      "start predicting:  2023-12-10 03:08:28.322230\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:28.335196\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7209\n",
      "Epoch: 0, Average Loss: 68.6507\n",
      "start predicting:  2023-12-10 03:08:28.368107\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:28.385063\n",
      "Round 8 metrics:\n",
      "Server Loss = 6.187386512756348\n",
      "Server Recall = 0.0\n",
      "Round 8 finished!\n",
      "Round: 9\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:28.397061\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0331\n",
      "Epoch: 0, Average Loss: 72.3976\n",
      "start predicting:  2023-12-10 03:08:28.431936\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.445899\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7902\n",
      "Epoch: 0, Average Loss: 69.4822\n",
      "start predicting:  2023-12-10 03:08:28.484795\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:28.497789\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2851\n",
      "Epoch: 0, Average Loss: 63.4211\n",
      "start predicting:  2023-12-10 03:08:28.532667\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.544636\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1262\n",
      "Epoch: 0, Average Loss: 61.5141\n",
      "start predicting:  2023-12-10 03:08:28.578544\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:28.591510\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6317\n",
      "Epoch: 0, Average Loss: 67.5799\n",
      "start predicting:  2023-12-10 03:08:28.627442\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.640407\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3713\n",
      "Epoch: 0, Average Loss: 64.4556\n",
      "start predicting:  2023-12-10 03:08:28.675314\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:28.687253\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8735\n",
      "Epoch: 0, Average Loss: 58.4824\n",
      "start predicting:  2023-12-10 03:08:28.719200\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.731164\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0752\n",
      "Epoch: 0, Average Loss: 72.9023\n",
      "start predicting:  2023-12-10 03:08:28.773327\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.787289\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9639\n",
      "Epoch: 0, Average Loss: 71.5673\n",
      "start predicting:  2023-12-10 03:08:28.822196\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.838154\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5907\n",
      "Epoch: 0, Average Loss: 67.0882\n",
      "start predicting:  2023-12-10 03:08:28.911928\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:28.928883\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2930\n",
      "Epoch: 0, Average Loss: 63.5162\n",
      "start predicting:  2023-12-10 03:08:28.970770\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 29.166666666666664}\n",
      "start training:  2023-12-10 03:08:28.983736\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1104\n",
      "Epoch: 0, Average Loss: 73.3249\n",
      "start predicting:  2023-12-10 03:08:29.019640\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:29.034600\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7625\n",
      "Epoch: 0, Average Loss: 69.1496\n",
      "start predicting:  2023-12-10 03:08:29.069763\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.085691\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.1060\n",
      "Epoch: 0, Average Loss: 73.2725\n",
      "start predicting:  2023-12-10 03:08:29.121596\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.133592\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5312\n",
      "Epoch: 0, Average Loss: 66.3743\n",
      "start predicting:  2023-12-10 03:08:29.165487\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:29.178443\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0859\n",
      "Epoch: 0, Average Loss: 61.0314\n",
      "start predicting:  2023-12-10 03:08:29.210387\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:29.223352\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0481\n",
      "Epoch: 0, Average Loss: 60.5768\n",
      "start predicting:  2023-12-10 03:08:29.255267\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:29.269201\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7632\n",
      "Epoch: 0, Average Loss: 69.1586\n",
      "start predicting:  2023-12-10 03:08:29.300830\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.313782\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5645\n",
      "Epoch: 0, Average Loss: 66.7738\n",
      "start predicting:  2023-12-10 03:08:29.355670\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.368607\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 6.0086\n",
      "Epoch: 0, Average Loss: 72.1027\n",
      "start predicting:  2023-12-10 03:08:29.404510\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:29.416478\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5100\n",
      "Epoch: 0, Average Loss: 66.1196\n",
      "start predicting:  2023-12-10 03:08:29.449419\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:29.466374\n",
      "Round 9 metrics:\n",
      "Server Loss = 6.103254318237305\n",
      "Server Recall = 0.0\n",
      "Round 9 finished!\n",
      "Round: 10\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:29.482329\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8557\n",
      "Epoch: 0, Average Loss: 70.2685\n",
      "start predicting:  2023-12-10 03:08:29.516240\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.531200\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5846\n",
      "Epoch: 0, Average Loss: 67.0147\n",
      "start predicting:  2023-12-10 03:08:29.571094\n",
      "Train result client 1: {'recall': 50.0, 'hit': 50.0, 'mrr': 30.0}\n",
      "start training:  2023-12-10 03:08:29.586056\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9969\n",
      "Epoch: 0, Average Loss: 59.9631\n",
      "start predicting:  2023-12-10 03:08:29.616971\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.629936\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7729\n",
      "Epoch: 0, Average Loss: 57.2745\n",
      "start predicting:  2023-12-10 03:08:29.662850\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:29.676811\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3882\n",
      "Epoch: 0, Average Loss: 64.6586\n",
      "start predicting:  2023-12-10 03:08:29.713684\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.727674\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0832\n",
      "Epoch: 0, Average Loss: 60.9987\n",
      "start predicting:  2023-12-10 03:08:29.759592\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:29.772527\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5683\n",
      "Epoch: 0, Average Loss: 54.8202\n",
      "start predicting:  2023-12-10 03:08:29.800482\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.815440\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9312\n",
      "Epoch: 0, Average Loss: 71.1746\n",
      "start predicting:  2023-12-10 03:08:29.856332\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.869296\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7936\n",
      "Epoch: 0, Average Loss: 69.5227\n",
      "start predicting:  2023-12-10 03:08:29.906201\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.941104\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3115\n",
      "Epoch: 0, Average Loss: 63.7385\n",
      "start predicting:  2023-12-10 03:08:29.976027\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:29.988976\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9782\n",
      "Epoch: 0, Average Loss: 59.7385\n",
      "start predicting:  2023-12-10 03:08:30.024884\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:30.037848\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9716\n",
      "Epoch: 0, Average Loss: 71.6588\n",
      "start predicting:  2023-12-10 03:08:30.074752\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:30.087683\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5350\n",
      "Epoch: 0, Average Loss: 66.4202\n",
      "start predicting:  2023-12-10 03:08:30.124404\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.136372\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.9593\n",
      "Epoch: 0, Average Loss: 71.5122\n",
      "start predicting:  2023-12-10 03:08:30.173274\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.186239\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2824\n",
      "Epoch: 0, Average Loss: 63.3887\n",
      "start predicting:  2023-12-10 03:08:30.217156\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:30.231120\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7647\n",
      "Epoch: 0, Average Loss: 57.1763\n",
      "start predicting:  2023-12-10 03:08:30.263033\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:30.275999\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7035\n",
      "Epoch: 0, Average Loss: 56.4417\n",
      "start predicting:  2023-12-10 03:08:30.308911\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:30.322329\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5760\n",
      "Epoch: 0, Average Loss: 66.9114\n",
      "start predicting:  2023-12-10 03:08:30.355270\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.367235\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3084\n",
      "Epoch: 0, Average Loss: 63.7005\n",
      "start predicting:  2023-12-10 03:08:30.408128\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.420099\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8594\n",
      "Epoch: 0, Average Loss: 70.3126\n",
      "start predicting:  2023-12-10 03:08:30.454974\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:30.467940\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2437\n",
      "Epoch: 0, Average Loss: 62.9241\n",
      "start predicting:  2023-12-10 03:08:30.499883\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:30.517807\n",
      "Round 10 metrics:\n",
      "Server Loss = 5.9876484870910645\n",
      "Server Recall = 0.0\n",
      "Round 10 finished!\n",
      "Round: 11\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:30.530772\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7328\n",
      "Epoch: 0, Average Loss: 68.7932\n",
      "start predicting:  2023-12-10 03:08:30.562715\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.578673\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3855\n",
      "Epoch: 0, Average Loss: 64.6261\n",
      "start predicting:  2023-12-10 03:08:30.616542\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:30.630506\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6568\n",
      "Epoch: 0, Average Loss: 55.8814\n",
      "start predicting:  2023-12-10 03:08:30.661456\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.673422\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3762\n",
      "Epoch: 0, Average Loss: 52.5150\n",
      "start predicting:  2023-12-10 03:08:30.707301\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:30.720294\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1427\n",
      "Epoch: 0, Average Loss: 61.7120\n",
      "start predicting:  2023-12-10 03:08:30.755172\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.769136\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7824\n",
      "Epoch: 0, Average Loss: 57.3894\n",
      "start predicting:  2023-12-10 03:08:30.800052\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:30.814041\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0510\n",
      "Epoch: 0, Average Loss: 48.6116\n",
      "start predicting:  2023-12-10 03:08:30.846959\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.860889\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7887\n",
      "Epoch: 0, Average Loss: 69.4646\n",
      "start predicting:  2023-12-10 03:08:30.900807\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.913773\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6451\n",
      "Epoch: 0, Average Loss: 67.7411\n",
      "start predicting:  2023-12-10 03:08:30.947683\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:30.964609\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0383\n",
      "Epoch: 0, Average Loss: 60.4596\n",
      "start predicting:  2023-12-10 03:08:31.014504\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.027469\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6358\n",
      "Epoch: 0, Average Loss: 55.6291\n",
      "start predicting:  2023-12-10 03:08:31.065369\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:31.078333\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8023\n",
      "Epoch: 0, Average Loss: 69.6272\n",
      "start predicting:  2023-12-10 03:08:31.113669\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:31.128631\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3358\n",
      "Epoch: 0, Average Loss: 64.0300\n",
      "start predicting:  2023-12-10 03:08:31.164535\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.177500\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8365\n",
      "Epoch: 0, Average Loss: 70.0374\n",
      "start predicting:  2023-12-10 03:08:31.212405\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.226371\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0738\n",
      "Epoch: 0, Average Loss: 60.8854\n",
      "start predicting:  2023-12-10 03:08:31.256260\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:31.270252\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3588\n",
      "Epoch: 0, Average Loss: 52.3053\n",
      "start predicting:  2023-12-10 03:08:31.305158\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:31.317097\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.2637\n",
      "Epoch: 0, Average Loss: 51.1638\n",
      "start predicting:  2023-12-10 03:08:31.353002\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:31.366964\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3769\n",
      "Epoch: 0, Average Loss: 64.5229\n",
      "start predicting:  2023-12-10 03:08:31.439769\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.453761\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0522\n",
      "Epoch: 0, Average Loss: 60.6259\n",
      "start predicting:  2023-12-10 03:08:31.492627\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.504596\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7023\n",
      "Epoch: 0, Average Loss: 68.4277\n",
      "start predicting:  2023-12-10 03:08:31.542372\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:31.554341\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9556\n",
      "Epoch: 0, Average Loss: 59.4668\n",
      "start predicting:  2023-12-10 03:08:31.590216\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:31.607199\n",
      "Round 11 metrics:\n",
      "Server Loss = 5.911597728729248\n",
      "Server Recall = 0.0\n",
      "Round 11 finished!\n",
      "Round: 12\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:31.619167\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5876\n",
      "Epoch: 0, Average Loss: 67.0517\n",
      "start predicting:  2023-12-10 03:08:31.653078\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.669037\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1745\n",
      "Epoch: 0, Average Loss: 62.0943\n",
      "start predicting:  2023-12-10 03:08:31.707929\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:31.721892\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3591\n",
      "Epoch: 0, Average Loss: 52.3095\n",
      "start predicting:  2023-12-10 03:08:31.755801\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.767769\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.9907\n",
      "Epoch: 0, Average Loss: 47.8889\n",
      "start predicting:  2023-12-10 03:08:31.827610\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:31.842569\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8819\n",
      "Epoch: 0, Average Loss: 58.5823\n",
      "start predicting:  2023-12-10 03:08:31.877476\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.890445\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4735\n",
      "Epoch: 0, Average Loss: 53.6825\n",
      "start predicting:  2023-12-10 03:08:31.923355\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:31.935322\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.6786\n",
      "Epoch: 0, Average Loss: 44.1437\n",
      "start predicting:  2023-12-10 03:08:31.965213\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:31.978207\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6476\n",
      "Epoch: 0, Average Loss: 67.7709\n",
      "start predicting:  2023-12-10 03:08:32.023086\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.036024\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4723\n",
      "Epoch: 0, Average Loss: 65.6677\n",
      "start predicting:  2023-12-10 03:08:32.072953\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.085891\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7639\n",
      "Epoch: 0, Average Loss: 57.1672\n",
      "start predicting:  2023-12-10 03:08:32.118839\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.131767\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3094\n",
      "Epoch: 0, Average Loss: 51.7131\n",
      "start predicting:  2023-12-10 03:08:32.166061\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:32.180056\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6829\n",
      "Epoch: 0, Average Loss: 68.1944\n",
      "start predicting:  2023-12-10 03:08:32.214931\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:32.228922\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1220\n",
      "Epoch: 0, Average Loss: 61.4641\n",
      "start predicting:  2023-12-10 03:08:32.264826\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.277792\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7080\n",
      "Epoch: 0, Average Loss: 68.4959\n",
      "start predicting:  2023-12-10 03:08:32.313698\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.326658\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7885\n",
      "Epoch: 0, Average Loss: 57.4620\n",
      "start predicting:  2023-12-10 03:08:32.360571\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:32.373507\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0214\n",
      "Epoch: 0, Average Loss: 48.2567\n",
      "start predicting:  2023-12-10 03:08:32.407445\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:32.420411\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8763\n",
      "Epoch: 0, Average Loss: 46.5157\n",
      "start predicting:  2023-12-10 03:08:32.455317\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:32.468254\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2003\n",
      "Epoch: 0, Average Loss: 62.4033\n",
      "start predicting:  2023-12-10 03:08:32.503188\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.516154\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8024\n",
      "Epoch: 0, Average Loss: 57.6292\n",
      "start predicting:  2023-12-10 03:08:32.556019\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.568985\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5516\n",
      "Epoch: 0, Average Loss: 66.6191\n",
      "start predicting:  2023-12-10 03:08:32.605915\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:32.619876\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7111\n",
      "Epoch: 0, Average Loss: 56.5329\n",
      "start predicting:  2023-12-10 03:08:32.652761\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:32.694677\n",
      "Round 12 metrics:\n",
      "Server Loss = 5.805550575256348\n",
      "Server Recall = 0.0\n",
      "Round 12 finished!\n",
      "Round: 13\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:32.707641\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3991\n",
      "Epoch: 0, Average Loss: 64.7890\n",
      "start predicting:  2023-12-10 03:08:32.739557\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.751496\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9890\n",
      "Epoch: 0, Average Loss: 59.8683\n",
      "start predicting:  2023-12-10 03:08:32.792386\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:32.806378\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0366\n",
      "Epoch: 0, Average Loss: 48.4388\n",
      "start predicting:  2023-12-10 03:08:32.840092\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.853085\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.6025\n",
      "Epoch: 0, Average Loss: 43.2299\n",
      "start predicting:  2023-12-10 03:08:32.887964\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:32.900930\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6337\n",
      "Epoch: 0, Average Loss: 55.6041\n",
      "start predicting:  2023-12-10 03:08:32.933869\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:32.947833\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.1597\n",
      "Epoch: 0, Average Loss: 49.9160\n",
      "start predicting:  2023-12-10 03:08:32.978721\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:32.992683\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.2684\n",
      "Epoch: 0, Average Loss: 39.2204\n",
      "start predicting:  2023-12-10 03:08:33.024629\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.036566\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5556\n",
      "Epoch: 0, Average Loss: 66.6668\n",
      "start predicting:  2023-12-10 03:08:33.079480\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.092445\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3368\n",
      "Epoch: 0, Average Loss: 64.0421\n",
      "start predicting:  2023-12-10 03:08:33.129380\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.143344\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5160\n",
      "Epoch: 0, Average Loss: 54.1923\n",
      "start predicting:  2023-12-10 03:08:33.174318\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.187281\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.9949\n",
      "Epoch: 0, Average Loss: 47.9386\n",
      "start predicting:  2023-12-10 03:08:33.220192\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:33.233129\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5761\n",
      "Epoch: 0, Average Loss: 66.9136\n",
      "start predicting:  2023-12-10 03:08:33.269035\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:33.282027\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9034\n",
      "Epoch: 0, Average Loss: 58.8410\n",
      "start predicting:  2023-12-10 03:08:33.318929\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.332892\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.6056\n",
      "Epoch: 0, Average Loss: 67.2672\n",
      "start predicting:  2023-12-10 03:08:33.369792\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.382758\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5410\n",
      "Epoch: 0, Average Loss: 54.4926\n",
      "start predicting:  2023-12-10 03:08:33.413675\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:33.428607\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.7053\n",
      "Epoch: 0, Average Loss: 44.4633\n",
      "start predicting:  2023-12-10 03:08:33.458555\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:33.472490\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.5008\n",
      "Epoch: 0, Average Loss: 42.0095\n",
      "start predicting:  2023-12-10 03:08:33.508394\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:33.524351\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.0113\n",
      "Epoch: 0, Average Loss: 60.1356\n",
      "start predicting:  2023-12-10 03:08:33.558288\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.570257\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5498\n",
      "Epoch: 0, Average Loss: 54.5975\n",
      "start predicting:  2023-12-10 03:08:33.611118\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.625081\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4415\n",
      "Epoch: 0, Average Loss: 65.2974\n",
      "start predicting:  2023-12-10 03:08:33.660019\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:33.673950\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4491\n",
      "Epoch: 0, Average Loss: 53.3886\n",
      "start predicting:  2023-12-10 03:08:33.728804\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:33.749780\n",
      "Round 13 metrics:\n",
      "Server Loss = 5.857643127441406\n",
      "Server Recall = 0.0\n",
      "Round 13 finished!\n",
      "Round: 14\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:33.763711\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3902\n",
      "Epoch: 0, Average Loss: 64.6824\n",
      "start predicting:  2023-12-10 03:08:33.800645\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.813605\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8589\n",
      "Epoch: 0, Average Loss: 58.3067\n",
      "start predicting:  2023-12-10 03:08:33.851476\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:33.869429\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8488\n",
      "Epoch: 0, Average Loss: 46.1854\n",
      "start predicting:  2023-12-10 03:08:33.899376\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:33.914337\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.2925\n",
      "Epoch: 0, Average Loss: 39.5102\n",
      "start predicting:  2023-12-10 03:08:33.945253\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:33.961211\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4520\n",
      "Epoch: 0, Average Loss: 53.4244\n",
      "start predicting:  2023-12-10 03:08:33.995120\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.008085\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.9581\n",
      "Epoch: 0, Average Loss: 47.4972\n",
      "start predicting:  2023-12-10 03:08:34.040096\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:34.052066\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.8741\n",
      "Epoch: 0, Average Loss: 34.4892\n",
      "start predicting:  2023-12-10 03:08:34.084948\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.097941\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4875\n",
      "Epoch: 0, Average Loss: 65.8494\n",
      "start predicting:  2023-12-10 03:08:34.137987\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.152976\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2710\n",
      "Epoch: 0, Average Loss: 63.2522\n",
      "start predicting:  2023-12-10 03:08:34.189306\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.202271\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3573\n",
      "Epoch: 0, Average Loss: 52.2878\n",
      "start predicting:  2023-12-10 03:08:34.236210\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.249177\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.7351\n",
      "Epoch: 0, Average Loss: 44.8212\n",
      "start predicting:  2023-12-10 03:08:34.284052\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:34.298015\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5314\n",
      "Epoch: 0, Average Loss: 66.3766\n",
      "start predicting:  2023-12-10 03:08:34.332921\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:34.348880\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7764\n",
      "Epoch: 0, Average Loss: 57.3174\n",
      "start predicting:  2023-12-10 03:08:34.396752\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.410714\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5504\n",
      "Epoch: 0, Average Loss: 66.6047\n",
      "start predicting:  2023-12-10 03:08:34.446618\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.460580\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3409\n",
      "Epoch: 0, Average Loss: 52.0904\n",
      "start predicting:  2023-12-10 03:08:34.491451\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:34.504414\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.3565\n",
      "Epoch: 0, Average Loss: 40.2777\n",
      "start predicting:  2023-12-10 03:08:34.537298\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:34.549295\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.1668\n",
      "Epoch: 0, Average Loss: 38.0016\n",
      "start predicting:  2023-12-10 03:08:34.587195\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:34.600162\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.9124\n",
      "Epoch: 0, Average Loss: 58.9488\n",
      "start predicting:  2023-12-10 03:08:34.634039\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.648033\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3816\n",
      "Epoch: 0, Average Loss: 52.5795\n",
      "start predicting:  2023-12-10 03:08:34.689918\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.701858\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3796\n",
      "Epoch: 0, Average Loss: 64.5554\n",
      "start predicting:  2023-12-10 03:08:34.738787\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:34.753747\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.2297\n",
      "Epoch: 0, Average Loss: 50.7568\n",
      "start predicting:  2023-12-10 03:08:34.787436\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:34.805836\n",
      "Round 14 metrics:\n",
      "Server Loss = 5.884713172912598\n",
      "Server Recall = 0.0\n",
      "Round 14 finished!\n",
      "Round: 15\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:34.818795\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3435\n",
      "Epoch: 0, Average Loss: 64.1215\n",
      "start predicting:  2023-12-10 03:08:34.851686\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.864679\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8078\n",
      "Epoch: 0, Average Loss: 57.6938\n",
      "start predicting:  2023-12-10 03:08:34.902549\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:34.919533\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.6545\n",
      "Epoch: 0, Average Loss: 43.8541\n",
      "start predicting:  2023-12-10 03:08:34.953414\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:34.966380\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.0327\n",
      "Epoch: 0, Average Loss: 36.3921\n",
      "start predicting:  2023-12-10 03:08:35.003280\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:35.016245\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3289\n",
      "Epoch: 0, Average Loss: 51.9463\n",
      "start predicting:  2023-12-10 03:08:35.053185\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.065143\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.6788\n",
      "Epoch: 0, Average Loss: 44.1452\n",
      "start predicting:  2023-12-10 03:08:35.097752\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:35.111713\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6150\n",
      "Epoch: 0, Average Loss: 31.3797\n",
      "start predicting:  2023-12-10 03:08:35.141604\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.156593\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4893\n",
      "Epoch: 0, Average Loss: 65.8717\n",
      "start predicting:  2023-12-10 03:08:35.200448\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.216404\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2369\n",
      "Epoch: 0, Average Loss: 62.8423\n",
      "start predicting:  2023-12-10 03:08:35.252308\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.266300\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.1968\n",
      "Epoch: 0, Average Loss: 50.3616\n",
      "start predicting:  2023-12-10 03:08:35.296191\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.308159\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.5077\n",
      "Epoch: 0, Average Loss: 42.0928\n",
      "start predicting:  2023-12-10 03:08:35.345088\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:35.358025\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5267\n",
      "Epoch: 0, Average Loss: 66.3206\n",
      "start predicting:  2023-12-10 03:08:35.393148\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:35.406113\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6693\n",
      "Epoch: 0, Average Loss: 56.0321\n",
      "start predicting:  2023-12-10 03:08:35.440022\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.452988\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5855\n",
      "Epoch: 0, Average Loss: 67.0259\n",
      "start predicting:  2023-12-10 03:08:35.486897\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.498865\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.1805\n",
      "Epoch: 0, Average Loss: 50.1661\n",
      "start predicting:  2023-12-10 03:08:35.530780\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 26.666666666666668}\n",
      "start training:  2023-12-10 03:08:35.544742\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.1475\n",
      "Epoch: 0, Average Loss: 37.7696\n",
      "start predicting:  2023-12-10 03:08:35.576657\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:35.591617\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.8648\n",
      "Epoch: 0, Average Loss: 34.3770\n",
      "start predicting:  2023-12-10 03:08:35.627606\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:35.640572\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8214\n",
      "Epoch: 0, Average Loss: 57.8564\n",
      "start predicting:  2023-12-10 03:08:35.673483\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.686449\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.2131\n",
      "Epoch: 0, Average Loss: 50.5567\n",
      "start predicting:  2023-12-10 03:08:35.724347\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.736344\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3539\n",
      "Epoch: 0, Average Loss: 64.2474\n",
      "start predicting:  2023-12-10 03:08:35.771222\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:35.783190\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0524\n",
      "Epoch: 0, Average Loss: 48.6288\n",
      "start predicting:  2023-12-10 03:08:35.817099\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:35.861980\n",
      "Round 15 metrics:\n",
      "Server Loss = 5.895993709564209\n",
      "Server Recall = 0.0\n",
      "Round 15 finished!\n",
      "Round: 16\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:35.878934\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2405\n",
      "Epoch: 0, Average Loss: 62.8863\n",
      "start predicting:  2023-12-10 03:08:35.916833\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:35.930795\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6845\n",
      "Epoch: 0, Average Loss: 56.2136\n",
      "start predicting:  2023-12-10 03:08:35.969492\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:35.984424\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.4847\n",
      "Epoch: 0, Average Loss: 41.8159\n",
      "start predicting:  2023-12-10 03:08:36.016319\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.050229\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.8427\n",
      "Epoch: 0, Average Loss: 34.1123\n",
      "start predicting:  2023-12-10 03:08:36.086132\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:36.098101\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.2089\n",
      "Epoch: 0, Average Loss: 50.5063\n",
      "start predicting:  2023-12-10 03:08:36.133512\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.147474\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.5908\n",
      "Epoch: 0, Average Loss: 43.0892\n",
      "start predicting:  2023-12-10 03:08:36.183381\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:36.196343\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.4461\n",
      "Epoch: 0, Average Loss: 29.3534\n",
      "start predicting:  2023-12-10 03:08:36.228229\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.241195\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4187\n",
      "Epoch: 0, Average Loss: 65.0245\n",
      "start predicting:  2023-12-10 03:08:36.280978\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.293946\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1498\n",
      "Epoch: 0, Average Loss: 61.7980\n",
      "start predicting:  2023-12-10 03:08:36.331841\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.345775\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0359\n",
      "Epoch: 0, Average Loss: 48.4313\n",
      "start predicting:  2023-12-10 03:08:36.375725\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.388660\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.3386\n",
      "Epoch: 0, Average Loss: 40.0634\n",
      "start predicting:  2023-12-10 03:08:36.424564\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 35.0}\n",
      "start training:  2023-12-10 03:08:36.438551\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4439\n",
      "Epoch: 0, Average Loss: 65.3270\n",
      "start predicting:  2023-12-10 03:08:36.474456\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:36.487424\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.5644\n",
      "Epoch: 0, Average Loss: 54.7729\n",
      "start predicting:  2023-12-10 03:08:36.523301\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.536266\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4440\n",
      "Epoch: 0, Average Loss: 65.3274\n",
      "start predicting:  2023-12-10 03:08:36.571173\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.584166\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0276\n",
      "Epoch: 0, Average Loss: 48.3314\n",
      "start predicting:  2023-12-10 03:08:36.618046\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:36.631043\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.8506\n",
      "Epoch: 0, Average Loss: 34.2069\n",
      "start predicting:  2023-12-10 03:08:36.664946\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:36.677915\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6809\n",
      "Epoch: 0, Average Loss: 32.1713\n",
      "start predicting:  2023-12-10 03:08:36.710798\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:36.723764\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7056\n",
      "Epoch: 0, Average Loss: 56.4668\n",
      "start predicting:  2023-12-10 03:08:36.756704\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.769642\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0613\n",
      "Epoch: 0, Average Loss: 48.7351\n",
      "start predicting:  2023-12-10 03:08:36.809534\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:36.822500\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2537\n",
      "Epoch: 0, Average Loss: 63.0440\n",
      "start predicting:  2023-12-10 03:08:36.858405\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:36.872366\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8875\n",
      "Epoch: 0, Average Loss: 46.6503\n",
      "start predicting:  2023-12-10 03:08:36.923258\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:36.940214\n",
      "Round 16 metrics:\n",
      "Server Loss = 5.765659809112549\n",
      "Server Recall = 0.0\n",
      "Round 16 finished!\n",
      "Round: 17\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:36.956171\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1971\n",
      "Epoch: 0, Average Loss: 62.3652\n",
      "start predicting:  2023-12-10 03:08:36.990092\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.002021\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7499\n",
      "Epoch: 0, Average Loss: 56.9989\n",
      "start predicting:  2023-12-10 03:08:37.040945\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:37.054907\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.6280\n",
      "Epoch: 0, Average Loss: 43.5360\n",
      "start predicting:  2023-12-10 03:08:37.087791\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.099786\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.1001\n",
      "Epoch: 0, Average Loss: 37.2011\n",
      "start predicting:  2023-12-10 03:08:37.134665\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:37.149659\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.3148\n",
      "Epoch: 0, Average Loss: 51.7774\n",
      "start predicting:  2023-12-10 03:08:37.186555\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.199521\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.5321\n",
      "Epoch: 0, Average Loss: 42.3851\n",
      "start predicting:  2023-12-10 03:08:37.231406\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:37.245369\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6030\n",
      "Epoch: 0, Average Loss: 31.2363\n",
      "start predicting:  2023-12-10 03:08:37.278281\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.291247\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3584\n",
      "Epoch: 0, Average Loss: 64.3010\n",
      "start predicting:  2023-12-10 03:08:37.332166\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.345131\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1259\n",
      "Epoch: 0, Average Loss: 61.5111\n",
      "start predicting:  2023-12-10 03:08:37.382033\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.395966\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.1154\n",
      "Epoch: 0, Average Loss: 49.3847\n",
      "start predicting:  2023-12-10 03:08:37.428153\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.441116\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.5323\n",
      "Epoch: 0, Average Loss: 42.3871\n",
      "start predicting:  2023-12-10 03:08:37.475656\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 35.0}\n",
      "start training:  2023-12-10 03:08:37.489590\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3364\n",
      "Epoch: 0, Average Loss: 64.0366\n",
      "start predicting:  2023-12-10 03:08:37.526492\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:37.538488\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6047\n",
      "Epoch: 0, Average Loss: 55.2567\n",
      "start predicting:  2023-12-10 03:08:37.572395\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.585335\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4909\n",
      "Epoch: 0, Average Loss: 65.8906\n",
      "start predicting:  2023-12-10 03:08:37.623233\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.636198\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0821\n",
      "Epoch: 0, Average Loss: 48.9854\n",
      "start predicting:  2023-12-10 03:08:37.671133\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:37.684099\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.2930\n",
      "Epoch: 0, Average Loss: 39.5156\n",
      "start predicting:  2023-12-10 03:08:37.742944\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:37.756905\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.0586\n",
      "Epoch: 0, Average Loss: 36.7030\n",
      "start predicting:  2023-12-10 03:08:37.790814\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:37.803779\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7273\n",
      "Epoch: 0, Average Loss: 56.7272\n",
      "start predicting:  2023-12-10 03:08:37.836691\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.849627\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.1400\n",
      "Epoch: 0, Average Loss: 49.6798\n",
      "start predicting:  2023-12-10 03:08:37.889551\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:37.902487\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.1942\n",
      "Epoch: 0, Average Loss: 62.3302\n",
      "start predicting:  2023-12-10 03:08:37.939416\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:37.955371\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0410\n",
      "Epoch: 0, Average Loss: 48.4916\n",
      "start predicting:  2023-12-10 03:08:38.016183\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:38.038155\n",
      "Round 17 metrics:\n",
      "Server Loss = 6.25460147857666\n",
      "Server Recall = 0.0\n",
      "Round 17 finished!\n",
      "Round: 18\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:38.050120\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5149\n",
      "Epoch: 0, Average Loss: 66.1787\n",
      "start predicting:  2023-12-10 03:08:38.084998\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.096966\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8518\n",
      "Epoch: 0, Average Loss: 58.2210\n",
      "start predicting:  2023-12-10 03:08:38.134361\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:38.151317\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.3342\n",
      "Epoch: 0, Average Loss: 40.0108\n",
      "start predicting:  2023-12-10 03:08:38.181645\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.197608\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6167\n",
      "Epoch: 0, Average Loss: 31.3999\n",
      "start predicting:  2023-12-10 03:08:38.232510\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:38.246471\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.2290\n",
      "Epoch: 0, Average Loss: 50.7485\n",
      "start predicting:  2023-12-10 03:08:38.280391\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.293350\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.4869\n",
      "Epoch: 0, Average Loss: 41.8430\n",
      "start predicting:  2023-12-10 03:08:38.324265\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:38.338198\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.1126\n",
      "Epoch: 0, Average Loss: 25.3518\n",
      "start predicting:  2023-12-10 03:08:38.369662\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.382623\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7688\n",
      "Epoch: 0, Average Loss: 69.2253\n",
      "start predicting:  2023-12-10 03:08:38.421519\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.436481\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.4280\n",
      "Epoch: 0, Average Loss: 65.1363\n",
      "start predicting:  2023-12-10 03:08:38.473388\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.486346\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0357\n",
      "Epoch: 0, Average Loss: 48.4283\n",
      "start predicting:  2023-12-10 03:08:38.520256\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.532226\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.1599\n",
      "Epoch: 0, Average Loss: 37.9184\n",
      "start predicting:  2023-12-10 03:08:38.566132\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:38.579069\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.7608\n",
      "Epoch: 0, Average Loss: 69.1292\n",
      "start predicting:  2023-12-10 03:08:38.612978\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:38.625974\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.6435\n",
      "Epoch: 0, Average Loss: 55.7224\n",
      "start predicting:  2023-12-10 03:08:38.658856\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.673844\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.8148\n",
      "Epoch: 0, Average Loss: 69.7776\n",
      "start predicting:  2023-12-10 03:08:38.706728\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.720724\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0260\n",
      "Epoch: 0, Average Loss: 48.3119\n",
      "start predicting:  2023-12-10 03:08:38.755597\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 22.5}\n",
      "start training:  2023-12-10 03:08:38.768563\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.7746\n",
      "Epoch: 0, Average Loss: 33.2949\n",
      "start predicting:  2023-12-10 03:08:38.800477\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:38.813442\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.4358\n",
      "Epoch: 0, Average Loss: 29.2296\n",
      "start predicting:  2023-12-10 03:08:38.847380\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:38.862342\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.8716\n",
      "Epoch: 0, Average Loss: 58.4588\n",
      "start predicting:  2023-12-10 03:08:38.894261\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.907222\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0883\n",
      "Epoch: 0, Average Loss: 49.0591\n",
      "start predicting:  2023-12-10 03:08:38.945120\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:38.960079\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5660\n",
      "Epoch: 0, Average Loss: 66.7915\n",
      "start predicting:  2023-12-10 03:08:38.997949\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:39.011911\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.9341\n",
      "Epoch: 0, Average Loss: 47.2093\n",
      "start predicting:  2023-12-10 03:08:39.043826\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:39.060810\n",
      "Round 18 metrics:\n",
      "Server Loss = 6.16945743560791\n",
      "Server Recall = 0.0\n",
      "Round 18 finished!\n",
      "Round: 19\n",
      "Obtaining Weights!!\n",
      "start training:  2023-12-10 03:08:39.072778\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3154\n",
      "Epoch: 0, Average Loss: 63.7852\n",
      "start predicting:  2023-12-10 03:08:39.107656\n",
      "Train result client 0: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.120649\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7695\n",
      "Epoch: 0, Average Loss: 57.2338\n",
      "start predicting:  2023-12-10 03:08:39.160514\n",
      "Train result client 1: {'recall': 25.0, 'hit': 25.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:39.174477\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.3540\n",
      "Epoch: 0, Average Loss: 40.2475\n",
      "start predicting:  2023-12-10 03:08:39.213373\n",
      "Train result client 2: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.229340\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6623\n",
      "Epoch: 0, Average Loss: 31.9480\n",
      "start predicting:  2023-12-10 03:08:39.261245\n",
      "Train result client 3: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:39.276233\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.0970\n",
      "Epoch: 0, Average Loss: 49.1640\n",
      "start predicting:  2023-12-10 03:08:39.311111\n",
      "Train result client 4: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.324077\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.3387\n",
      "Epoch: 0, Average Loss: 40.0645\n",
      "start predicting:  2023-12-10 03:08:39.358014\n",
      "Train result client 5: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:39.370952\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.2310\n",
      "Epoch: 0, Average Loss: 26.7720\n",
      "start predicting:  2023-12-10 03:08:39.403254\n",
      "Train result client 6: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.416247\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5441\n",
      "Epoch: 0, Average Loss: 66.5293\n",
      "start predicting:  2023-12-10 03:08:39.457138\n",
      "Train result client 7: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.470103\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.2517\n",
      "Epoch: 0, Average Loss: 63.0207\n",
      "start predicting:  2023-12-10 03:08:39.504982\n",
      "Train result client 8: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.518946\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8303\n",
      "Epoch: 0, Average Loss: 45.9639\n",
      "start predicting:  2023-12-10 03:08:39.548999\n",
      "Train result client 9: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.562934\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.1099\n",
      "Epoch: 0, Average Loss: 37.3191\n",
      "start predicting:  2023-12-10 03:08:39.597865\n",
      "Train result client 10: {'recall': 100.0, 'hit': 100.0, 'mrr': 37.5}\n",
      "start training:  2023-12-10 03:08:39.612828\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5688\n",
      "Epoch: 0, Average Loss: 66.8260\n",
      "start predicting:  2023-12-10 03:08:39.648735\n",
      "Train result client 11: {'recall': 100.0, 'hit': 100.0, 'mrr': 20.0}\n",
      "start training:  2023-12-10 03:08:39.662694\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.4734\n",
      "Epoch: 0, Average Loss: 53.6806\n",
      "start predicting:  2023-12-10 03:08:39.699568\n",
      "Train result client 12: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.714556\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.5866\n",
      "Epoch: 0, Average Loss: 67.0394\n",
      "start predicting:  2023-12-10 03:08:39.751431\n",
      "Train result client 13: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.766430\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8840\n",
      "Epoch: 0, Average Loss: 46.6079\n",
      "start predicting:  2023-12-10 03:08:39.804288\n",
      "Train result client 14: {'recall': 100.0, 'hit': 100.0, 'mrr': 33.33333333333333}\n",
      "start training:  2023-12-10 03:08:39.819248\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.6674\n",
      "Epoch: 0, Average Loss: 32.0089\n",
      "start predicting:  2023-12-10 03:08:39.869114\n",
      "Train result client 15: {'recall': 100.0, 'hit': 100.0, 'mrr': 50.0}\n",
      "start training:  2023-12-10 03:08:39.882079\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 2.5797\n",
      "Epoch: 0, Average Loss: 30.9560\n",
      "start predicting:  2023-12-10 03:08:39.915989\n",
      "Train result client 16: {'recall': 100.0, 'hit': 100.0, 'mrr': 100.0}\n",
      "start training:  2023-12-10 03:08:39.927988\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 4.7541\n",
      "Epoch: 0, Average Loss: 57.0493\n",
      "start predicting:  2023-12-10 03:08:39.960868\n",
      "Train result client 17: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:39.973862\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.9174\n",
      "Epoch: 0, Average Loss: 47.0085\n",
      "start predicting:  2023-12-10 03:08:40.014752\n",
      "Train result client 18: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "start training:  2023-12-10 03:08:40.028687\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 5.3261\n",
      "Epoch: 0, Average Loss: 63.9128\n",
      "start predicting:  2023-12-10 03:08:40.071573\n",
      "Train result client 19: {'recall': 100.0, 'hit': 100.0, 'mrr': 25.0}\n",
      "start training:  2023-12-10 03:08:40.086561\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_weight\n",
      "Parameter shape: torch.Size([600, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.in_proj_bias\n",
      "Parameter shape: torch.Size([600])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.weight\n",
      "Parameter shape: torch.Size([200, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.self_attn.out_proj.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.weight\n",
      "Parameter shape: torch.Size([800, 200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear1.bias\n",
      "Parameter shape: torch.Size([800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.weight\n",
      "Parameter shape: torch.Size([200, 800])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.linear2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm1.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.weight\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "Parameter name: transformerEncoderLayer.norm2.bias\n",
      "Parameter shape: torch.Size([200])\n",
      "Gradient: None\n",
      "====================\n",
      "[0/1] Loss: 3.8137\n",
      "Epoch: 0, Average Loss: 45.7646\n",
      "start predicting:  2023-12-10 03:08:40.121457\n",
      "Train result client 20: {'recall': 0.0, 'hit': 0.0, 'mrr': 0.0}\n",
      "Aggregating Model!!\n",
      "start predicting:  2023-12-10 03:08:40.138393\n",
      "Round 19 metrics:\n",
      "Server Loss = 6.0685224533081055\n",
      "Server Recall = 0.0\n",
      "Round 19 finished!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Recall of all rounds: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "clients = {}\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "  clients[i] = {\"id\": i, \"val_size\": 0.25, \"batch_size\": opt.batchSize, \"local_epoch\": 1}\n",
    "  clients[i]['train_data'] = Data(train_data[i], shuffle=True)\n",
    "  clients[i]['test_data'] = Data(valid_data[i], shuffle=False)\n",
    "  print(f\"client: {i}\")\n",
    "  print(f\"Number of batches in the dataloader train: {len(clients[i]['train_data'])}\")\n",
    "  print(f\"Number of batches in the dataloader test: {len(clients[i]['test_data'])}\")\n",
    "\n",
    "serverdata = Data(valid_data[0], shuffle=False)\n",
    "server = FedAvg() ### initialize server\n",
    "\n",
    "allrecall = []\n",
    "for i in range(numrounds):\n",
    "  clients, recall = server.initiate_FL(clients, serverdata)\n",
    "  allrecall.append(recall)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Recall of all rounds: {}\".format(allrecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test to All Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on user 0...\n",
      "start predicting:  2023-12-10 03:08:40.169467\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 1...\n",
      "start predicting:  2023-12-10 03:08:40.175450\n",
      "Recall@5: 25.0000\n",
      "MRR@5: 25.0000\n",
      "Testing on user 2...\n",
      "start predicting:  2023-12-10 03:08:40.182431\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 3...\n",
      "start predicting:  2023-12-10 03:08:40.188415\n",
      "Recall@5: 100.0000\n",
      "MRR@5: 100.0000\n",
      "Testing on user 4...\n",
      "start predicting:  2023-12-10 03:08:40.197391\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 5...\n",
      "start predicting:  2023-12-10 03:08:40.203376\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 6...\n",
      "start predicting:  2023-12-10 03:08:40.209387\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 7...\n",
      "start predicting:  2023-12-10 03:08:40.214371\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 8...\n",
      "start predicting:  2023-12-10 03:08:40.221353\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 9...\n",
      "start predicting:  2023-12-10 03:08:40.227311\n",
      "Recall@5: 100.0000\n",
      "MRR@5: 20.0000\n",
      "Testing on user 10...\n",
      "start predicting:  2023-12-10 03:08:40.232337\n",
      "Recall@5: 50.0000\n",
      "MRR@5: 12.5000\n",
      "Testing on user 11...\n",
      "start predicting:  2023-12-10 03:08:40.242272\n",
      "Recall@5: 100.0000\n",
      "MRR@5: 33.3333\n",
      "Testing on user 12...\n",
      "start predicting:  2023-12-10 03:08:40.248283\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 13...\n",
      "start predicting:  2023-12-10 03:08:40.255237\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 14...\n",
      "start predicting:  2023-12-10 03:08:40.260224\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 15...\n",
      "start predicting:  2023-12-10 03:08:40.273217\n",
      "Recall@5: 100.0000\n",
      "MRR@5: 20.0000\n",
      "Testing on user 16...\n",
      "start predicting:  2023-12-10 03:08:40.279200\n",
      "Recall@5: 100.0000\n",
      "MRR@5: 50.0000\n",
      "Testing on user 17...\n",
      "start predicting:  2023-12-10 03:08:40.285157\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 18...\n",
      "start predicting:  2023-12-10 03:08:40.291171\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 19...\n",
      "start predicting:  2023-12-10 03:08:40.299148\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Testing on user 20...\n",
      "start predicting:  2023-12-10 03:08:40.306100\n",
      "Recall@5: 0.0000\n",
      "MRR@5: 0.0000\n",
      "Average Recall@5: 27.3810\n",
      "Average MRR@5: 12.4206\n"
     ]
    }
   ],
   "source": [
    "final_model = server.globalmodel\n",
    "final_model = trans_to_cuda(final_model)\n",
    "\n",
    "recall_clients = []\n",
    "mrr_clients = []\n",
    "loss_clients = []\n",
    "\n",
    "# loop for each client\n",
    "for i in range(len(train_data)):\n",
    "    print(f\"Testing on user {i}...\")\n",
    "    local_test = valid_data[i]\n",
    "    testloader = Data(local_test, shuffle=False)\n",
    "\n",
    "    # Evaluate the network\n",
    "    loss, results = test(final_model, testloader, DEVICE)\n",
    "\n",
    "    print(f\"Recall@5: {results['recall']:.4f}\")\n",
    "    print(f\"MRR@5: {results['mrr']:.4f}\")\n",
    "\n",
    "    recall_clients.append(results['recall'])\n",
    "    mrr_clients.append(results['mrr'])\n",
    "    loss_clients.append(loss) \n",
    "\n",
    "print(f\"Average Recall@5: {np.mean(recall_clients):.4f}\")\n",
    "print(f\"Average MRR@5: {np.mean(mrr_clients):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
