{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tr_data = np.load(f'./train_data_diginetica.npy', allow_pickle=True)\n",
    "raw_val_data = np.load(f'./test_data_diginetica.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'diginetica'\n",
    "attack_type = 'B' # A1: label_poison, A2: gaussian_attack, A3: scaling_attack, A4: reverse_attack\n",
    "local_learning_rate = 0.01\n",
    "local_steps= 1\n",
    "data_path= f\".\"\n",
    "learning_rate_decay_gamma= 0.99\n",
    "learning_rate_decay= False\n",
    "future_test= False\n",
    "mu= 1\n",
    "global_rounds= 50\n",
    "num_clients= len(raw_val_data)\n",
    "join_ratio= 1.0\n",
    "attack_ratio= 0.0\n",
    "algorithm= \"FedCHAR\"\n",
    "future_ratio= 0.0\n",
    "finetune_rounds= 0\n",
    "eval_gap= 1\n",
    "detailed_info= False\n",
    "partition= \"nature\"\n",
    "initial_rounds= 10\n",
    "n_clusters= 4\n",
    "metric= 'cosine'\n",
    "linkage= 'complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter for recommender system\n",
    "input_size = 889\n",
    "hidden_size = 100\n",
    "num_layers = 2\n",
    "output_size = input_size\n",
    "batch_size = 10\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all train data as one dataframe\n",
    "train_combined = np.concatenate(raw_tr_data)\n",
    "#convert to dataframe\n",
    "train_combined = pd.DataFrame(train_combined)\n",
    "train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique item IDs from the combined DataFrame\n",
    "all_unique_items = train_combined[2].unique()\n",
    "\n",
    "# Step 2: Create a universal item index mapping\n",
    "universal_item_map = pd.DataFrame({\n",
    "    'item_idx': np.arange(len(all_unique_items)),\n",
    "    'itemId': all_unique_items\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUDataset(Dataset):\n",
    "    def __init__(self, data, itemmap, session_key='sessionId', item_key='itemId', time_key='time'):\n",
    "        self.data = data\n",
    "        self.itemmap = itemmap\n",
    "        self.session_key = session_key\n",
    "        self.item_key = item_key\n",
    "        self.time_key = time_key\n",
    "\n",
    "        # Map items to indices\n",
    "        self.data = pd.merge(self.data, self.itemmap, on=self.item_key, how='inner')\n",
    "\n",
    "        # Sort by session and time\n",
    "        self.data.sort_values([self.session_key, self.time_key], inplace=True)\n",
    "\n",
    "        # Group data by session and collect item indices\n",
    "        self.sessions = self.data.groupby(self.session_key)['item_idx'].apply(list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        session_items = self.sessions.iloc[index]\n",
    "        sequence = torch.tensor(session_items[:-1], dtype=torch.long)\n",
    "        target = torch.tensor(session_items[1:], dtype=torch.long)\n",
    "        return sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=-1)\n",
    "    return sequences_padded, targets_padded\n",
    "\n",
    "def get_loader(data, itemmap, batch_size=32, shuffle=True):\n",
    "    dataset = GRUDataset(data, itemmap=itemmap)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedGradientDescent(Optimizer):\n",
    "  def __init__(self, params, lr=0.01, mu=0.0):\n",
    "    default = dict(lr=lr, mu=mu)\n",
    "    super().__init__(params, default)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def step(self, global_params, device):\n",
    "    for group in self.param_groups:\n",
    "      for p, g in zip(group['params'], global_params):\n",
    "        g = g.to(device)\n",
    "        d_p = p.grad.data + group['mu'] * (p.data - g.data)\n",
    "        p.data.add_(d_p, alpha=-group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of expected features in the input `x`\n",
    "            hidden_size (int): The number of features in the hidden state `h`\n",
    "            output_size (int): The size of the output layer (number of items)\n",
    "            num_layers (int, optional): Number of recurrent layers. Default: 1\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x: Input data\n",
    "            hidden: Hidden state (h_0, c_0)\n",
    "\n",
    "        Returns:\n",
    "            Output and new hidden state\n",
    "        \"\"\"\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # LSTM\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "\n",
    "        # Predict next item\n",
    "        output = self.fc(output[:, -1, :])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state of the LSTM.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The size of the batch\n",
    "\n",
    "        Returns:\n",
    "            Initial hidden state (h_0, c_0)\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOP1MaxLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1MaxLoss, self).__init__()\n",
    "\n",
    "    def forward(self, scores, targets):\n",
    "        # Initialize loss\n",
    "        loss = 0.0\n",
    "\n",
    "        # Loop over each element in the batch\n",
    "        for i in range(scores.size(0)):  # Loop over batch\n",
    "            for j in range(targets.size(1)):  # Loop over sequence\n",
    "                if targets[i, j] == -1:  # Skip padding\n",
    "                    continue\n",
    "\n",
    "                # Get the score of the target item\n",
    "                pos_score = scores[i, targets[i, j]]\n",
    "\n",
    "                # Calculate the difference with all other items\n",
    "                diff = -torch.sigmoid(pos_score - scores[i])\n",
    "\n",
    "                # Exclude the positive item from the loss\n",
    "                diff[targets[i, j]] = 0\n",
    "\n",
    "                # Add to the total loss\n",
    "                loss += torch.sum(diff)\n",
    "\n",
    "        # Average the loss\n",
    "        loss = loss / (scores.size(0) * targets.size(1))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "  \"\"\"\n",
    "  Base class for clients in federated learning.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, model, id, malicious, **kwargs):\n",
    "    self.model = copy.deepcopy(model)\n",
    "    self.dataset = dataset\n",
    "    self.device = DEVICE\n",
    "    self.id = id\n",
    "    self.malicious = malicious\n",
    "    self.attack_type = attack_type\n",
    "    self.num_classes = output_size\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = local_learning_rate\n",
    "    self.local_steps = local_steps\n",
    "    self.data_path = data_path\n",
    "    self.learning_rate_decay = learning_rate_decay\n",
    "    self.future_test = future_test\n",
    "\n",
    "\n",
    "    # check BatchNorm\n",
    "    self.has_BatchNorm = False\n",
    "    for layer in self.model.children():\n",
    "      if isinstance(layer, nn.BatchNorm2d):\n",
    "        self.has_BatchNorm = True\n",
    "        break\n",
    "\n",
    "    self.loss = TOP1MaxLoss()  # Replace with your loss function\n",
    "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate) # momentum=0.9, weight_decay=1e-4\n",
    "    self.learning_rate_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "      optimizer=self.optimizer,\n",
    "      gamma=learning_rate_decay_gamma\n",
    "    )\n",
    "\n",
    "  def load_train_data(self, batch_size=None):\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    train_data = get_loader(raw_tr_data[self.id], itemmap=universal_item_map, batch_size=batch_size)\n",
    "\n",
    "    # label poison attack\n",
    "    if self.malicious and self.attack_type == 'A1':\n",
    "      for idx in range(len(train_data)):\n",
    "        train_data[idx][1] = self.num_classes - train_data[idx][1] - 1\n",
    "    self.train_samples = len(train_data)\n",
    "    return train_data\n",
    "\n",
    "  def load_test_data(self, batch_size=None):\n",
    "    \"\"\"\n",
    "    fine-tunes the model using the loaded training data\n",
    "    \"\"\"\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    test_data = get_loader(raw_val_data[self.id], itemmap=universal_item_map, batch_size=batch_size)\n",
    "    return test_data\n",
    "  \n",
    "  def set_parameters(self, model):\n",
    "    for new_param, old_param in zip(model.parameters(), self.model.parameters()):\n",
    "      old_param.data = new_param.data.clone()\n",
    "\n",
    "  def fine_tuning(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.train()\n",
    "\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "      # if type(x) == type([]):\n",
    "      #   x[0] = x[0].to(self.device)\n",
    "      # else:\n",
    "      #   x = x.to(self.device)\n",
    "      x = x.to(self.device)\n",
    "      y = y.to(self.device)\n",
    "      self.optimizer.zero_grad()\n",
    "      hidden = self.model.init_hidden(x.size(0))\n",
    "      hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "      output, _ = self.model(x, hidden)\n",
    "      # output = self.model(x)\n",
    "      loss = self.loss(output, y)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "  def new_test_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's performance on test data, particularly its accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    testloaderfull = self.load_test_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    y_prob = [] #model outputs or probabilities\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in testloaderfull:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        # output = self.model(x)\n",
    "        output, _ = self.model(x, hidden)\n",
    "\n",
    "        # Select top-k items\n",
    "        _, top_k_indices = torch.topk(output, K, dim=1)\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        for i in range(x.size(0)):\n",
    "          for y_item in y[i]:\n",
    "            if y_item == -1:\n",
    "              continue\n",
    "            target_item_scalar = y_item.item()\n",
    "            top_k_items = top_k_indices[i].tolist()\n",
    "\n",
    "            # Calculate Recall@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              total_recall += 1\n",
    "\n",
    "            # Calculate MRR@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              rank = top_k_items.index(target_item_scalar)\n",
    "              total_mrr += 1 / (rank + 1)\n",
    "          \n",
    "          test_num += len(y[i][y[i] != -1])  # Count non-padding elements\n",
    "\n",
    "        y_prob.append(output.detach().cpu().numpy())\n",
    "        nc = self.num_classes\n",
    "        if self.num_classes == 2:\n",
    "          nc += 1\n",
    "        lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))\n",
    "        if self.num_classes == 2:\n",
    "          lb = lb[:, :2]\n",
    "        y_true.append(lb)\n",
    "\n",
    "    y_prob = np.concatenate(y_prob, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def new_train_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's loss on the training data.\n",
    "    \"\"\"\n",
    "\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0.0\n",
    "    with torch.no_grad():\n",
    "      for x, y in trainloader:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        output, _ = self.model(x, hidden)\n",
    "        # output = self.model(x)\n",
    "        # calculate losses\n",
    "        loss = self.loss(output, y)\n",
    "        train_num += y.shape[0]\n",
    "        losses += loss * y.shape[0]\n",
    "        # loss = self.loss(output, y)\n",
    "        # train_num += y.shape[0]\n",
    "        # losses += loss.item() * y.shape[0]\n",
    "\n",
    "    return losses, train_num\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    testloaderfull = self.load_test_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    # y_prob = []\n",
    "    # y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in testloaderfull:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        #output = self.model(x)\n",
    "        output,_ = self.model(x, hidden) \n",
    "\n",
    "        # Select top-k items\n",
    "        _, top_k_indices = torch.topk(output, K, dim=1)\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        for i in range(x.size(0)):\n",
    "          for y_item in y[i]:\n",
    "            if y_item == -1:\n",
    "              continue\n",
    "            target_item_scalar = y_item.item()\n",
    "            top_k_items = top_k_indices[i].tolist()\n",
    "\n",
    "            # Calculate Recall@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              total_recall += 1\n",
    "\n",
    "            # Calculate MRR@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              rank = top_k_items.index(target_item_scalar)\n",
    "              total_mrr += 1 / (rank + 1)\n",
    "          \n",
    "          test_num += len(y[i][y[i] != -1]) # Count non-padding elements\n",
    "\n",
    "        # y_prob.append(output.detach().cpu().numpy())\n",
    "        # nc = self.num_classes\n",
    "        # if self.num_classes == 2:\n",
    "        #   nc += 1\n",
    "        # lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))\n",
    "        # if self.num_classes == 2:\n",
    "        #   lb = lb[:, :2]\n",
    "        # y_true.append(lb)\n",
    "\n",
    "    # y_prob = np.concatenate(y_prob, axis=0)\n",
    "    # y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    trainloader = self.load_train_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "      for x, y in trainloader:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        output, _ = self.model(x, hidden)\n",
    "        # output = self.model(x)\n",
    "        loss = self.loss(output, y)\n",
    "        train_num += y.shape[0]\n",
    "        losses += loss * y.shape[0]\n",
    "\n",
    "    return losses, train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clientCHAR(Client):\n",
    "  def __init__(self, model, id, malicious, **kwargs):\n",
    "    super().__init__(model, id, malicious, **kwargs)\n",
    "    self.mu = mu\n",
    "    self.model_per = copy.deepcopy(self.model)\n",
    "    self.optimizer_per = PerturbedGradientDescent(self.model_per.parameters(), lr=self.learning_rate, mu=self.mu)\n",
    "    self.learning_rate_scheduler_per = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer=self.optimizer_per,\n",
    "        gamma=learning_rate_decay_gamma\n",
    "        )\n",
    "\n",
    "  def dtrain(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    model = copy.deepcopy(self.model)\n",
    "    self.model.train()\n",
    "    self.model_per.train()\n",
    "\n",
    "    max_local_steps = self.local_steps\n",
    "\n",
    "    for step in range(max_local_steps):\n",
    "      for x, y in trainloader:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden_p = self.model_per.init_hidden(x.size(0))\n",
    "        hidden_p = (hidden_p[0].to(self.device), hidden_p[1].to(self.device))\n",
    "        out_p, _ = self.model_per(x, hidden_p)\n",
    "        # out_p = self.model_per(x)\n",
    "        loss = self.loss(out_p, y)\n",
    "        self.optimizer_per.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f\"loss: {loss}\")\n",
    "        for name, param in self.model_per.named_parameters():\n",
    "          if param.grad is None:\n",
    "            print(f\"Parameter name: {name}\")\n",
    "            print(f\"Parameter shape: {param.shape}\")\n",
    "            print(f\"Gradient: {param.grad}\")\n",
    "            print(\"=\" * 20)\n",
    "        self.optimizer_per.step(model.parameters(), self.device)\n",
    "\n",
    "        hidden_g = self.model.init_hidden(x.size(0))\n",
    "        hidden_g = (hidden_g[0].to(self.device), hidden_g[1].to(self.device))\n",
    "        out_g, _ = self.model(x, hidden_g)\n",
    "        # out_g = self.model(x)\n",
    "        loss = self.loss(out_g, y)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    if self.learning_rate_decay:\n",
    "      self.learning_rate_scheduler.step()\n",
    "      self.learning_rate_scheduler_per.step()\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    testloaderfull = self.load_test_data()\n",
    "    self.model_per.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    # y_prob = []\n",
    "    # y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in testloaderfull:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model_per.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        output, _ = self.model_per(x, hidden)\n",
    "        # output = self.model_per(x)\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        # Select top-k items\n",
    "        _, top_k_indices = torch.topk(output, K, dim=1)\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        for i in range(x.size(0)):\n",
    "          for y_item in y[i]:\n",
    "            if y_item == -1:\n",
    "              continue\n",
    "            target_item_scalar = y_item.item()\n",
    "            top_k_items = top_k_indices[i].tolist()\n",
    "\n",
    "            # Calculate Recall@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              total_recall += 1\n",
    "\n",
    "            # Calculate MRR@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              rank = top_k_items.index(target_item_scalar)\n",
    "              total_mrr += 1 / (rank + 1)\n",
    "          \n",
    "          test_num += len(y[i][y[i] != -1])\n",
    "\n",
    "    #     y_prob.append(F.softmax(output).detach().cpu().numpy())\n",
    "    #     y_true.append(label_binarize(y.detach().cpu().numpy(), classes=np.arange(self.num_classes)))\n",
    "\n",
    "    # y_prob = np.concatenate(y_prob, axis=0)\n",
    "    # y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model_per.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "      for x, y in trainloader:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model_per.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        output, _ = self.model_per(x, hidden)\n",
    "        # output = self.model_per(x)\n",
    "        loss = self.loss(output, y)\n",
    "\n",
    "        #add a regularization term to the loss\n",
    "        # ensure that the personalized model doesn't deviate too far from the global model.\n",
    "        # The strength of this regularization is controlled by the parameter self.mu\n",
    "        gm = torch.cat([p.data.view(-1) for p in self.model.parameters()], dim=0)\n",
    "        pm = torch.cat([p.data.view(-1) for p in self.model_per.parameters()], dim=0)\n",
    "        loss += 0.5 * self.mu * torch.norm(pm-gm, p=2) #element-wise difference using L2 norm\n",
    "\n",
    "        train_num += y.shape[0]\n",
    "        losses += loss.item() * y.shape[0]\n",
    "\n",
    "    return losses, train_num\n",
    "\n",
    "  def get_update(self, global_model):\n",
    "    trainloader = self.load_train_data()\n",
    "    model = copy.deepcopy(self.model) #old model\n",
    "    self.set_parameters(global_model)\n",
    "    self.model.train()\n",
    "\n",
    "    max_local_steps = self.local_steps\n",
    "\n",
    "    for step in range(max_local_steps):\n",
    "      for i, (x, y) in enumerate(trainloader):\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        hidden = (hidden[0].to(self.device), hidden[1].to(self.device))\n",
    "        output, _ = self.model(x, hidden)\n",
    "        # output = self.model(x)\n",
    "        loss = self.loss(output, y)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    model_update = [c_param.data - s_param.data for c_param, s_param in zip(self.model.parameters(), global_model.parameters())]\n",
    "    self.set_parameters(model)\n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the train_num and test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(object):\n",
    "  def __init__(self, model):\n",
    "    # Set up the main attributes\n",
    "    self.device = DEVICE\n",
    "    self.dataset = dataset\n",
    "    self.num_classes = input_size\n",
    "    self.global_rounds = global_rounds\n",
    "    self.local_steps = local_steps\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = local_learning_rate\n",
    "    self.global_model = copy.deepcopy(model)\n",
    "    self.num_clients = num_clients\n",
    "    self.join_ratio = join_ratio\n",
    "    self.attack_ratio = attack_ratio\n",
    "    self.attack_type = attack_type\n",
    "    self.seed = seed\n",
    "    self.algorithm = algorithm\n",
    "    self.current_round = -1\n",
    "    self.future_test = future_test\n",
    "    self.future_ratio = future_ratio\n",
    "    self.num_training_clients = num_clients - int(num_clients * future_ratio)\n",
    "    self.join_clients = int(self.num_training_clients * self.join_ratio)\n",
    "    self.finetune_rounds = finetune_rounds\n",
    "    self.eval_gap = eval_gap\n",
    "    self.detailed_info = detailed_info\n",
    "    self.partition = partition\n",
    "    self.data_path = data_path\n",
    "\n",
    "    self.clients = []\n",
    "    self.training_clients = []\n",
    "    self.malicious_ids = []\n",
    "    self.selected_clients = []\n",
    "\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_models = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    self.rs_test_recall_g = []\n",
    "    self.rs_test_mrr_g = []\n",
    "    self.rs_train_loss_g = []\n",
    "    self.rs_test_recalls_g = []\n",
    "    self.rs_test_mrrs_g = []\n",
    "    self.rs_test_recall_p = []\n",
    "    self.rs_test_mrr_p = []\n",
    "    self.rs_train_loss_p = []\n",
    "    self.rs_test_recalls_p = []\n",
    "    self.rs_test_mrrs_p = []\n",
    "    self.ft_train_loss = []\n",
    "    self.ft_test_recall = []\n",
    "    self.ft_std_recall = []\n",
    "    self.ft_test_mrr = []\n",
    "    self.ft_std_mrr = []\n",
    "\n",
    "  def set_clients(self, model, clientObj):\n",
    "\n",
    "    if self.future_test == False:\n",
    "      if self.attack_type == 'B':\n",
    "        self.malicious_ids = []\n",
    "        self.attack_ratio = 0.0\n",
    "      else:\n",
    "        self.malicious_ids = np.sort(np.random.choice(np.arange(self.num_clients), int(self.num_clients * self.attack_ratio), replace=False))\n",
    "\n",
    "\n",
    "      for i in range(self.num_clients):\n",
    "        client = clientObj(model=model, id=i,\n",
    "                        malicious=True if i in self.malicious_ids else False)\n",
    "        self.clients.append(client)\n",
    "\n",
    "      self.training_clients = self.clients\n",
    "      self.training_clients_ids = np.arange(self.num_clients)\n",
    "\n",
    "    else:\n",
    "      if self.algorithm != 'FedCHAR_DC':\n",
    "        print('{} do not support future testing'.format(self.algorithm))\n",
    "        raise NotImplementedError\n",
    "\n",
    "      self.training_clients_ids = np.sort(np.random.choice(np.arange(self.num_clients), self.num_training_clients, replace=False))\n",
    "\n",
    "      if self.attack_type == 'B':\n",
    "        self.malicious_ids = []\n",
    "        self.attack_ratio = 0.0\n",
    "      else:\n",
    "        self.malicious_ids = np.sort(np.random.choice(self.training_clients_ids, int(self.num_training_clients * self.attack_ratio),\n",
    "                                                      replace=False))\n",
    "\n",
    "      for i in range(self.num_clients):\n",
    "        client = clientObj(model=model, id=i,\n",
    "                        malicious=True if i in self.malicious_ids else False)\n",
    "        self.clients.append(client)\n",
    "\n",
    "        if i in self.training_clients_ids:\n",
    "          self.training_clients.append(client)\n",
    "\n",
    "    print('Malicious Clients: {}'.format(list(self.malicious_ids)))\n",
    "    print('Future Clients: {}'.format(list(np.sort(np.setdiff1d(np.arange(self.num_clients), self.training_clients_ids)))))\n",
    "\n",
    "  def select_clients(self):\n",
    "    selected_clients = list(np.random.choice(self.training_clients, self.join_clients, replace=False))\n",
    "    return selected_clients\n",
    "\n",
    "  def send_models(self):\n",
    "    for client in self.selected_clients:\n",
    "      client.set_parameters(self.global_model)\n",
    "\n",
    "  def send_models_to_future_clients(self):\n",
    "    for client in self.selected_clients:\n",
    "      client.set_parameters(self.global_model)\n",
    "\n",
    "  def receive_models(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = [] #weight based on the fraction of client's data\n",
    "    self.uploaded_models = []\n",
    "\n",
    "    tot_samples = 0\n",
    "    for client in self.selected_clients:\n",
    "      tot_samples += client.train_samples\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      self.uploaded_models.append(client.model)\n",
    "\n",
    "    for i, w in enumerate(self.uploaded_weights):\n",
    "      self.uploaded_weights[i] = w / tot_samples\n",
    "\n",
    "  def load_model(self):\n",
    "    model_path = os.path.join(f\"./models\", self.dataset)\n",
    "    model_path = os.path.join(model_path, self.algorithm + \"_server\" + \".pt\")\n",
    "    assert (os.path.exists(model_path))\n",
    "    self.global_model = torch.load(model_path)\n",
    "\n",
    "  def model_exists(self):\n",
    "    model_path = os.path.join(f\"./models\", self.dataset)\n",
    "    model_path = os.path.join(model_path, self.algorithm + \"_server\" + \".pt\")\n",
    "    return os.path.exists(model_path)\n",
    "\n",
    "  def save_results(self):\n",
    "    filename = \"{}_{}_{}_{}_{}_bz{}_lr{}_gr{}_ep{}_jr{}_nc{}_fur{}_ntc{}_ftr{}_seed{}\".format(self.dataset, self.partition, self.algorithm,\n",
    "                                                                                        self.attack_type, self.attack_ratio, self.batch_size,\n",
    "                                                                                        self.learning_rate, self.global_rounds, self.local_steps,\n",
    "                                                                                        self.join_ratio, self.num_clients, self.future_ratio,\n",
    "                                                                                        self.num_training_clients, self.finetune_rounds,\n",
    "                                                                                        self.seed)\n",
    "\n",
    "    if self.algorithm == 'FedCHAR':\n",
    "      filename = filename + '_ir{}_ng{}_mtrc{}_lkg{}'.format(self.initial_rounds, self.n_clusters, self.metric, self.linkage)\n",
    "\n",
    "    elif self.algorithm == 'FedCHAR_DC':\n",
    "      filename = filename + '_ir{}_ng{}_mtrc{}_lkg{}_rr{}'.format(self.initial_rounds, self.n_clusters, self.metric, self.linkage,\n",
    "                                                                  self.recluster_rounds)\n",
    "\n",
    "    result_path = f\"./results/npz/\"\n",
    "    if not os.path.exists(result_path):\n",
    "      os.makedirs(result_path)\n",
    "\n",
    "    if len(self.rs_test_acc_g) or len(self.rs_test_acc_p):\n",
    "      file_path = result_path + \"{}.npz\".format(filename)\n",
    "      print(\"Result path: \" + file_path)\n",
    "\n",
    "      np.savez(file_path, test_acc_g=self.rs_test_acc_g,\n",
    "              test_acc_p=self.rs_test_acc_p, test_accs_g=self.rs_test_accs_g,\n",
    "              test_accs_p=self.rs_test_accs_p, train_loss_g=self.rs_train_loss_g,\n",
    "              train_loss_p=self.rs_train_loss_p, ft_train_loss=self.ft_train_loss,\n",
    "              ft_test_acc=self.ft_test_acc, ft_std_acc=self.ft_std_acc)\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def test_metrics_for_future_clients(self):\n",
    "    num_samples = []\n",
    "    tot_correct = []\n",
    "\n",
    "    for c in self.selected_clients:\n",
    "      ct, ns = c.new_test_metrics()\n",
    "      tot_correct.append(ct*1.0)\n",
    "      num_samples.append(ns)\n",
    "\n",
    "    ids = [c.id for c in self.selected_clients]\n",
    "    return ids, num_samples, tot_correct\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def train_metrics_for_future_clients(self):\n",
    "    num_samples = []\n",
    "    losses = []\n",
    "    for c in self.selected_clients:\n",
    "      cl, ns = c.new_train_metrics()\n",
    "      num_samples.append(ns)\n",
    "      losses.append(cl*1.0)\n",
    "\n",
    "    ids = [c.id for c in self.selected_clients]\n",
    "    return ids, num_samples, losses\n",
    "\n",
    "  def evaluate_personalized(self, rec=None, loss=None, mrr=None):\n",
    "    stats = self.test_metrics_personalized()\n",
    "    stats_train = self.train_metrics_personalized()\n",
    "\n",
    "    if self.malicious_ids != []: # skip this for now\n",
    "      relative_malicious_ids = np.array([stats[0].index(i) for i in self.malicious_ids])\n",
    "\n",
    "      stats_A = np.array(stats)[:, relative_malicious_ids].tolist()\n",
    "      stats_train_A = np.array(stats_train)[:, relative_malicious_ids].tolist()\n",
    "\n",
    "      test_acc_A = sum(stats_A[2])*1.0 / sum(stats_A[1])\n",
    "      train_loss_A = sum(stats_train_A[2])*1.0 / sum(stats_train_A[1])\n",
    "      accs_A = [a / n for a, n in zip(stats_A[2], stats_A[1])]\n",
    "      losses_A = [a / n for a, n in zip(stats_train_A[2], stats_train_A[1])]\n",
    "\n",
    "    else:\n",
    "      test_acc_A = -1\n",
    "      train_loss_A = -1\n",
    "      accs_A = []\n",
    "      losses_A = []\n",
    "\n",
    "    benign_ids = np.sort(np.setdiff1d(self.training_clients_ids, self.malicious_ids))\n",
    "    relative_benign_ids = np.array([stats[0].index(i) for i in benign_ids])\n",
    "\n",
    "    stats_B = np.array(stats)[:, relative_benign_ids].tolist()\n",
    "    stats_train_B = np.array(stats_train)[:, relative_benign_ids].tolist()\n",
    "\n",
    "    stats = None\n",
    "    stats_train = None\n",
    "\n",
    "    # test_acc = sum(stats_B[2])*1.0 / sum(stats_B[1])\n",
    "    # train_loss = sum(stats_train_B[2])*1.0 / sum(stats_train_B[1])\n",
    "    # accs = [a / n for a, n in zip(stats_B[2], stats_B[1])]\n",
    "    # losses = [a / n for a, n in zip(stats_train_B[2], stats_train_B[1])]\n",
    "\n",
    "    test_recall = sum(stats_B[2])*1.0 / sum(stats_B[1])\n",
    "    test_mrr = sum(stats_B[3])*1.0 / sum(stats_B[1])\n",
    "    train_loss = sum(stats_train_B[2])*1.0 / sum(stats_train_B[1])\n",
    "    recalls = [a / n for a, n in zip(stats_B[2], stats_B[1])]\n",
    "    mrrs = [a / n for a, n in zip(stats_B[3], stats_B[1])]\n",
    "    losses = [a / n for a, n in zip(stats_train_B[2], stats_train_B[1])]\n",
    "\n",
    "    if rec == None:\n",
    "      self.rs_test_recall_p.append(test_recall)\n",
    "    else:\n",
    "      rec.append(test_recall)\n",
    "\n",
    "    if mrr == None:\n",
    "      self.rs_test_mrr_p.append(test_mrr)\n",
    "    else:\n",
    "      mrr.append(test_mrr)\n",
    "\n",
    "    if loss == None:\n",
    "      self.rs_train_loss_p.append(train_loss)\n",
    "    else:\n",
    "      loss.append(train_loss)\n",
    "\n",
    "    self.rs_test_recall_p.append(recalls)\n",
    "    self.rs_test_mrr_p.append(mrrs)\n",
    "\n",
    "    print(\"Benign Averaged Train Loss: {:.2f}\".format(train_loss))\n",
    "    # print(\"Benign Averaged Test Accurancy: {:.2f}%\".format(test_acc*100))\n",
    "    # print(\"Benign Std Test Accurancy: {:.2f}%\".format(np.std(accs)*100))\n",
    "    print(\"Benign Averaged Test Recall: {:.2f}%\".format(test_recall*100))\n",
    "    print(\"Benign Std Test Recall: {:.2f}%\".format(np.std(recalls)*100))\n",
    "    print(\"Benign Averaged Test MRR: {:.2f}%\".format(test_mrr*100))\n",
    "    print(\"Benign Std Test MRR: {:.2f}%\".format(np.std(mrrs)*100))\n",
    "\n",
    "    if self.malicious_ids != []:\n",
    "      print(\"Malicious Averaged Train Loss: {:.2f}\".format(train_loss_A))\n",
    "      print(\"Malicious Averaged Test Accurancy: {:.2f}%\".format(test_acc_A*100))\n",
    "\n",
    "  # did not implemented the modification\n",
    "  def evaluate_for_future_clients(self):\n",
    "    stats = self.test_metrics_for_future_clients()\n",
    "    stats_train = self.train_metrics_for_future_clients()\n",
    "    stats = np.array(stats).tolist()\n",
    "    stats_train = np.array(stats_train).tolist()\n",
    "    test_acc = sum(stats[2])*1.0 / sum(stats[1])\n",
    "    train_loss = sum(stats_train[2])*1.0 / sum(stats_train[1])\n",
    "    accs = [a / n for a, n in zip(stats[2], stats[1])]\n",
    "    losses = [a / n for a, n in zip(stats_train[2], stats_train[1])]\n",
    "\n",
    "    print(\"Averaged Future Train Loss: {:.2f}\".format(train_loss))\n",
    "    print(\"Averaged Future Test Accurancy: {:.2f}%\".format(test_acc*100))\n",
    "    print(\"Std Future Test Accurancy: {:.2f}%\".format(np.std(accs)*100))\n",
    "\n",
    "    if self.detailed_info:\n",
    "      print('Future Clients Train Loss:\\n', [(int(stats[0][idx]), format(loss, '.2f')) for idx, loss in enumerate(losses)])\n",
    "      print('Future Clients Test Accuracy:\\n', [(int(stats[0][idx]), format(acc*100, '.2f')+'%') for idx, acc in enumerate(accs)])\n",
    "\n",
    "    self.ft_train_loss.append(train_loss)\n",
    "    self.ft_test_acc.append(test_acc)\n",
    "    self.ft_std_acc.append(np.std(accs))\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    num_samples = []\n",
    "    tot_recall = []\n",
    "    tot_mrr = []\n",
    "\n",
    "    for c in self.training_clients:\n",
    "      rc, mrr, ns = c.test_metrics_personalized()\n",
    "      tot_recall.append(rc)\n",
    "      tot_mrr.append(mrr)\n",
    "      num_samples.append(ns)\n",
    "\n",
    "    ids = [c.id for c in self.training_clients]\n",
    "    return ids, num_samples, tot_recall, tot_mrr\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    num_samples = []\n",
    "    losses = []\n",
    "    for c in self.training_clients:\n",
    "      cl, ns = c.train_metrics_personalized()\n",
    "      num_samples.append(ns)\n",
    "      losses.append(cl*1.0)\n",
    "\n",
    "    ids = [c.id for c in self.training_clients]\n",
    "    return ids, num_samples, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedCHAR(Server):\n",
    "  def __init__(self, model):\n",
    "    super().__init__(model)\n",
    "\n",
    "    self.set_clients(model, clientCHAR)\n",
    "\n",
    "    print(f\"\\nJoin ratio / total clients: {self.join_ratio} / {self.num_training_clients}\")\n",
    "    print(\"Finished creating server and clients.\")\n",
    "\n",
    "    self.initial_rounds = initial_rounds\n",
    "    self.n_clusters = n_clusters\n",
    "    self.metric = metric\n",
    "    self.linkage = linkage\n",
    "\n",
    "  def train(self):\n",
    "    # initial Stage\n",
    "    for i in range(self.initial_rounds):\n",
    "      self.selected_clients = self.select_clients()\n",
    "      self.send_models()\n",
    "\n",
    "      for client in self.selected_clients:\n",
    "        client.dtrain()\n",
    "\n",
    "      if i%self.eval_gap == 0:\n",
    "        print(f\"\\n-------------Round number: {i}-------------\")\n",
    "        print(\"\\nEvaluate personalized models for training clients.\")\n",
    "        self.evaluate_personalized()\n",
    "\n",
    "      self.receive_models()\n",
    "      self.aggregate_parameters()\n",
    "\n",
    "    # Clustering Stage\n",
    "    print(f\"\\n-------------Clustering-------------\")\n",
    "    clients_updates = self.collect()\n",
    "    self.cluster_identity = self.cluster(clients_updates)\n",
    "    cluster_info = [[('Malicious' if self.training_clients[idx].malicious else 'Benign', idx) for idx, g_id in enumerate(self.cluster_identity) if g_id == i] for i in range(max(self.cluster_identity)+1)]\n",
    "    for idx, info in enumerate(cluster_info):\n",
    "      print('Cluster {}: {}'.format(idx, info))\n",
    "\n",
    "    self.group_models = [copy.deepcopy(self.global_model)] * (max(self.cluster_identity) + 1)\n",
    "\n",
    "    # Remaining Stage\n",
    "    for i in range(self.global_rounds - self.initial_rounds):\n",
    "      self.selected_clients = self.select_clients()\n",
    "      self.send_models_g()\n",
    "\n",
    "      for client in self.selected_clients:\n",
    "        client.dtrain()\n",
    "\n",
    "      if i%self.eval_gap == 0:\n",
    "        print(f\"\\n-------------Round number: {i+self.initial_rounds}-------------\")\n",
    "        print(\"\\nEvaluate personalized models for training clients.\")\n",
    "        self.evaluate_personalized()\n",
    "\n",
    "      self.receive_models_g()\n",
    "      self.aggregate_parameters_g()\n",
    "\n",
    "    print(\"\\nFinal Average Personalized Recall: {}\\n\".format(self.rs_test_recall_p[-1]))\n",
    "    print(f\"Average Recall for All Users: {np.mean(self.rs_test_recall_p[-1])}\")\n",
    "    print(\"\\nFinal Average Personalized Recall: {}\\n\".format(self.rs_test_mrr_p[-1]))\n",
    "    print(f\"Average MRR for All Users: {np.mean(self.rs_test_mrr_p[-1])}\")\n",
    "\n",
    "  def receive_models(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    tot_samples = 0\n",
    "    for client in self.selected_clients:\n",
    "      tot_samples += client.train_samples\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      self.uploaded_updates.append([c_param.data - s_param.data for c_param, s_param in zip(client.model.parameters(), self.global_model.parameters())])\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.uploaded_ids) if c_id in self.malicious_ids]\n",
    "      self.uploaded_updates = eval(self.attack_type)(self.uploaded_updates, malicious_ids)\n",
    "\n",
    "    for i, w in enumerate(self.uploaded_weights):\n",
    "      self.uploaded_weights[i] = w / tot_samples\n",
    "\n",
    "  def add_parameters(self, w, client_update):\n",
    "    for server_param, client_param in zip(self.global_update, client_update):\n",
    "      server_param.data += client_param.data.clone() * w\n",
    "\n",
    "  def aggregate_parameters(self):\n",
    "    self.global_update = copy.deepcopy(self.uploaded_updates[0])\n",
    "    for param in self.global_update:\n",
    "      param.data.zero_()\n",
    "\n",
    "    for w, client_update in zip(self.uploaded_weights, self.uploaded_updates):\n",
    "      self.add_parameters(w, client_update)\n",
    "\n",
    "    for model_param, update_param in zip(self.global_model.parameters(), self.global_update):\n",
    "      model_param.data += update_param.data.clone()\n",
    "\n",
    "  def collect(self):\n",
    "    clients_updates = []\n",
    "    for client in self.training_clients:\n",
    "      clients_updates.append(client.get_update(self.global_model))\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.training_clients_ids) if c_id in self.malicious_ids]\n",
    "      clients_updates = eval(self.attack_type)(clients_updates, malicious_ids, len(self.selected_clients))\n",
    "\n",
    "    clients_updates = [torch.cat([uu.reshape(-1, 1) for uu in u], axis=0).detach().cpu().numpy().squeeze() for u in clients_updates]\n",
    "    return clients_updates\n",
    "\n",
    "  def cluster(self, clients_updates):\n",
    "    clustering = AgglomerativeClustering(n_clusters=self.n_clusters, metric=self.metric, linkage=self.linkage).fit(clients_updates)\n",
    "    return clustering.labels_\n",
    "\n",
    "  def send_models_g(self):\n",
    "    for client in self.selected_clients:\n",
    "      c_idx = list(self.training_clients_ids).index(client.id)\n",
    "      client.set_parameters(self.group_models[self.cluster_identity[c_idx]])\n",
    "\n",
    "  def receive_models_g(self):\n",
    "    self.uploaded_ids = []\n",
    "    self.uploaded_weights = []\n",
    "    self.uploaded_updates = []\n",
    "\n",
    "    for client in self.selected_clients:\n",
    "      self.uploaded_ids.append(client.id)\n",
    "      self.uploaded_weights.append(client.train_samples)\n",
    "      c_idx = list(self.training_clients_ids).index(client.id)\n",
    "      self.uploaded_updates.append([c_param.data - s_param.data for c_param, s_param in zip(client.model.parameters(), self.group_models[self.cluster_identity[c_idx]].parameters())])\n",
    "\n",
    "    if self.attack_type != 'B' and self.attack_type != 'A1':\n",
    "      malicious_ids = [idx for idx, c_id in enumerate(self.uploaded_ids) if c_id in self.malicious_ids]\n",
    "      self.uploaded_updates = eval(self.attack_type)(self.uploaded_updates, malicious_ids)\n",
    "\n",
    "  def aggregate_parameters_g(self):\n",
    "    for i in range(len(self.group_models)):\n",
    "      self.global_update = copy.deepcopy(self.uploaded_updates[0])\n",
    "      for param in self.global_update:\n",
    "        param.data.zero_()\n",
    "\n",
    "      user_idx_in_same_group = np.array([r_id for r_id, c_id in enumerate(self.uploaded_ids) if self.cluster_identity[list(self.training_clients_ids).index(c_id)] == i])\n",
    "      uploaded_weights = [self.uploaded_weights[u_id] for u_id in range(len(self.uploaded_weights)) if u_id in user_idx_in_same_group]\n",
    "      uploaded_weights = [weight / sum(uploaded_weights) for weight in uploaded_weights]\n",
    "      uploaded_updates = [self.uploaded_updates[u_id] for u_id in range(len(self.uploaded_updates)) if u_id in user_idx_in_same_group]\n",
    "\n",
    "      for w, client_update in zip(uploaded_weights, uploaded_updates):\n",
    "        self.add_parameters(w, client_update)\n",
    "\n",
    "      for model_param, update_param in zip(self.group_models[i].parameters(), self.global_update):\n",
    "        model_param.data += update_param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating server and clients ...\n",
      "LSTMModel(\n",
      "  (embedding): Embedding(889, 100)\n",
      "  (lstm): LSTM(100, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=889, bias=True)\n",
      ")\n",
      "Malicious Clients: []\n",
      "Future Clients: []\n",
      "\n",
      "Join ratio / total clients: 1.0 / 45\n",
      "Finished creating server and clients.\n",
      "loss: -171.93251037597656\n",
      "loss: -326.71661376953125\n",
      "loss: -290.0793762207031\n",
      "loss: -135.84202575683594\n",
      "loss: -172.8736114501953\n",
      "loss: -386.22613525390625\n",
      "loss: -292.8441162109375\n",
      "loss: -223.5255126953125\n",
      "loss: -298.7701416015625\n",
      "loss: -208.58302307128906\n",
      "loss: -163.14146423339844\n",
      "loss: -165.4900665283203\n",
      "loss: -226.43844604492188\n",
      "loss: -188.77316284179688\n",
      "loss: -323.55255126953125\n",
      "loss: -167.89459228515625\n",
      "loss: -167.63380432128906\n",
      "loss: -237.8425750732422\n",
      "loss: -183.9105224609375\n",
      "loss: -268.3379821777344\n",
      "loss: -317.7210388183594\n",
      "loss: -444.0528564453125\n",
      "loss: -177.93954467773438\n",
      "loss: -264.158203125\n",
      "loss: -454.48199462890625\n",
      "loss: -230.03326416015625\n",
      "loss: -211.86734008789062\n",
      "loss: -296.6644287109375\n",
      "loss: -337.5416564941406\n",
      "loss: -267.1913146972656\n",
      "loss: -208.23455810546875\n",
      "loss: -183.08462524414062\n",
      "loss: -180.2171173095703\n",
      "loss: -126.02967834472656\n",
      "loss: -223.76687622070312\n",
      "loss: -233.12557983398438\n",
      "loss: -457.37506103515625\n",
      "loss: -221.0449676513672\n",
      "loss: -194.50946044921875\n",
      "loss: -272.9093322753906\n",
      "loss: -180.53970336914062\n",
      "loss: -450.046630859375\n",
      "loss: -393.7122497558594\n",
      "loss: -215.20370483398438\n",
      "loss: -291.01275634765625\n",
      "loss: -198.03363037109375\n",
      "loss: -246.93112182617188\n",
      "loss: -265.6092224121094\n",
      "loss: -346.10174560546875\n",
      "loss: -262.8673095703125\n",
      "loss: -207.6462860107422\n",
      "loss: -153.75051879882812\n",
      "\n",
      "-------------Round number: 0-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -262.88\n",
      "Benign Averaged Test Recall: 40.78%\n",
      "Benign Std Test Recall: 44.75%\n",
      "Benign Averaged Test MRR: 25.36%\n",
      "Benign Std Test MRR: 35.01%\n",
      "loss: -249.73643493652344\n",
      "loss: -385.2943420410156\n",
      "loss: -364.3679504394531\n",
      "loss: -311.3943786621094\n",
      "loss: -242.60304260253906\n",
      "loss: -176.60389709472656\n",
      "loss: -254.23683166503906\n",
      "loss: -209.24053955078125\n",
      "loss: -300.94439697265625\n",
      "loss: -203.3483428955078\n",
      "loss: -464.71478271484375\n",
      "loss: -320.79193115234375\n",
      "loss: -462.28955078125\n",
      "loss: -216.05377197265625\n",
      "loss: -627.6818237304688\n",
      "loss: -304.99444580078125\n",
      "loss: -134.7533416748047\n",
      "loss: -292.00946044921875\n",
      "loss: -331.0118103027344\n",
      "loss: -454.56640625\n",
      "loss: -143.04547119140625\n",
      "loss: -833.4853515625\n",
      "loss: -186.6312713623047\n",
      "loss: -301.4709167480469\n",
      "loss: -265.40380859375\n",
      "loss: -230.45448303222656\n",
      "loss: -190.18966674804688\n",
      "loss: -828.4427490234375\n",
      "loss: -212.914306640625\n",
      "loss: -259.3756408691406\n",
      "loss: -246.73492431640625\n",
      "loss: -180.85975646972656\n",
      "loss: -177.48443603515625\n",
      "loss: -269.21624755859375\n",
      "loss: -328.6937561035156\n",
      "loss: -246.61676025390625\n",
      "loss: -392.9029235839844\n",
      "loss: -403.2064514160156\n",
      "loss: -201.72088623046875\n",
      "loss: -464.1524963378906\n",
      "loss: -177.34518432617188\n",
      "loss: -317.09912109375\n",
      "loss: -563.3578491210938\n",
      "loss: -386.4898986816406\n",
      "loss: -239.3223114013672\n",
      "loss: -514.5185546875\n",
      "loss: -401.86767578125\n",
      "loss: -157.32241821289062\n",
      "loss: -451.70672607421875\n",
      "loss: -245.7325897216797\n",
      "loss: -200.87942504882812\n",
      "loss: -213.775146484375\n",
      "\n",
      "-------------Round number: 1-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -292.44\n",
      "Benign Averaged Test Recall: 48.54%\n",
      "Benign Std Test Recall: 46.09%\n",
      "Benign Averaged Test MRR: 26.39%\n",
      "Benign Std Test MRR: 35.11%\n",
      "loss: -179.02151489257812\n",
      "loss: -312.4706115722656\n",
      "loss: -187.58685302734375\n",
      "loss: -264.6131896972656\n",
      "loss: -372.4178161621094\n",
      "loss: -159.3323211669922\n",
      "loss: -375.0705261230469\n",
      "loss: -338.26220703125\n",
      "loss: -297.0355224609375\n",
      "loss: -219.0946502685547\n",
      "loss: -244.524658203125\n",
      "loss: -262.431884765625\n",
      "loss: -286.004638671875\n",
      "loss: -505.3910217285156\n",
      "loss: -605.0740356445312\n",
      "loss: -452.96893310546875\n",
      "loss: -550.2704467773438\n",
      "loss: -861.0576782226562\n",
      "loss: -748.03466796875\n",
      "loss: -434.56195068359375\n",
      "loss: -255.67352294921875\n",
      "loss: -193.56414794921875\n",
      "loss: -224.1649627685547\n",
      "loss: -333.0877685546875\n",
      "loss: -143.73947143554688\n",
      "loss: -864.772705078125\n",
      "loss: -200.77981567382812\n",
      "loss: -203.30421447753906\n",
      "loss: -309.121337890625\n",
      "loss: -189.50192260742188\n",
      "loss: -381.5755615234375\n",
      "loss: -329.3951110839844\n",
      "loss: -681.650634765625\n",
      "loss: -279.6617126464844\n",
      "loss: -208.998046875\n",
      "loss: -396.56011962890625\n",
      "loss: -221.65264892578125\n",
      "loss: -295.7402648925781\n",
      "loss: -544.70849609375\n",
      "loss: -575.4759521484375\n",
      "loss: -150.35813903808594\n",
      "loss: -261.172607421875\n",
      "loss: -290.4101257324219\n",
      "loss: -466.1360778808594\n",
      "loss: -476.9803466796875\n",
      "loss: -190.05865478515625\n",
      "loss: -265.7650451660156\n",
      "loss: -436.6002502441406\n",
      "loss: -351.0639343261719\n",
      "loss: -252.8933868408203\n",
      "loss: -301.62200927734375\n",
      "loss: -294.6139221191406\n",
      "\n",
      "-------------Round number: 2-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -319.84\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.68%\n",
      "Benign Averaged Test MRR: 26.88%\n",
      "Benign Std Test MRR: 34.25%\n",
      "loss: -199.296875\n",
      "loss: -326.0953369140625\n",
      "loss: -640.8905639648438\n",
      "loss: -807.7472534179688\n",
      "loss: -217.35569763183594\n",
      "loss: -202.23703002929688\n",
      "loss: -158.51841735839844\n",
      "loss: -870.9332275390625\n",
      "loss: -236.9555206298828\n",
      "loss: -382.7939453125\n",
      "loss: -420.4005126953125\n",
      "loss: -279.7750244140625\n",
      "loss: -306.2489013671875\n",
      "loss: -873.5145874023438\n",
      "loss: -345.7887268066406\n",
      "loss: -233.9811553955078\n",
      "loss: -219.0084228515625\n",
      "loss: -274.9764099121094\n",
      "loss: -290.1327819824219\n",
      "loss: -361.8036193847656\n",
      "loss: -219.971923828125\n",
      "loss: -684.4457397460938\n",
      "loss: -370.97100830078125\n",
      "loss: -321.4671936035156\n",
      "loss: -342.47100830078125\n",
      "loss: -199.7625732421875\n",
      "loss: -154.09999084472656\n",
      "loss: -237.60487365722656\n",
      "loss: -359.1545104980469\n",
      "loss: -501.94921875\n",
      "loss: -372.844970703125\n",
      "loss: -490.9971923828125\n",
      "loss: -283.6297912597656\n",
      "loss: -350.2224426269531\n",
      "loss: -277.4842529296875\n",
      "loss: -515.52197265625\n",
      "loss: -461.287109375\n",
      "loss: -205.02574157714844\n",
      "loss: -287.18634033203125\n",
      "loss: -286.87860107421875\n",
      "loss: -640.3113403320312\n",
      "loss: -639.97802734375\n",
      "loss: -398.13250732421875\n",
      "loss: -524.9681396484375\n",
      "loss: -495.1168518066406\n",
      "loss: -228.125244140625\n",
      "loss: -181.86141967773438\n",
      "loss: -420.73443603515625\n",
      "loss: -635.70703125\n",
      "loss: -318.67279052734375\n",
      "loss: -489.3263854980469\n",
      "loss: -313.4123840332031\n",
      "\n",
      "-------------Round number: 3-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -347.67\n",
      "Benign Averaged Test Recall: 49.51%\n",
      "Benign Std Test Recall: 45.72%\n",
      "Benign Averaged Test MRR: 28.17%\n",
      "Benign Std Test MRR: 35.63%\n",
      "loss: -246.69488525390625\n",
      "loss: -837.1432495117188\n",
      "loss: -325.2151794433594\n",
      "loss: -255.60035705566406\n",
      "loss: -360.9153747558594\n",
      "loss: -459.97210693359375\n",
      "loss: -238.41790771484375\n",
      "loss: -166.4781951904297\n",
      "loss: -315.21356201171875\n",
      "loss: -256.0101623535156\n",
      "loss: -391.8775634765625\n",
      "loss: -168.0884246826172\n",
      "loss: -432.8779296875\n",
      "loss: -155.9297332763672\n",
      "loss: -393.811767578125\n",
      "loss: -875.7391357421875\n",
      "loss: -541.9353637695312\n",
      "loss: -381.5757141113281\n",
      "loss: -213.04331970214844\n",
      "loss: -318.6744689941406\n",
      "loss: -330.8804626464844\n",
      "loss: -707.1885375976562\n",
      "loss: -382.0481872558594\n",
      "loss: -423.9878234863281\n",
      "loss: -735.7484741210938\n",
      "loss: -298.89239501953125\n",
      "loss: -223.36680603027344\n",
      "loss: -213.60267639160156\n",
      "loss: -304.62945556640625\n",
      "loss: -648.0208740234375\n",
      "loss: -327.6130065917969\n",
      "loss: -560.8345947265625\n",
      "loss: -499.82940673828125\n",
      "loss: -558.5896606445312\n",
      "loss: -877.65673828125\n",
      "loss: -227.609619140625\n",
      "loss: -211.9656982421875\n",
      "loss: -316.121826171875\n",
      "loss: -434.8323669433594\n",
      "loss: -410.5091247558594\n",
      "loss: -303.45989990234375\n",
      "loss: -579.6731567382812\n",
      "loss: -257.67333984375\n",
      "loss: -707.5552978515625\n",
      "loss: -552.0184326171875\n",
      "loss: -537.2252197265625\n",
      "loss: -671.717529296875\n",
      "loss: -311.9951477050781\n",
      "loss: -254.3029327392578\n",
      "loss: -348.39453125\n",
      "loss: -391.2712097167969\n",
      "loss: -318.044677734375\n",
      "\n",
      "-------------Round number: 4-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -364.90\n",
      "Benign Averaged Test Recall: 56.31%\n",
      "Benign Std Test Recall: 45.45%\n",
      "Benign Averaged Test MRR: 29.51%\n",
      "Benign Std Test MRR: 33.70%\n",
      "loss: -424.1560363769531\n",
      "loss: -225.86776733398438\n",
      "loss: -277.8796081542969\n",
      "loss: -431.3303527832031\n",
      "loss: -228.05255126953125\n",
      "loss: -395.1344909667969\n",
      "loss: -219.95037841796875\n",
      "loss: -674.94140625\n",
      "loss: -353.80059814453125\n",
      "loss: -260.92315673828125\n",
      "loss: -880.0269165039062\n",
      "loss: -348.567626953125\n",
      "loss: -466.125732421875\n",
      "loss: -327.27935791015625\n",
      "loss: -228.41400146484375\n",
      "loss: -682.8009033203125\n",
      "loss: -389.4302978515625\n",
      "loss: -444.4505310058594\n",
      "loss: -560.3768310546875\n",
      "loss: -245.1494598388672\n",
      "loss: -487.4110412597656\n",
      "loss: -738.5174560546875\n",
      "loss: -278.29833984375\n",
      "loss: -323.8949279785156\n",
      "loss: -587.6942749023438\n",
      "loss: -378.9284362792969\n",
      "loss: -332.32733154296875\n",
      "loss: -240.14566040039062\n",
      "loss: -566.163330078125\n",
      "loss: -587.5709228515625\n",
      "loss: -262.9654541015625\n",
      "loss: -852.7809448242188\n",
      "loss: -475.0740661621094\n",
      "loss: -274.77777099609375\n",
      "loss: -878.5338134765625\n",
      "loss: -737.8900146484375\n",
      "loss: -180.79054260253906\n",
      "loss: -347.1316223144531\n",
      "loss: -372.28765869140625\n",
      "loss: -397.33074951171875\n",
      "loss: -592.1994018554688\n",
      "loss: -514.71533203125\n",
      "loss: -403.1285095214844\n",
      "loss: -301.8725891113281\n",
      "loss: -312.3616638183594\n",
      "loss: -459.3130798339844\n",
      "loss: -411.3816223144531\n",
      "loss: -442.2675476074219\n",
      "loss: -334.98809814453125\n",
      "loss: -349.5908203125\n",
      "loss: -653.7927856445312\n",
      "loss: -179.5303955078125\n",
      "\n",
      "-------------Round number: 5-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -389.75\n",
      "Benign Averaged Test Recall: 57.28%\n",
      "Benign Std Test Recall: 44.80%\n",
      "Benign Averaged Test MRR: 29.47%\n",
      "Benign Std Test MRR: 33.48%\n",
      "loss: -283.4913024902344\n",
      "loss: -376.45843505859375\n",
      "loss: -330.82110595703125\n",
      "loss: -441.0848388671875\n",
      "loss: -268.03741455078125\n",
      "loss: -192.71690368652344\n",
      "loss: -381.5129089355469\n",
      "loss: -567.2838745117188\n",
      "loss: -282.1969909667969\n",
      "loss: -244.58181762695312\n",
      "loss: -571.7081298828125\n",
      "loss: -503.7542724609375\n",
      "loss: -491.559814453125\n",
      "loss: -227.03909301757812\n",
      "loss: -528.1385498046875\n",
      "loss: -385.91448974609375\n",
      "loss: -434.5437927246094\n",
      "loss: -623.1910400390625\n",
      "loss: -386.6424865722656\n",
      "loss: -289.0729675292969\n",
      "loss: -240.61093139648438\n",
      "loss: -195.87364196777344\n",
      "loss: -297.0330810546875\n",
      "loss: -472.9328918457031\n",
      "loss: -348.4383544921875\n",
      "loss: -352.21923828125\n",
      "loss: -334.0688171386719\n",
      "loss: -687.3799438476562\n",
      "loss: -520.799072265625\n",
      "loss: -412.93780517578125\n",
      "loss: -881.538818359375\n",
      "loss: -356.8343505859375\n",
      "loss: -749.7627563476562\n",
      "loss: -499.5199279785156\n",
      "loss: -880.3345947265625\n",
      "loss: -448.2339172363281\n",
      "loss: -356.56121826171875\n",
      "loss: -670.8682250976562\n",
      "loss: -605.90380859375\n",
      "loss: -401.3726501464844\n",
      "loss: -426.3673400878906\n",
      "loss: -302.11773681640625\n",
      "loss: -254.6009521484375\n",
      "loss: -573.80419921875\n",
      "loss: -382.3482971191406\n",
      "loss: -750.3959350585938\n",
      "loss: -368.5373840332031\n",
      "loss: -244.76878356933594\n",
      "loss: -619.0116577148438\n",
      "loss: -356.8425598144531\n",
      "loss: -656.9185791015625\n",
      "loss: -861.83251953125\n",
      "\n",
      "-------------Round number: 6-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -395.96\n",
      "Benign Averaged Test Recall: 55.34%\n",
      "Benign Std Test Recall: 45.53%\n",
      "Benign Averaged Test MRR: 28.90%\n",
      "Benign Std Test MRR: 33.74%\n",
      "loss: -408.5316467285156\n",
      "loss: -435.2620544433594\n",
      "loss: -358.6379699707031\n",
      "loss: -503.9449157714844\n",
      "loss: -302.9795837402344\n",
      "loss: -409.3623352050781\n",
      "loss: -755.4140625\n",
      "loss: -507.8926696777344\n",
      "loss: -417.5655822753906\n",
      "loss: -335.3487854003906\n",
      "loss: -658.809814453125\n",
      "loss: -270.0762939453125\n",
      "loss: -432.607666015625\n",
      "loss: -377.71142578125\n",
      "loss: -832.0379638671875\n",
      "loss: -578.25927734375\n",
      "loss: -261.0140686035156\n",
      "loss: -511.3575744628906\n",
      "loss: -355.5662841796875\n",
      "loss: -399.673583984375\n",
      "loss: -217.3802947998047\n",
      "loss: -362.20635986328125\n",
      "loss: -298.2364196777344\n",
      "loss: -450.7873229980469\n",
      "loss: -449.0417175292969\n",
      "loss: -755.1353149414062\n",
      "loss: -393.7938232421875\n",
      "loss: -321.7244873046875\n",
      "loss: -325.31829833984375\n",
      "loss: -867.48486328125\n",
      "loss: -395.2247619628906\n",
      "loss: -375.1028747558594\n",
      "loss: -508.13592529296875\n",
      "loss: -389.17437744140625\n",
      "loss: -750.5028686523438\n",
      "loss: -636.2296752929688\n",
      "loss: -255.03004455566406\n",
      "loss: -512.851806640625\n",
      "loss: -382.9363098144531\n",
      "loss: -209.8009033203125\n",
      "loss: -577.53564453125\n",
      "loss: -206.85040283203125\n",
      "loss: -302.5307922363281\n",
      "loss: -882.5758056640625\n",
      "loss: -881.5775146484375\n",
      "loss: -262.1004943847656\n",
      "loss: -313.5973205566406\n",
      "loss: -523.8565673828125\n",
      "loss: -415.75341796875\n",
      "loss: -287.8435363769531\n",
      "loss: -689.7359008789062\n",
      "loss: -615.5502319335938\n",
      "\n",
      "-------------Round number: 7-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -408.37\n",
      "Benign Averaged Test Recall: 52.43%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 28.35%\n",
      "Benign Std Test MRR: 33.71%\n",
      "loss: -439.4093322753906\n",
      "loss: -616.5215454101562\n",
      "loss: -517.1920776367188\n",
      "loss: -425.5050964355469\n",
      "loss: -338.0670471191406\n",
      "loss: -221.06097412109375\n",
      "loss: -249.37559509277344\n",
      "loss: -615.4890747070312\n",
      "loss: -359.4525146484375\n",
      "loss: -321.8216247558594\n",
      "loss: -303.7641296386719\n",
      "loss: -268.321533203125\n",
      "loss: -466.0652160644531\n",
      "loss: -331.3541564941406\n",
      "loss: -402.7845153808594\n",
      "loss: -758.01806640625\n",
      "loss: -620.5408325195312\n",
      "loss: -345.3070983886719\n",
      "loss: -278.6365661621094\n",
      "loss: -421.7407531738281\n",
      "loss: -757.9769287109375\n",
      "loss: -386.8397216796875\n",
      "loss: -301.9896240234375\n",
      "loss: -871.2443237304688\n",
      "loss: -420.0122375488281\n",
      "loss: -581.06201171875\n",
      "loss: -644.7323608398438\n",
      "loss: -691.1378784179688\n",
      "loss: -525.6371459960938\n",
      "loss: -660.0515747070312\n",
      "loss: -285.69927978515625\n",
      "loss: -318.103759765625\n",
      "loss: -580.8614501953125\n",
      "loss: -883.3250732421875\n",
      "loss: -402.41448974609375\n",
      "loss: -436.0673828125\n",
      "loss: -397.9659423828125\n",
      "loss: -392.7794494628906\n",
      "loss: -882.4791259765625\n",
      "loss: -220.65164184570312\n",
      "loss: -364.29302978515625\n",
      "loss: -429.9219665527344\n",
      "loss: -782.7396850585938\n",
      "loss: -453.1588134765625\n",
      "loss: -517.3688354492188\n",
      "loss: -416.6318054199219\n",
      "loss: -277.229736328125\n",
      "loss: -424.26861572265625\n",
      "loss: -327.2165222167969\n",
      "loss: -530.6210327148438\n",
      "loss: -425.4798583984375\n",
      "loss: -518.0335693359375\n",
      "\n",
      "-------------Round number: 8-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -420.20\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 28.56%\n",
      "Benign Std Test MRR: 35.15%\n",
      "loss: -291.97918701171875\n",
      "loss: -393.8717346191406\n",
      "loss: -421.4561767578125\n",
      "loss: -660.9179077148438\n",
      "loss: -359.84478759765625\n",
      "loss: -307.0890808105469\n",
      "loss: -582.9406127929688\n",
      "loss: -429.5902404785156\n",
      "loss: -464.39288330078125\n",
      "loss: -465.40521240234375\n",
      "loss: -520.7664184570312\n",
      "loss: -582.9430541992188\n",
      "loss: -526.7813110351562\n",
      "loss: -759.486328125\n",
      "loss: -455.5513916015625\n",
      "loss: -649.1920776367188\n",
      "loss: -759.7639770507812\n",
      "loss: -230.41574096679688\n",
      "loss: -433.2257995605469\n",
      "loss: -328.7582092285156\n",
      "loss: -313.82904052734375\n",
      "loss: -501.99322509765625\n",
      "loss: -789.0534057617188\n",
      "loss: -873.8751220703125\n",
      "loss: -232.8032684326172\n",
      "loss: -429.2796325683594\n",
      "loss: -300.7710266113281\n",
      "loss: -623.3380737304688\n",
      "loss: -428.12713623046875\n",
      "loss: -280.3067932128906\n",
      "loss: -399.9282531738281\n",
      "loss: -487.3761291503906\n",
      "loss: -310.9766845703125\n",
      "loss: -455.6089782714844\n",
      "loss: -338.696533203125\n",
      "loss: -293.3962097167969\n",
      "loss: -474.3702392578125\n",
      "loss: -521.1757202148438\n",
      "loss: -692.0557250976562\n",
      "loss: -338.39495849609375\n",
      "loss: -522.0152587890625\n",
      "loss: -361.74664306640625\n",
      "loss: -883.888427734375\n",
      "loss: -339.7231750488281\n",
      "loss: -427.7489318847656\n",
      "loss: -883.15869140625\n",
      "loss: -543.2498779296875\n",
      "loss: -435.09747314453125\n",
      "loss: -414.9795227050781\n",
      "loss: -229.33753967285156\n",
      "loss: -419.93511962890625\n",
      "loss: -693.1690673828125\n",
      "\n",
      "-------------Round number: 9-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -425.20\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 28.56%\n",
      "Benign Std Test MRR: 35.15%\n",
      "\n",
      "-------------Clustering-------------\n",
      "Cluster 0: [('Benign', 2), ('Benign', 4), ('Benign', 11), ('Benign', 13), ('Benign', 19), ('Benign', 20), ('Benign', 24), ('Benign', 27), ('Benign', 28), ('Benign', 29), ('Benign', 30), ('Benign', 31), ('Benign', 33), ('Benign', 34), ('Benign', 35)]\n",
      "Cluster 1: [('Benign', 6), ('Benign', 9), ('Benign', 16), ('Benign', 22), ('Benign', 38), ('Benign', 40), ('Benign', 43)]\n",
      "Cluster 2: [('Benign', 1), ('Benign', 12), ('Benign', 14), ('Benign', 15), ('Benign', 18), ('Benign', 25), ('Benign', 26), ('Benign', 32), ('Benign', 42)]\n",
      "Cluster 3: [('Benign', 0), ('Benign', 3), ('Benign', 5), ('Benign', 7), ('Benign', 8), ('Benign', 10), ('Benign', 17), ('Benign', 21), ('Benign', 23), ('Benign', 36), ('Benign', 37), ('Benign', 39), ('Benign', 41), ('Benign', 44)]\n",
      "loss: -409.0384216308594\n",
      "loss: -568.5885620117188\n",
      "loss: -692.6975708007812\n",
      "loss: -584.265869140625\n",
      "loss: -314.705322265625\n",
      "loss: -291.0812072753906\n",
      "loss: -422.4808654785156\n",
      "loss: -303.61798095703125\n",
      "loss: -431.6728210449219\n",
      "loss: -363.20947265625\n",
      "loss: -422.3847961425781\n",
      "loss: -335.6980895996094\n",
      "loss: -413.9759521484375\n",
      "loss: -418.7561340332031\n",
      "loss: -807.1063842773438\n",
      "loss: -523.20947265625\n",
      "loss: -550.2019653320312\n",
      "loss: -457.0751953125\n",
      "loss: -367.9739990234375\n",
      "loss: -413.5213623046875\n",
      "loss: -316.5234680175781\n",
      "loss: -522.8758544921875\n",
      "loss: -459.0564880371094\n",
      "loss: -371.0378112792969\n",
      "loss: -644.0016479492188\n",
      "loss: -242.48341369628906\n",
      "loss: -347.3985900878906\n",
      "loss: -625.0538940429688\n",
      "loss: -584.3421630859375\n",
      "loss: -527.5690307617188\n",
      "loss: -524.7666625976562\n",
      "loss: -352.7023620605469\n",
      "loss: -263.87237548828125\n",
      "loss: -572.8848266601562\n",
      "loss: -760.9146118164062\n",
      "loss: -760.4666137695312\n",
      "loss: -884.3253173828125\n",
      "loss: -368.9656982421875\n",
      "loss: -309.1667785644531\n",
      "loss: -661.55078125\n",
      "loss: -305.86358642578125\n",
      "loss: -432.3546447753906\n",
      "loss: -398.1191711425781\n",
      "loss: -883.686279296875\n",
      "loss: -481.8833923339844\n",
      "loss: -875.7933349609375\n",
      "loss: -478.9095153808594\n",
      "loss: -340.7852478027344\n",
      "loss: -434.69769287109375\n",
      "loss: -440.50506591796875\n",
      "loss: -235.1532745361328\n",
      "loss: -651.7855224609375\n",
      "\n",
      "-------------Round number: 10-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -425.81\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.53%\n",
      "Benign Std Test MRR: 35.85%\n",
      "loss: -363.9281921386719\n",
      "loss: -554.2870483398438\n",
      "loss: -364.2033386230469\n",
      "loss: -458.11444091796875\n",
      "loss: -585.2396240234375\n",
      "loss: -439.0531311035156\n",
      "loss: -320.0341491699219\n",
      "loss: -528.1396484375\n",
      "loss: -884.6729125976562\n",
      "loss: -524.601806640625\n",
      "loss: -761.1484985351562\n",
      "loss: -526.4721069335938\n",
      "loss: -254.09278869628906\n",
      "loss: -637.922119140625\n",
      "loss: -433.8312072753906\n",
      "loss: -884.1063232421875\n",
      "loss: -327.11907958984375\n",
      "loss: -340.10064697265625\n",
      "loss: -693.1691284179688\n",
      "loss: -354.2716979980469\n",
      "loss: -662.030517578125\n",
      "loss: -400.8028259277344\n",
      "loss: -524.2841796875\n",
      "loss: -761.7213134765625\n",
      "loss: -423.02197265625\n",
      "loss: -481.5821838378906\n",
      "loss: -239.1953582763672\n",
      "loss: -513.3024291992188\n",
      "loss: -360.8429870605469\n",
      "loss: -533.2411499023438\n",
      "loss: -300.6584777832031\n",
      "loss: -434.3495788574219\n",
      "loss: -311.6007080078125\n",
      "loss: -316.03802490234375\n",
      "loss: -310.5326232910156\n",
      "loss: -626.1876831054688\n",
      "loss: -585.335205078125\n",
      "loss: -249.63072204589844\n",
      "loss: -424.54852294921875\n",
      "loss: -685.8592529296875\n",
      "loss: -426.9631652832031\n",
      "loss: -341.5044250488281\n",
      "loss: -434.7783508300781\n",
      "loss: -456.6715087890625\n",
      "loss: -834.92724609375\n",
      "loss: -877.2391357421875\n",
      "loss: -307.12957763671875\n",
      "loss: -497.5888977050781\n",
      "loss: -503.22515869140625\n",
      "loss: -653.4339599609375\n",
      "loss: -443.72491455078125\n",
      "loss: -374.3952941894531\n",
      "\n",
      "-------------Round number: 11-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -431.51\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.72%\n",
      "Benign Std Test MRR: 36.04%\n",
      "loss: -429.7693176269531\n",
      "loss: -445.7886047363281\n",
      "loss: -311.4821472167969\n",
      "loss: -359.4833984375\n",
      "loss: -478.72723388671875\n",
      "loss: -508.9579772949219\n",
      "loss: -337.90509033203125\n",
      "loss: -884.453369140625\n",
      "loss: -693.534423828125\n",
      "loss: -377.72491455078125\n",
      "loss: -434.94976806640625\n",
      "loss: -611.9230346679688\n",
      "loss: -254.7110137939453\n",
      "loss: -364.9174499511719\n",
      "loss: -626.9869384765625\n",
      "loss: -586.078125\n",
      "loss: -527.6146240234375\n",
      "loss: -654.5610961914062\n",
      "loss: -221.4503631591797\n",
      "loss: -497.75177001953125\n",
      "loss: -359.239501953125\n",
      "loss: -884.9608154296875\n",
      "loss: -435.2564697265625\n",
      "loss: -761.6510009765625\n",
      "loss: -324.1649169921875\n",
      "loss: -520.1676635742188\n",
      "loss: -556.8855590820312\n",
      "loss: -762.319091796875\n",
      "loss: -372.7408752441406\n",
      "loss: -316.7016906738281\n",
      "loss: -342.018798828125\n",
      "loss: -878.3688354492188\n",
      "loss: -525.2848510742188\n",
      "loss: -528.5777587890625\n",
      "loss: -435.7232360839844\n",
      "loss: -531.9588623046875\n",
      "loss: -348.01422119140625\n",
      "loss: -773.3795776367188\n",
      "loss: -585.986328125\n",
      "loss: -483.29095458984375\n",
      "loss: -525.6068115234375\n",
      "loss: -441.8790588378906\n",
      "loss: -308.94866943359375\n",
      "loss: -402.5968322753906\n",
      "loss: -423.4856872558594\n",
      "loss: -460.2209777832031\n",
      "loss: -409.7049865722656\n",
      "loss: -322.3658142089844\n",
      "loss: -458.8681335449219\n",
      "loss: -242.0202178955078\n",
      "loss: -662.41552734375\n",
      "loss: -342.9567565917969\n",
      "\n",
      "-------------Round number: 12-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -428.75\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.72%\n",
      "Benign Std Test MRR: 36.04%\n",
      "loss: -627.5769653320312\n",
      "loss: -762.0372314453125\n",
      "loss: -655.3739624023438\n",
      "loss: -334.25018310546875\n",
      "loss: -450.8993225097656\n",
      "loss: -403.8552551269531\n",
      "loss: -762.7792358398438\n",
      "loss: -244.0160369873047\n",
      "loss: -379.5989990234375\n",
      "loss: -447.1958312988281\n",
      "loss: -420.9228820800781\n",
      "loss: -429.5159912109375\n",
      "loss: -880.867431640625\n",
      "loss: -431.6247253417969\n",
      "loss: -884.7451782226562\n",
      "loss: -315.84527587890625\n",
      "loss: -693.8267822265625\n",
      "loss: -436.2565612792969\n",
      "loss: -362.7204895019531\n",
      "loss: -323.9886474609375\n",
      "loss: -365.4519958496094\n",
      "loss: -528.926025390625\n",
      "loss: -484.4588317871094\n",
      "loss: -344.8836975097656\n",
      "loss: -586.5748291015625\n",
      "loss: -885.203125\n",
      "loss: -528.4261474609375\n",
      "loss: -319.95758056640625\n",
      "loss: -586.6539916992188\n",
      "loss: -423.83734130859375\n",
      "loss: -312.1728210449219\n",
      "loss: -436.7131042480469\n",
      "loss: -342.4021301269531\n",
      "loss: -662.7322998046875\n",
      "loss: -380.016845703125\n",
      "loss: -448.7884216308594\n",
      "loss: -716.46923828125\n",
      "loss: -258.2875671386719\n",
      "loss: -459.43792724609375\n",
      "loss: -558.6498413085938\n",
      "loss: -526.3599853515625\n",
      "loss: -443.79132080078125\n",
      "loss: -330.4765930175781\n",
      "loss: -347.0509948730469\n",
      "loss: -533.168701171875\n",
      "loss: -879.2716674804688\n",
      "loss: -379.8824462890625\n",
      "loss: -526.0277709960938\n",
      "loss: -322.29205322265625\n",
      "loss: -446.7380065917969\n",
      "loss: -402.4284973144531\n",
      "loss: -869.86474609375\n",
      "\n",
      "-------------Round number: 13-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.81\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.64%\n",
      "Benign Std Test MRR: 36.06%\n",
      "loss: -342.6982727050781\n",
      "loss: -432.91693115234375\n",
      "loss: -365.160888671875\n",
      "loss: -462.1922912597656\n",
      "loss: -431.7328796386719\n",
      "loss: -834.561767578125\n",
      "loss: -485.3009948730469\n",
      "loss: -559.913818359375\n",
      "loss: -459.88494873046875\n",
      "loss: -763.14501953125\n",
      "loss: -424.1136169433594\n",
      "loss: -197.56491088867188\n",
      "loss: -723.4164428710938\n",
      "loss: -529.030029296875\n",
      "loss: -335.22845458984375\n",
      "loss: -354.5501403808594\n",
      "loss: -880.0077514648438\n",
      "loss: -542.581298828125\n",
      "loss: -312.6937255859375\n",
      "loss: -526.943115234375\n",
      "loss: -260.83074951171875\n",
      "loss: -436.1817932128906\n",
      "loss: -599.7702026367188\n",
      "loss: -885.4102172851562\n",
      "loss: -655.9867553710938\n",
      "loss: -448.20660400390625\n",
      "loss: -587.050048828125\n",
      "loss: -694.0676879882812\n",
      "loss: -628.0302124023438\n",
      "loss: -245.45285034179688\n",
      "loss: -322.1109619140625\n",
      "loss: -404.7766418457031\n",
      "loss: -436.9937744140625\n",
      "loss: -437.4552307128906\n",
      "loss: -384.9494323730469\n",
      "loss: -351.1019287109375\n",
      "loss: -450.51861572265625\n",
      "loss: -581.623291015625\n",
      "loss: -762.3442993164062\n",
      "loss: -662.99951171875\n",
      "loss: -346.242431640625\n",
      "loss: -587.1136474609375\n",
      "loss: -381.3623962402344\n",
      "loss: -526.60009765625\n",
      "loss: -365.8663024902344\n",
      "loss: -321.3202819824219\n",
      "loss: -433.9546203613281\n",
      "loss: -444.8157043457031\n",
      "loss: -445.1435241699219\n",
      "loss: -325.1648254394531\n",
      "loss: -529.2118530273438\n",
      "loss: -884.9943237304688\n",
      "\n",
      "-------------Round number: 14-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -437.43\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.08%\n",
      "Benign Std Test MRR: 34.75%\n",
      "loss: -325.4833068847656\n",
      "loss: -762.5958862304688\n",
      "loss: -763.4443359375\n",
      "loss: -326.0490417480469\n",
      "loss: -246.5115203857422\n",
      "loss: -382.4299011230469\n",
      "loss: -366.9067077636719\n",
      "loss: -469.4932556152344\n",
      "loss: -521.5473022460938\n",
      "loss: -350.9719543457031\n",
      "loss: -449.9478454589844\n",
      "loss: -546.4508666992188\n",
      "loss: -433.8580627441406\n",
      "loss: -389.1512145996094\n",
      "loss: -313.0996398925781\n",
      "loss: -405.47576904296875\n",
      "loss: -437.5588684082031\n",
      "loss: -628.3904418945312\n",
      "loss: -885.2101440429688\n",
      "loss: -342.93359375\n",
      "loss: -587.490478515625\n",
      "loss: -529.4528198242188\n",
      "loss: -446.1390075683594\n",
      "loss: -587.442138671875\n",
      "loss: -549.09033203125\n",
      "loss: -485.9353332519531\n",
      "loss: -663.2298583984375\n",
      "loss: -416.15460205078125\n",
      "loss: -466.3757019042969\n",
      "loss: -262.6745300292969\n",
      "loss: -527.4070434570312\n",
      "loss: -474.5549011230469\n",
      "loss: -333.1899719238281\n",
      "loss: -876.6278076171875\n",
      "loss: -360.4373474121094\n",
      "loss: -366.1968994140625\n",
      "loss: -694.271240234375\n",
      "loss: -885.5899047851562\n",
      "loss: -448.96435546875\n",
      "loss: -347.2398986816406\n",
      "loss: -338.73321533203125\n",
      "loss: -424.3374328613281\n",
      "loss: -560.860107421875\n",
      "loss: -880.6190185546875\n",
      "loss: -438.0307312011719\n",
      "loss: -656.4655151367188\n",
      "loss: -527.0546875\n",
      "loss: -529.498046875\n",
      "loss: -301.46563720703125\n",
      "loss: -519.3847045898438\n",
      "loss: -460.2467041015625\n",
      "loss: -323.6003112792969\n",
      "\n",
      "-------------Round number: 15-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.43\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.08%\n",
      "Benign Std Test MRR: 34.75%\n",
      "loss: -628.684814453125\n",
      "loss: -313.4246826171875\n",
      "loss: -527.4254150390625\n",
      "loss: -326.7346496582031\n",
      "loss: -529.8727416992188\n",
      "loss: -365.8607177734375\n",
      "loss: -534.026611328125\n",
      "loss: -694.4470825195312\n",
      "loss: -341.3102111816406\n",
      "loss: -272.48388671875\n",
      "loss: -645.9343872070312\n",
      "loss: -449.7936706542969\n",
      "loss: -452.0201110839844\n",
      "loss: -483.8719177246094\n",
      "loss: -392.4671630859375\n",
      "loss: -328.5657653808594\n",
      "loss: -404.3204345703125\n",
      "loss: -865.99951171875\n",
      "loss: -383.2325134277344\n",
      "loss: -762.80712890625\n",
      "loss: -347.9988098144531\n",
      "loss: -460.5468444824219\n",
      "loss: -247.31155395507812\n",
      "loss: -406.0222473144531\n",
      "loss: -405.8304138183594\n",
      "loss: -416.2356872558594\n",
      "loss: -880.2887573242188\n",
      "loss: -364.8771667480469\n",
      "loss: -264.04345703125\n",
      "loss: -529.6602172851562\n",
      "loss: -366.46728515625\n",
      "loss: -561.5946044921875\n",
      "loss: -881.1341552734375\n",
      "loss: -885.7474365234375\n",
      "loss: -343.1257019042969\n",
      "loss: -438.489990234375\n",
      "loss: -587.7716064453125\n",
      "loss: -434.56976318359375\n",
      "loss: -763.6954956054688\n",
      "loss: -438.00634765625\n",
      "loss: -587.8058471679688\n",
      "loss: -885.3990478515625\n",
      "loss: -446.8975524902344\n",
      "loss: -663.430908203125\n",
      "loss: -527.7848510742188\n",
      "loss: -424.5233459472656\n",
      "loss: -449.55279541015625\n",
      "loss: -324.67510986328125\n",
      "loss: -656.8507080078125\n",
      "loss: -368.191162109375\n",
      "loss: -553.5621948242188\n",
      "loss: -486.4302978515625\n",
      "\n",
      "-------------Round number: 16-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -438.43\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.13%\n",
      "Benign Std Test MRR: 34.72%\n",
      "loss: -763.91015625\n",
      "loss: -406.4602355957031\n",
      "loss: -516.88427734375\n",
      "loss: -350.0079040527344\n",
      "loss: -520.4525756835938\n",
      "loss: -460.8013000488281\n",
      "loss: -881.5741577148438\n",
      "loss: -588.0748291015625\n",
      "loss: -486.8274230957031\n",
      "loss: -438.3699951171875\n",
      "loss: -343.2857666015625\n",
      "loss: -348.5941467285156\n",
      "loss: -447.4930419921875\n",
      "loss: -265.0846252441406\n",
      "loss: -885.8867797851562\n",
      "loss: -885.5658569335938\n",
      "loss: -588.052734375\n",
      "loss: -397.2263488769531\n",
      "loss: -489.12872314453125\n",
      "loss: -628.9306030273438\n",
      "loss: -450.0234375\n",
      "loss: -368.1488952636719\n",
      "loss: -369.1645202636719\n",
      "loss: -325.48016357421875\n",
      "loss: -374.3887634277344\n",
      "loss: -433.342041015625\n",
      "loss: -876.8274536132812\n",
      "loss: -381.0009460449219\n",
      "loss: -755.3516235351562\n",
      "loss: -366.6929626464844\n",
      "loss: -327.28033447265625\n",
      "loss: -383.8569030761719\n",
      "loss: -424.6807861328125\n",
      "loss: -435.12493896484375\n",
      "loss: -302.0398254394531\n",
      "loss: -521.3299560546875\n",
      "loss: -528.0985107421875\n",
      "loss: -762.9886474609375\n",
      "loss: -530.1807861328125\n",
      "loss: -562.1815185546875\n",
      "loss: -529.8414306640625\n",
      "loss: -330.83489990234375\n",
      "loss: -395.0918273925781\n",
      "loss: -556.7109375\n",
      "loss: -657.168212890625\n",
      "loss: -343.2275390625\n",
      "loss: -438.86529541015625\n",
      "loss: -247.93106079101562\n",
      "loss: -663.6079711914062\n",
      "loss: -313.69158935546875\n",
      "loss: -694.6011962890625\n",
      "loss: -527.7338256835938\n",
      "\n",
      "-------------Round number: 17-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -438.19\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.08%\n",
      "Benign Std Test MRR: 34.75%\n",
      "loss: -588.3078002929688\n",
      "loss: -327.7237243652344\n",
      "loss: -402.6263732910156\n",
      "loss: -631.8128662109375\n",
      "loss: -332.5226745605469\n",
      "loss: -369.9225769042969\n",
      "loss: -487.15380859375\n",
      "loss: -461.0206604003906\n",
      "loss: -344.6814270019531\n",
      "loss: -313.91461181640625\n",
      "loss: -588.2958984375\n",
      "loss: -234.05087280273438\n",
      "loss: -645.147216796875\n",
      "loss: -657.435302734375\n",
      "loss: -530.4397583007812\n",
      "loss: -265.8943176269531\n",
      "loss: -343.42138671875\n",
      "loss: -886.0109252929688\n",
      "loss: -349.0734558105469\n",
      "loss: -450.4086608886719\n",
      "loss: -764.0966796875\n",
      "loss: -528.3635864257812\n",
      "loss: -384.3568115234375\n",
      "loss: -326.1022644042969\n",
      "loss: -663.7657470703125\n",
      "loss: -439.177978515625\n",
      "loss: -447.9724426269531\n",
      "loss: -410.58221435546875\n",
      "loss: -482.27264404296875\n",
      "loss: -588.130859375\n",
      "loss: -406.81915283203125\n",
      "loss: -397.176025390625\n",
      "loss: -340.8571472167969\n",
      "loss: -444.9435729980469\n",
      "loss: -694.7381591796875\n",
      "loss: -370.5518798828125\n",
      "loss: -885.7147216796875\n",
      "loss: -763.1469116210938\n",
      "loss: -527.9955444335938\n",
      "loss: -881.9542236328125\n",
      "loss: -562.6624755859375\n",
      "loss: -424.8166198730469\n",
      "loss: -438.6720886230469\n",
      "loss: -435.5693054199219\n",
      "loss: -366.88494873046875\n",
      "loss: -248.42184448242188\n",
      "loss: -559.00927734375\n",
      "loss: -461.13043212890625\n",
      "loss: -433.1421813964844\n",
      "loss: -874.5325927734375\n",
      "loss: -629.1402587890625\n",
      "loss: -530.0016479492188\n",
      "\n",
      "-------------Round number: 18-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -442.43\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.73%\n",
      "Benign Averaged Test MRR: 29.08%\n",
      "Benign Std Test MRR: 34.75%\n",
      "loss: -886.1220703125\n",
      "loss: -882.2858276367188\n",
      "loss: -314.10357666015625\n",
      "loss: -764.260986328125\n",
      "loss: -528.22021484375\n",
      "loss: -390.8870544433594\n",
      "loss: -465.1080322265625\n",
      "loss: -560.748779296875\n",
      "loss: -763.2869262695312\n",
      "loss: -588.5081787109375\n",
      "loss: -326.59527587890625\n",
      "loss: -528.590087890625\n",
      "loss: -367.04974365234375\n",
      "loss: -349.46710205078125\n",
      "loss: -450.73004150390625\n",
      "loss: -588.5112915039062\n",
      "loss: -345.8075256347656\n",
      "loss: -629.3211669921875\n",
      "loss: -424.9349365234375\n",
      "loss: -448.3659362792969\n",
      "loss: -343.5375061035156\n",
      "loss: -439.4423522949219\n",
      "loss: -328.0901794433594\n",
      "loss: -384.7657470703125\n",
      "loss: -407.1175231933594\n",
      "loss: -266.5368347167969\n",
      "loss: -370.5270690917969\n",
      "loss: -438.9270324707031\n",
      "loss: -435.93218994140625\n",
      "loss: -347.2943420410156\n",
      "loss: -476.6879577636719\n",
      "loss: -821.1710205078125\n",
      "loss: -248.81777954101562\n",
      "loss: -563.063720703125\n",
      "loss: -425.2877502441406\n",
      "loss: -701.6686401367188\n",
      "loss: -461.2118225097656\n",
      "loss: -260.9441223144531\n",
      "loss: -611.2352294921875\n",
      "loss: -487.4268798828125\n",
      "loss: -530.6600341796875\n",
      "loss: -372.3349609375\n",
      "loss: -694.8602294921875\n",
      "loss: -657.663330078125\n",
      "loss: -333.8015441894531\n",
      "loss: -663.906005859375\n",
      "loss: -530.1433715820312\n",
      "loss: -390.79107666015625\n",
      "loss: -451.0639343261719\n",
      "loss: -580.9358520507812\n",
      "loss: -398.8388366699219\n",
      "loss: -885.8477783203125\n",
      "\n",
      "-------------Round number: 19-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -435.52\n",
      "Benign Averaged Test Recall: 48.54%\n",
      "Benign Std Test Recall: 45.77%\n",
      "Benign Averaged Test MRR: 28.58%\n",
      "Benign Std Test MRR: 34.74%\n",
      "loss: -528.4148559570312\n",
      "loss: -588.6904296875\n",
      "loss: -882.57763671875\n",
      "loss: -528.7855834960938\n",
      "loss: -373.6805419921875\n",
      "loss: -886.2216796875\n",
      "loss: -763.4113159179688\n",
      "loss: -407.3686828613281\n",
      "loss: -328.3970642089844\n",
      "loss: -425.03826904296875\n",
      "loss: -490.1675109863281\n",
      "loss: -390.7570495605469\n",
      "loss: -488.4208068847656\n",
      "loss: -264.816650390625\n",
      "loss: -549.5567626953125\n",
      "loss: -249.14199829101562\n",
      "loss: -436.4762878417969\n",
      "loss: -759.4306640625\n",
      "loss: -657.859619140625\n",
      "loss: -461.72882080078125\n",
      "loss: -361.89892578125\n",
      "loss: -878.9149169921875\n",
      "loss: -563.4031372070312\n",
      "loss: -371.0184020996094\n",
      "loss: -343.6378173828125\n",
      "loss: -451.0013122558594\n",
      "loss: -487.6583251953125\n",
      "loss: -367.1924743652344\n",
      "loss: -562.1083984375\n",
      "loss: -588.6952514648438\n",
      "loss: -334.7904357910156\n",
      "loss: -385.10577392578125\n",
      "loss: -346.6971130371094\n",
      "loss: -461.37939453125\n",
      "loss: -400.17449951171875\n",
      "loss: -694.9693603515625\n",
      "loss: -530.8495483398438\n",
      "loss: -436.2329406738281\n",
      "loss: -267.0554504394531\n",
      "loss: -326.99407958984375\n",
      "loss: -439.6679382324219\n",
      "loss: -349.7952880859375\n",
      "loss: -378.029052734375\n",
      "loss: -503.1553649902344\n",
      "loss: -764.4063720703125\n",
      "loss: -629.478759765625\n",
      "loss: -439.14483642578125\n",
      "loss: -530.2691040039062\n",
      "loss: -448.6940002441406\n",
      "loss: -664.0308837890625\n",
      "loss: -885.9671020507812\n",
      "loss: -314.2649841308594\n",
      "\n",
      "-------------Round number: 20-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -432.83\n",
      "Benign Averaged Test Recall: 48.54%\n",
      "Benign Std Test Recall: 45.77%\n",
      "Benign Averaged Test MRR: 28.58%\n",
      "Benign Std Test MRR: 34.74%\n",
      "loss: -882.83642578125\n",
      "loss: -371.4247131347656\n",
      "loss: -327.32220458984375\n",
      "loss: -588.8491821289062\n",
      "loss: -328.6572570800781\n",
      "loss: -563.6940307617188\n",
      "loss: -462.0639343261719\n",
      "loss: -401.1856384277344\n",
      "loss: -552.8238525390625\n",
      "loss: -256.6207580566406\n",
      "loss: -727.139404296875\n",
      "loss: -658.0304565429688\n",
      "loss: -664.1427001953125\n",
      "loss: -764.5362548828125\n",
      "loss: -401.2576904296875\n",
      "loss: -528.9557495117188\n",
      "loss: -350.0731506347656\n",
      "loss: -448.9715881347656\n",
      "loss: -563.201416015625\n",
      "loss: -347.41314697265625\n",
      "loss: -439.33294677734375\n",
      "loss: -695.0674438476562\n",
      "loss: -886.3115844726562\n",
      "loss: -407.58282470703125\n",
      "loss: -249.41146850585938\n",
      "loss: -385.392822265625\n",
      "loss: -451.23345947265625\n",
      "loss: -314.4043884277344\n",
      "loss: -530.3812866210938\n",
      "loss: -886.07470703125\n",
      "loss: -374.7177429199219\n",
      "loss: -531.0137329101562\n",
      "loss: -423.2591552734375\n",
      "loss: -363.5642395019531\n",
      "loss: -425.1295166015625\n",
      "loss: -414.4942932128906\n",
      "loss: -787.9607543945312\n",
      "loss: -629.6173095703125\n",
      "loss: -436.48577880859375\n",
      "loss: -367.31719970703125\n",
      "loss: -461.5274353027344\n",
      "loss: -267.48065185546875\n",
      "loss: -335.57135009765625\n",
      "loss: -763.5228881835938\n",
      "loss: -343.7250061035156\n",
      "loss: -487.85687255859375\n",
      "loss: -439.8627624511719\n",
      "loss: -588.8610229492188\n",
      "loss: -406.5225830078125\n",
      "loss: -447.0796813964844\n",
      "loss: -616.8880004882812\n",
      "loss: -528.5851440429688\n",
      "\n",
      "-------------Round number: 21-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -439.95\n",
      "Benign Averaged Test Recall: 47.57%\n",
      "Benign Std Test Recall: 45.89%\n",
      "Benign Averaged Test MRR: 28.38%\n",
      "Benign Std Test MRR: 35.01%\n",
      "loss: -451.4341735839844\n",
      "loss: -249.63841247558594\n",
      "loss: -328.88043212890625\n",
      "loss: -886.1720581054688\n",
      "loss: -421.838134765625\n",
      "loss: -365.7724304199219\n",
      "loss: -529.1053466796875\n",
      "loss: -436.24810791015625\n",
      "loss: -764.5540771484375\n",
      "loss: -385.6383361816406\n",
      "loss: -407.7671203613281\n",
      "loss: -883.06787109375\n",
      "loss: -417.6263122558594\n",
      "loss: -448.0068359375\n",
      "loss: -854.6082153320312\n",
      "loss: -375.5348815917969\n",
      "loss: -528.7352294921875\n",
      "loss: -327.59674072265625\n",
      "loss: -326.8176574707031\n",
      "loss: -453.5209655761719\n",
      "loss: -402.1462707519531\n",
      "loss: -347.99957275390625\n",
      "loss: -588.9911499023438\n",
      "loss: -449.2093811035156\n",
      "loss: -343.80145263671875\n",
      "loss: -488.0292053222656\n",
      "loss: -531.157958984375\n",
      "loss: -414.9645690917969\n",
      "loss: -400.7834167480469\n",
      "loss: -628.4354858398438\n",
      "loss: -664.243408203125\n",
      "loss: -530.4815673828125\n",
      "loss: -589.0091552734375\n",
      "loss: -764.6529541015625\n",
      "loss: -658.1806030273438\n",
      "loss: -629.7399291992188\n",
      "loss: -314.5257568359375\n",
      "loss: -695.1559448242188\n",
      "loss: -461.6590881347656\n",
      "loss: -436.7008361816406\n",
      "loss: -267.8341979980469\n",
      "loss: -563.9461669921875\n",
      "loss: -564.1024169921875\n",
      "loss: -350.3108825683594\n",
      "loss: -367.4273681640625\n",
      "loss: -371.76617431640625\n",
      "loss: -440.03228759765625\n",
      "loss: -439.4968566894531\n",
      "loss: -336.20111083984375\n",
      "loss: -425.2104797363281\n",
      "loss: -763.6233520507812\n",
      "loss: -886.392822265625\n",
      "\n",
      "-------------Round number: 22-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.23\n",
      "Benign Averaged Test Recall: 47.57%\n",
      "Benign Std Test Recall: 45.89%\n",
      "Benign Averaged Test MRR: 28.38%\n",
      "Benign Std Test MRR: 35.01%\n",
      "loss: -883.2758178710938\n",
      "loss: -528.8679809570312\n",
      "loss: -372.05584716796875\n",
      "loss: -348.48626708984375\n",
      "loss: -268.13116455078125\n",
      "loss: -314.6317138671875\n",
      "loss: -589.1414794921875\n",
      "loss: -564.1658935546875\n",
      "loss: -440.180419921875\n",
      "loss: -488.1793518066406\n",
      "loss: -421.0849914550781\n",
      "loss: -403.3669128417969\n",
      "loss: -876.7666015625\n",
      "loss: -886.4664306640625\n",
      "loss: -436.88494873046875\n",
      "loss: -407.9265441894531\n",
      "loss: -886.260009765625\n",
      "loss: -451.46185302734375\n",
      "loss: -590.2062377929688\n",
      "loss: -530.5716552734375\n",
      "loss: -629.8486328125\n",
      "loss: -531.2836303710938\n",
      "loss: -658.3126831054688\n",
      "loss: -367.524658203125\n",
      "loss: -336.716064453125\n",
      "loss: -343.86871337890625\n",
      "loss: -249.8307647705078\n",
      "loss: -329.0727233886719\n",
      "loss: -589.1179809570312\n",
      "loss: -695.2354736328125\n",
      "loss: -327.82867431640625\n",
      "loss: -451.6084899902344\n",
      "loss: -350.5162658691406\n",
      "loss: -439.6402893066406\n",
      "loss: -449.4148254394531\n",
      "loss: -396.95452880859375\n",
      "loss: -449.76947021484375\n",
      "loss: -664.334228515625\n",
      "loss: -764.7579956054688\n",
      "loss: -385.8495788574219\n",
      "loss: -564.8584594726562\n",
      "loss: -459.49517822265625\n",
      "loss: -414.6201171875\n",
      "loss: -441.7112731933594\n",
      "loss: -529.2372436523438\n",
      "loss: -376.1890563964844\n",
      "loss: -402.8817138671875\n",
      "loss: -248.38037109375\n",
      "loss: -482.86712646484375\n",
      "loss: -763.7139282226562\n",
      "loss: -461.77618408203125\n",
      "loss: -425.28216552734375\n",
      "\n",
      "-------------Round number: 23-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -433.94\n",
      "Benign Averaged Test Recall: 47.57%\n",
      "Benign Std Test Recall: 45.89%\n",
      "Benign Averaged Test MRR: 28.46%\n",
      "Benign Std Test MRR: 34.97%\n",
      "loss: -329.2405700683594\n",
      "loss: -476.4268798828125\n",
      "loss: -453.49444580078125\n",
      "loss: -592.94921875\n",
      "loss: -664.4158935546875\n",
      "loss: -530.6525268554688\n",
      "loss: -589.2608642578125\n",
      "loss: -883.4635620117188\n",
      "loss: -328.02716064453125\n",
      "loss: -248.1403045654297\n",
      "loss: -487.33465576171875\n",
      "loss: -447.7582702636719\n",
      "loss: -867.0174560546875\n",
      "loss: -440.3110046386719\n",
      "loss: -425.34613037109375\n",
      "loss: -528.986328125\n",
      "loss: -348.89520263671875\n",
      "loss: -529.3546142578125\n",
      "loss: -386.0338134765625\n",
      "loss: -629.9457397460938\n",
      "loss: -763.7963256835938\n",
      "loss: -695.3074951171875\n",
      "loss: -449.59368896484375\n",
      "loss: -564.3592529296875\n",
      "loss: -249.99545288085938\n",
      "loss: -268.38360595703125\n",
      "loss: -439.76702880859375\n",
      "loss: -367.61138916015625\n",
      "loss: -451.76123046875\n",
      "loss: -658.4295043945312\n",
      "loss: -461.88134765625\n",
      "loss: -376.7227478027344\n",
      "loss: -565.5049438476562\n",
      "loss: -350.6950378417969\n",
      "loss: -437.0442810058594\n",
      "loss: -886.3400268554688\n",
      "loss: -374.13983154296875\n",
      "loss: -457.1981506347656\n",
      "loss: -886.5333251953125\n",
      "loss: -343.9281921386719\n",
      "loss: -488.3116455078125\n",
      "loss: -371.80499267578125\n",
      "loss: -439.6994323730469\n",
      "loss: -769.9371337890625\n",
      "loss: -337.145263671875\n",
      "loss: -589.232177734375\n",
      "loss: -314.7251281738281\n",
      "loss: -403.4974365234375\n",
      "loss: -372.3049011230469\n",
      "loss: -408.0657958984375\n",
      "loss: -531.394775390625\n",
      "loss: -764.8531494140625\n",
      "\n",
      "-------------Round number: 24-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -435.18\n",
      "Benign Averaged Test Recall: 47.57%\n",
      "Benign Std Test Recall: 45.89%\n",
      "Benign Averaged Test MRR: 28.54%\n",
      "Benign Std Test MRR: 34.96%\n",
      "loss: -529.0921630859375\n",
      "loss: -337.5069885253906\n",
      "loss: -314.80780029296875\n",
      "loss: -278.56219482421875\n",
      "loss: -753.4603271484375\n",
      "loss: -437.1830139160156\n",
      "loss: -386.19573974609375\n",
      "loss: -529.45947265625\n",
      "loss: -408.1882629394531\n",
      "loss: -451.8960266113281\n",
      "loss: -329.3877868652344\n",
      "loss: -502.2351379394531\n",
      "loss: -435.14935302734375\n",
      "loss: -737.4529418945312\n",
      "loss: -250.13763427734375\n",
      "loss: -630.0330200195312\n",
      "loss: -377.1650085449219\n",
      "loss: -440.4266662597656\n",
      "loss: -461.9758605957031\n",
      "loss: -589.3687744140625\n",
      "loss: -530.7259521484375\n",
      "loss: -268.6001281738281\n",
      "loss: -404.01824951171875\n",
      "loss: -886.412841796875\n",
      "loss: -566.0657348632812\n",
      "loss: -372.5210876464844\n",
      "loss: -883.6341552734375\n",
      "loss: -372.9635314941406\n",
      "loss: -379.0107421875\n",
      "loss: -589.3350830078125\n",
      "loss: -763.871826171875\n",
      "loss: -488.4286193847656\n",
      "loss: -438.96002197265625\n",
      "loss: -648.25048828125\n",
      "loss: -391.1951904296875\n",
      "loss: -451.9797058105469\n",
      "loss: -575.0072631835938\n",
      "loss: -531.4930419921875\n",
      "loss: -658.5335083007812\n",
      "loss: -449.7507019042969\n",
      "loss: -328.1984558105469\n",
      "loss: -439.8795471191406\n",
      "loss: -764.9395141601562\n",
      "loss: -349.2434387207031\n",
      "loss: -664.4900512695312\n",
      "loss: -564.530517578125\n",
      "loss: -695.3731079101562\n",
      "loss: -367.6885681152344\n",
      "loss: -886.59423828125\n",
      "loss: -343.981201171875\n",
      "loss: -350.8521728515625\n",
      "loss: -425.4033508300781\n",
      "\n",
      "-------------Round number: 25-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -440.46\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.29%\n",
      "Benign Std Test MRR: 35.05%\n",
      "loss: -883.7897338867188\n",
      "loss: -440.5298767089844\n",
      "loss: -247.83294677734375\n",
      "loss: -488.7437744140625\n",
      "loss: -439.98016357421875\n",
      "loss: -695.4326782226562\n",
      "loss: -351.4427185058594\n",
      "loss: -517.8566284179688\n",
      "loss: -866.6490478515625\n",
      "loss: -268.7876892089844\n",
      "loss: -367.25506591796875\n",
      "loss: -535.1666870117188\n",
      "loss: -529.1878662109375\n",
      "loss: -564.6835327148438\n",
      "loss: -392.1275329589844\n",
      "loss: -432.79534912109375\n",
      "loss: -875.8431396484375\n",
      "loss: -566.5585327148438\n",
      "loss: -408.2967834472656\n",
      "loss: -337.8160705566406\n",
      "loss: -314.88153076171875\n",
      "loss: -765.0183715820312\n",
      "loss: -763.9409790039062\n",
      "loss: -459.18927001953125\n",
      "loss: -721.6201171875\n",
      "loss: -488.5328674316406\n",
      "loss: -367.75823974609375\n",
      "loss: -630.1119995117188\n",
      "loss: -452.0157470703125\n",
      "loss: -886.4793090820312\n",
      "loss: -386.3392639160156\n",
      "loss: -349.5428771972656\n",
      "loss: -250.2615203857422\n",
      "loss: -530.7926635742188\n",
      "loss: -404.4635314941406\n",
      "loss: -372.7105712890625\n",
      "loss: -589.4287109375\n",
      "loss: -328.3476867675781\n",
      "loss: -329.517822265625\n",
      "loss: -437.30511474609375\n",
      "loss: -425.4549865722656\n",
      "loss: -886.6502075195312\n",
      "loss: -449.8900451660156\n",
      "loss: -377.5365905761719\n",
      "loss: -664.557373046875\n",
      "loss: -350.9914245605469\n",
      "loss: -462.06170654296875\n",
      "loss: -589.4668579101562\n",
      "loss: -529.5538330078125\n",
      "loss: -531.580810546875\n",
      "loss: -344.02850341796875\n",
      "loss: -658.6267700195312\n",
      "\n",
      "-------------Round number: 26-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -435.96\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.21%\n",
      "Benign Std Test MRR: 35.09%\n",
      "loss: -566.996337890625\n",
      "loss: -450.0142822265625\n",
      "loss: -764.0049438476562\n",
      "loss: -589.556640625\n",
      "loss: -529.6390380859375\n",
      "loss: -630.1838989257812\n",
      "loss: -314.9481201171875\n",
      "loss: -664.619140625\n",
      "loss: -349.8028869628906\n",
      "loss: -425.50146484375\n",
      "loss: -351.1157531738281\n",
      "loss: -440.6227722167969\n",
      "loss: -589.5140380859375\n",
      "loss: -268.9515686035156\n",
      "loss: -462.1396179199219\n",
      "loss: -529.2744140625\n",
      "loss: -437.1901550292969\n",
      "loss: -766.9767456054688\n",
      "loss: -429.33160400390625\n",
      "loss: -357.03045654296875\n",
      "loss: -367.8209228515625\n",
      "loss: -404.29010009765625\n",
      "loss: -449.6763000488281\n",
      "loss: -886.61962890625\n",
      "loss: -530.8539428710938\n",
      "loss: -886.5404052734375\n",
      "loss: -437.4128723144531\n",
      "loss: -250.37005615234375\n",
      "loss: -531.6591796875\n",
      "loss: -372.8780517578125\n",
      "loss: -276.5308837890625\n",
      "loss: -604.921142578125\n",
      "loss: -419.1896667480469\n",
      "loss: -420.3393859863281\n",
      "loss: -583.4813842773438\n",
      "loss: -328.478515625\n",
      "loss: -886.7014770507812\n",
      "loss: -695.4874877929688\n",
      "loss: -883.9322509765625\n",
      "loss: -338.0827941894531\n",
      "loss: -377.8529052734375\n",
      "loss: -408.3935852050781\n",
      "loss: -488.62652587890625\n",
      "loss: -765.0911865234375\n",
      "loss: -386.4674072265625\n",
      "loss: -564.8213500976562\n",
      "loss: -404.84747314453125\n",
      "loss: -440.0703125\n",
      "loss: -452.12286376953125\n",
      "loss: -658.7108764648438\n",
      "loss: -329.6339416503906\n",
      "loss: -344.0710144042969\n",
      "\n",
      "-------------Round number: 27-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -446.13\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.69%\n",
      "Benign Std Test MRR: 35.16%\n",
      "loss: -378.1253356933594\n",
      "loss: -440.1518249511719\n",
      "loss: -386.5830078125\n",
      "loss: -886.748779296875\n",
      "loss: -367.8782653808594\n",
      "loss: -488.7112731933594\n",
      "loss: -589.6390991210938\n",
      "loss: -350.03070068359375\n",
      "loss: -250.46646118164062\n",
      "loss: -664.676025390625\n",
      "loss: -529.3536376953125\n",
      "loss: -886.5968017578125\n",
      "loss: -531.7299194335938\n",
      "loss: -462.21112060546875\n",
      "loss: -530.9103393554688\n",
      "loss: -351.2275085449219\n",
      "loss: -269.09600830078125\n",
      "loss: -328.5943908691406\n",
      "loss: -450.1263732910156\n",
      "loss: -589.5925903320312\n",
      "loss: -529.7166748046875\n",
      "loss: -567.3897094726562\n",
      "loss: -630.2498168945312\n",
      "loss: -413.75933837890625\n",
      "loss: -377.58203125\n",
      "loss: -884.0633544921875\n",
      "loss: -425.5439758300781\n",
      "loss: -391.6719665527344\n",
      "loss: -418.07598876953125\n",
      "loss: -461.5430603027344\n",
      "loss: -405.1820983886719\n",
      "loss: -274.0894775390625\n",
      "loss: -648.7028198242188\n",
      "loss: -315.0082702636719\n",
      "loss: -338.3157958984375\n",
      "loss: -437.5090637207031\n",
      "loss: -764.0640869140625\n",
      "loss: -426.5135192871094\n",
      "loss: -703.416015625\n",
      "loss: -373.0271301269531\n",
      "loss: -344.1097412109375\n",
      "loss: -765.1585693359375\n",
      "loss: -564.9462280273438\n",
      "loss: -448.98291015625\n",
      "loss: -375.7417907714844\n",
      "loss: -879.5677490234375\n",
      "loss: -440.70660400390625\n",
      "loss: -658.7870483398438\n",
      "loss: -695.5379028320312\n",
      "loss: -408.4804382324219\n",
      "loss: -329.73797607421875\n",
      "loss: -452.21978759765625\n",
      "\n",
      "-------------Round number: 28-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.94\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.69%\n",
      "Benign Std Test MRR: 35.16%\n",
      "loss: -269.2237548828125\n",
      "loss: -450.22747802734375\n",
      "loss: -658.8565673828125\n",
      "loss: -408.5586853027344\n",
      "loss: -884.1847534179688\n",
      "loss: -462.2767028808594\n",
      "loss: -764.11962890625\n",
      "loss: -886.7926025390625\n",
      "loss: -529.78759765625\n",
      "loss: -410.5817565917969\n",
      "loss: -545.3349609375\n",
      "loss: -452.3072814941406\n",
      "loss: -367.93060302734375\n",
      "loss: -531.793701171875\n",
      "loss: -329.831298828125\n",
      "loss: -373.1611633300781\n",
      "loss: -440.225830078125\n",
      "loss: -362.1466369628906\n",
      "loss: -440.652587890625\n",
      "loss: -585.5994262695312\n",
      "loss: -695.5842895507812\n",
      "loss: -378.3622741699219\n",
      "loss: -664.7285766601562\n",
      "loss: -448.11083984375\n",
      "loss: -658.9155883789062\n",
      "loss: -386.6874084472656\n",
      "loss: -328.697509765625\n",
      "loss: -338.5208740234375\n",
      "loss: -344.14483642578125\n",
      "loss: -273.9634704589844\n",
      "loss: -658.0331420898438\n",
      "loss: -589.6648559570312\n",
      "loss: -529.4261474609375\n",
      "loss: -351.3287353515625\n",
      "loss: -530.9622192382812\n",
      "loss: -505.3296203613281\n",
      "loss: -418.3135070800781\n",
      "loss: -871.6652221679688\n",
      "loss: -315.062744140625\n",
      "loss: -886.6488647460938\n",
      "loss: -250.55194091796875\n",
      "loss: -589.7149658203125\n",
      "loss: -405.4756164550781\n",
      "loss: -567.745849609375\n",
      "loss: -488.78802490234375\n",
      "loss: -350.2320251464844\n",
      "loss: -565.059814453125\n",
      "loss: -440.78271484375\n",
      "loss: -437.59503173828125\n",
      "loss: -765.2208251953125\n",
      "loss: -425.5827941894531\n",
      "loss: -630.3101806640625\n",
      "\n",
      "-------------Round number: 29-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -440.16\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -405.734619140625\n",
      "loss: -328.78973388671875\n",
      "loss: -488.85797119140625\n",
      "loss: -630.3655395507812\n",
      "loss: -589.784912109375\n",
      "loss: -884.2970581054688\n",
      "loss: -348.5125732421875\n",
      "loss: -549.61865234375\n",
      "loss: -833.123779296875\n",
      "loss: -664.7772827148438\n",
      "loss: -438.1149597167969\n",
      "loss: -604.5123291015625\n",
      "loss: -386.7826232910156\n",
      "loss: -378.57012939453125\n",
      "loss: -531.8516235351562\n",
      "loss: -356.6146545410156\n",
      "loss: -504.8913269042969\n",
      "loss: -568.0704956054688\n",
      "loss: -440.8515625\n",
      "loss: -658.91943359375\n",
      "loss: -425.6183166503906\n",
      "loss: -408.6293640136719\n",
      "loss: -252.08929443359375\n",
      "loss: -872.500244140625\n",
      "loss: -269.3374938964844\n",
      "loss: -452.3868408203125\n",
      "loss: -351.4204406738281\n",
      "loss: -329.9159851074219\n",
      "loss: -765.2786865234375\n",
      "loss: -440.2931823730469\n",
      "loss: -344.1766357421875\n",
      "loss: -437.6724548339844\n",
      "loss: -695.6273803710938\n",
      "loss: -373.2816162109375\n",
      "loss: -367.9783935546875\n",
      "loss: -529.4924926757812\n",
      "loss: -315.112060546875\n",
      "loss: -589.7312622070312\n",
      "loss: -529.852783203125\n",
      "loss: -886.6971435546875\n",
      "loss: -565.163818359375\n",
      "loss: -350.41015625\n",
      "loss: -312.98175048828125\n",
      "loss: -462.3722229003906\n",
      "loss: -630.1983642578125\n",
      "loss: -450.3190612792969\n",
      "loss: -764.17138671875\n",
      "loss: -531.0103149414062\n",
      "loss: -250.6282196044922\n",
      "loss: -886.8331909179688\n",
      "loss: -462.3369140625\n",
      "loss: -338.7026672363281\n",
      "\n",
      "-------------Round number: 30-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -438.49\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -440.35504150390625\n",
      "loss: -400.6808776855469\n",
      "loss: -391.8562927246094\n",
      "loss: -565.2594604492188\n",
      "loss: -269.4394226074219\n",
      "loss: -529.553955078125\n",
      "loss: -531.904052734375\n",
      "loss: -408.69378662109375\n",
      "loss: -365.58843994140625\n",
      "loss: -528.5095825195312\n",
      "loss: -566.9732666015625\n",
      "loss: -462.3926696777344\n",
      "loss: -589.7930908203125\n",
      "loss: -217.70431518554688\n",
      "loss: -862.3468627929688\n",
      "loss: -452.45928955078125\n",
      "loss: -368.02239990234375\n",
      "loss: -886.8709716796875\n",
      "loss: -884.4013671875\n",
      "loss: -350.5697021484375\n",
      "loss: -765.3328247070312\n",
      "loss: -328.87286376953125\n",
      "loss: -315.15728759765625\n",
      "loss: -440.9148864746094\n",
      "loss: -329.9927978515625\n",
      "loss: -351.5043640136719\n",
      "loss: -403.75\n",
      "loss: -631.4112548828125\n",
      "loss: -425.65093994140625\n",
      "loss: -450.4023742675781\n",
      "loss: -658.9774780273438\n",
      "loss: -344.2059631347656\n",
      "loss: -695.667236328125\n",
      "loss: -405.96490478515625\n",
      "loss: -764.2199096679688\n",
      "loss: -529.9127197265625\n",
      "loss: -437.74224853515625\n",
      "loss: -664.8224487304688\n",
      "loss: -589.8501586914062\n",
      "loss: -488.9219970703125\n",
      "loss: -531.0551147460938\n",
      "loss: -378.75408935546875\n",
      "loss: -386.86968994140625\n",
      "loss: -630.4169311523438\n",
      "loss: -338.8648986816406\n",
      "loss: -373.3911437988281\n",
      "loss: -568.3687133789062\n",
      "loss: -886.7420654296875\n",
      "loss: -492.2632751464844\n",
      "loss: -381.66693115234375\n",
      "loss: -868.0894775390625\n",
      "loss: -250.696533203125\n",
      "\n",
      "-------------Round number: 31-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -437.12\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -659.0307006835938\n",
      "loss: -406.1703796386719\n",
      "loss: -886.78369140625\n",
      "loss: -452.5252990722656\n",
      "loss: -344.2327575683594\n",
      "loss: -398.5682373046875\n",
      "loss: -447.59503173828125\n",
      "loss: -378.91754150390625\n",
      "loss: -764.2657470703125\n",
      "loss: -425.6808776855469\n",
      "loss: -630.464599609375\n",
      "loss: -437.8053894042969\n",
      "loss: -250.7578887939453\n",
      "loss: -440.97265625\n",
      "loss: -437.40533447265625\n",
      "loss: -613.3810424804688\n",
      "loss: -765.3831787109375\n",
      "loss: -568.6434936523438\n",
      "loss: -407.32733154296875\n",
      "loss: -381.8836975097656\n",
      "loss: -544.29833984375\n",
      "loss: -247.8293914794922\n",
      "loss: -488.9150085449219\n",
      "loss: -315.19866943359375\n",
      "loss: -886.906005859375\n",
      "loss: -330.0626220703125\n",
      "loss: -339.01007080078125\n",
      "loss: -351.5811767578125\n",
      "loss: -408.75213623046875\n",
      "loss: -440.41156005859375\n",
      "loss: -589.9104614257812\n",
      "loss: -664.864501953125\n",
      "loss: -589.8502807617188\n",
      "loss: -531.9519653320312\n",
      "loss: -488.9808044433594\n",
      "loss: -373.4905700683594\n",
      "loss: -328.94769287109375\n",
      "loss: -450.4786682128906\n",
      "loss: -462.4441223144531\n",
      "loss: -368.06268310546875\n",
      "loss: -269.5311279296875\n",
      "loss: -565.3474731445312\n",
      "loss: -531.0966796875\n",
      "loss: -529.9680786132812\n",
      "loss: -529.6105346679688\n",
      "loss: -695.7042236328125\n",
      "loss: -386.94952392578125\n",
      "loss: -405.5945739746094\n",
      "loss: -485.25225830078125\n",
      "loss: -871.909423828125\n",
      "loss: -884.498291015625\n",
      "loss: -350.71270751953125\n",
      "\n",
      "-------------Round number: 32-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -440.79\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -269.61383056640625\n",
      "loss: -489.03472900390625\n",
      "loss: -368.10009765625\n",
      "loss: -630.509033203125\n",
      "loss: -339.1415100097656\n",
      "loss: -373.7613525390625\n",
      "loss: -431.23486328125\n",
      "loss: -537.6145629882812\n",
      "loss: -344.2573547363281\n",
      "loss: -695.7382202148438\n",
      "loss: -589.9664306640625\n",
      "loss: -568.8986206054688\n",
      "loss: -589.903564453125\n",
      "loss: -373.5820007324219\n",
      "loss: -330.126708984375\n",
      "loss: -425.7085266113281\n",
      "loss: -530.01904296875\n",
      "loss: -387.02301025390625\n",
      "loss: -427.2108459472656\n",
      "loss: -691.6105346679688\n",
      "loss: -406.35479736328125\n",
      "loss: -765.4302978515625\n",
      "loss: -462.4920959472656\n",
      "loss: -886.9387817382812\n",
      "loss: -437.86260986328125\n",
      "loss: -350.8416748046875\n",
      "loss: -351.6518249511719\n",
      "loss: -452.58563232421875\n",
      "loss: -884.5887451171875\n",
      "loss: -659.0791015625\n",
      "loss: -329.01568603515625\n",
      "loss: -440.4635925292969\n",
      "loss: -450.54827880859375\n",
      "loss: -886.8226318359375\n",
      "loss: -408.8055419921875\n",
      "loss: -424.654296875\n",
      "loss: -364.0355224609375\n",
      "loss: -531.9954833984375\n",
      "loss: -565.4288940429688\n",
      "loss: -664.9033813476562\n",
      "loss: -764.3087768554688\n",
      "loss: -441.0257263183594\n",
      "loss: -250.81321716308594\n",
      "loss: -379.0638427734375\n",
      "loss: -476.7765197753906\n",
      "loss: -451.99407958984375\n",
      "loss: -885.1837158203125\n",
      "loss: -529.6632690429688\n",
      "loss: -273.8260192871094\n",
      "loss: -653.1207885742188\n",
      "loss: -531.1353759765625\n",
      "loss: -315.23687744140625\n",
      "\n",
      "-------------Round number: 33-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -432.72\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -351.7172546386719\n",
      "loss: -250.8630828857422\n",
      "loss: -884.6728515625\n",
      "loss: -529.7117919921875\n",
      "loss: -886.9692993164062\n",
      "loss: -664.9397583007812\n",
      "loss: -344.2799377441406\n",
      "loss: -437.8891296386719\n",
      "loss: -608.8737182617188\n",
      "loss: -886.8587646484375\n",
      "loss: -339.25994873046875\n",
      "loss: -695.7699584960938\n",
      "loss: -387.0908203125\n",
      "loss: -269.68890380859375\n",
      "loss: -589.9528198242188\n",
      "loss: -530.066162109375\n",
      "loss: -452.6408386230469\n",
      "loss: -437.9146728515625\n",
      "loss: -440.51141357421875\n",
      "loss: -565.5042724609375\n",
      "loss: -489.0842590332031\n",
      "loss: -330.1852722167969\n",
      "loss: -368.13433837890625\n",
      "loss: -425.73388671875\n",
      "loss: -408.8541564941406\n",
      "loss: -566.5967407226562\n",
      "loss: -352.17962646484375\n",
      "loss: -390.8734436035156\n",
      "loss: -350.9584655761719\n",
      "loss: -764.349609375\n",
      "loss: -500.67535400390625\n",
      "loss: -490.8108215332031\n",
      "loss: -861.6318359375\n",
      "loss: -379.1958923339844\n",
      "loss: -531.1712646484375\n",
      "loss: -373.6654052734375\n",
      "loss: -590.0184326171875\n",
      "loss: -532.0349731445312\n",
      "loss: -765.4741821289062\n",
      "loss: -450.61224365234375\n",
      "loss: -329.0773010253906\n",
      "loss: -300.5774230957031\n",
      "loss: -533.8088989257812\n",
      "loss: -462.5364990234375\n",
      "loss: -305.0303039550781\n",
      "loss: -519.093505859375\n",
      "loss: -441.0740661621094\n",
      "loss: -406.5209655761719\n",
      "loss: -659.1237182617188\n",
      "loss: -569.13623046875\n",
      "loss: -630.5504150390625\n",
      "loss: -315.2720031738281\n",
      "\n",
      "-------------Round number: 34-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -443.06\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -695.7996826171875\n",
      "loss: -315.30462646484375\n",
      "loss: -351.7777404785156\n",
      "loss: -408.89910888671875\n",
      "loss: -489.13037109375\n",
      "loss: -530.1101684570312\n",
      "loss: -659.1651611328125\n",
      "loss: -330.23919677734375\n",
      "loss: -884.7515869140625\n",
      "loss: -339.3680725097656\n",
      "loss: -886.8928833007812\n",
      "loss: -373.7428283691406\n",
      "loss: -250.90850830078125\n",
      "loss: -464.3800354003906\n",
      "loss: -539.2106323242188\n",
      "loss: -351.0648498535156\n",
      "loss: -387.1539306640625\n",
      "loss: -406.67156982421875\n",
      "loss: -589.9991455078125\n",
      "loss: -425.7574462890625\n",
      "loss: -437.9622497558594\n",
      "loss: -344.30096435546875\n",
      "loss: -312.4590759277344\n",
      "loss: -498.6089782714844\n",
      "loss: -487.7690734863281\n",
      "loss: -396.63885498046875\n",
      "loss: -886.9979248046875\n",
      "loss: -450.6711120605469\n",
      "loss: -532.0714111328125\n",
      "loss: -452.69171142578125\n",
      "loss: -440.55572509765625\n",
      "loss: -765.5158081054688\n",
      "loss: -529.7575073242188\n",
      "loss: -452.099853515625\n",
      "loss: -410.4184265136719\n",
      "loss: -585.2325439453125\n",
      "loss: -606.7103881835938\n",
      "loss: -491.24761962890625\n",
      "loss: -863.3179931640625\n",
      "loss: -531.2050170898438\n",
      "loss: -329.1337890625\n",
      "loss: -764.3883056640625\n",
      "loss: -630.5890502929688\n",
      "loss: -379.3152770996094\n",
      "loss: -590.0675659179688\n",
      "loss: -565.5748901367188\n",
      "loss: -269.75738525390625\n",
      "loss: -569.3587036132812\n",
      "loss: -368.16644287109375\n",
      "loss: -441.1192321777344\n",
      "loss: -462.5782165527344\n",
      "loss: -664.9736328125\n",
      "\n",
      "-------------Round number: 35-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -437.82\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -373.8139343261719\n",
      "loss: -351.8341979980469\n",
      "loss: -274.2584533691406\n",
      "loss: -655.0187377929688\n",
      "loss: -452.7387390136719\n",
      "loss: -330.28887939453125\n",
      "loss: -590.0419921875\n",
      "loss: -431.77227783203125\n",
      "loss: -354.97552490234375\n",
      "loss: -565.6408081054688\n",
      "loss: -379.4239501953125\n",
      "loss: -489.1731872558594\n",
      "loss: -590.1131591796875\n",
      "loss: -630.62548828125\n",
      "loss: -425.7792663574219\n",
      "loss: -339.466552734375\n",
      "loss: -351.16192626953125\n",
      "loss: -886.9247436523438\n",
      "loss: -884.8253784179688\n",
      "loss: -315.33453369140625\n",
      "loss: -659.2034301757812\n",
      "loss: -530.1512451171875\n",
      "loss: -406.80841064453125\n",
      "loss: -450.7256774902344\n",
      "loss: -438.0058898925781\n",
      "loss: -529.7999267578125\n",
      "loss: -502.7416687011719\n",
      "loss: -377.24249267578125\n",
      "loss: -870.4447631835938\n",
      "loss: -441.16070556640625\n",
      "loss: -462.6170959472656\n",
      "loss: -387.2128601074219\n",
      "loss: -408.9403381347656\n",
      "loss: -250.94970703125\n",
      "loss: -332.5796203613281\n",
      "loss: -479.0484313964844\n",
      "loss: -621.789794921875\n",
      "loss: -344.3202209472656\n",
      "loss: -531.2367553710938\n",
      "loss: -269.8199462890625\n",
      "loss: -765.5547485351562\n",
      "loss: -470.2989807128906\n",
      "loss: -586.0555419921875\n",
      "loss: -440.5968017578125\n",
      "loss: -764.4251708984375\n",
      "loss: -368.1959228515625\n",
      "loss: -329.1852722167969\n",
      "loss: -665.0054931640625\n",
      "loss: -569.567138671875\n",
      "loss: -695.827392578125\n",
      "loss: -887.02490234375\n",
      "loss: -532.1043090820312\n",
      "\n",
      "-------------Round number: 36-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -435.52\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -425.7995300292969\n",
      "loss: -387.2678527832031\n",
      "loss: -659.2389526367188\n",
      "loss: -630.6597900390625\n",
      "loss: -453.1448974609375\n",
      "loss: -462.1242370605469\n",
      "loss: -874.173583984375\n",
      "loss: -590.0823364257812\n",
      "loss: -462.3942565917969\n",
      "loss: -322.51171875\n",
      "loss: -687.634765625\n",
      "loss: -532.1349487304688\n",
      "loss: -337.26397705078125\n",
      "loss: -556.7260131835938\n",
      "loss: -764.4607543945312\n",
      "loss: -569.763916015625\n",
      "loss: -530.189453125\n",
      "loss: -887.05029296875\n",
      "loss: -886.9546508789062\n",
      "loss: -450.7762145996094\n",
      "loss: -462.6536865234375\n",
      "loss: -315.3626403808594\n",
      "loss: -368.2236022949219\n",
      "loss: -884.8946533203125\n",
      "loss: -441.1993103027344\n",
      "loss: -470.44317626953125\n",
      "loss: -838.04833984375\n",
      "loss: -344.33819580078125\n",
      "loss: -695.8532104492188\n",
      "loss: -665.0352172851562\n",
      "loss: -590.1561279296875\n",
      "loss: -531.2662963867188\n",
      "loss: -250.98721313476562\n",
      "loss: -373.8803405761719\n",
      "loss: -379.523193359375\n",
      "loss: -330.3349304199219\n",
      "loss: -351.25115966796875\n",
      "loss: -408.97845458984375\n",
      "loss: -440.6349182128906\n",
      "loss: -226.6810760498047\n",
      "loss: -505.51824951171875\n",
      "loss: -438.0458679199219\n",
      "loss: -339.5570068359375\n",
      "loss: -329.23272705078125\n",
      "loss: -269.8773193359375\n",
      "loss: -406.9334716796875\n",
      "loss: -452.7820129394531\n",
      "loss: -351.8869323730469\n",
      "loss: -765.591552734375\n",
      "loss: -565.70263671875\n",
      "loss: -529.8397827148438\n",
      "loss: -489.21295166015625\n",
      "\n",
      "-------------Round number: 37-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -436.98\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.77%\n",
      "Benign Std Test MRR: 35.12%\n",
      "loss: -884.9598999023438\n",
      "loss: -569.9495849609375\n",
      "loss: -376.67218017578125\n",
      "loss: -489.5707092285156\n",
      "loss: -442.5826416015625\n",
      "loss: -407.04803466796875\n",
      "loss: -695.8775024414062\n",
      "loss: -462.6880187988281\n",
      "loss: -315.3886413574219\n",
      "loss: -452.82208251953125\n",
      "loss: -251.02175903320312\n",
      "loss: -530.2255249023438\n",
      "loss: -630.6925659179688\n",
      "loss: -450.8231506347656\n",
      "loss: -344.3550109863281\n",
      "loss: -590.1201171875\n",
      "loss: -373.9420471191406\n",
      "loss: -590.1964721679688\n",
      "loss: -440.6705627441406\n",
      "loss: -441.23516845703125\n",
      "loss: -269.9302062988281\n",
      "loss: -384.4679260253906\n",
      "loss: -417.05157470703125\n",
      "loss: -447.7362976074219\n",
      "loss: -377.85595703125\n",
      "loss: -868.7814331054688\n",
      "loss: -887.07421875\n",
      "loss: -438.0828552246094\n",
      "loss: -565.760986328125\n",
      "loss: -529.8770751953125\n",
      "loss: -387.31964111328125\n",
      "loss: -426.6974792480469\n",
      "loss: -700.1713256835938\n",
      "loss: -532.1629028320312\n",
      "loss: -368.24932861328125\n",
      "loss: -765.6265258789062\n",
      "loss: -425.81854248046875\n",
      "loss: -764.4950561523438\n",
      "loss: -330.3777160644531\n",
      "loss: -339.6400451660156\n",
      "loss: -379.61468505859375\n",
      "loss: -351.3332214355469\n",
      "loss: -409.01361083984375\n",
      "loss: -235.2892303466797\n",
      "loss: -652.37646484375\n",
      "loss: -329.2764892578125\n",
      "loss: -665.0632934570312\n",
      "loss: -489.2502746582031\n",
      "loss: -659.2719116210938\n",
      "loss: -351.9363098144531\n",
      "loss: -531.294189453125\n",
      "loss: -886.98291015625\n",
      "\n",
      "-------------Round number: 38-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.83\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.69%\n",
      "Benign Std Test MRR: 35.16%\n",
      "loss: -425.8362731933594\n",
      "loss: -590.2344970703125\n",
      "loss: -344.37054443359375\n",
      "loss: -438.1170959472656\n",
      "loss: -590.1558227539062\n",
      "loss: -379.6990661621094\n",
      "loss: -887.0968017578125\n",
      "loss: -315.4129638671875\n",
      "loss: -418.3985290527344\n",
      "loss: -346.94195556640625\n",
      "loss: -452.8594665527344\n",
      "loss: -351.9827575683594\n",
      "loss: -565.8159790039062\n",
      "loss: -887.0096435546875\n",
      "loss: -462.72052001953125\n",
      "loss: -489.28521728515625\n",
      "loss: -440.7039489746094\n",
      "loss: -339.7169494628906\n",
      "loss: -330.41748046875\n",
      "loss: -407.1535339355469\n",
      "loss: -374.0001220703125\n",
      "loss: -269.9791564941406\n",
      "loss: -665.0897216796875\n",
      "loss: -490.6568603515625\n",
      "loss: -429.5941467285156\n",
      "loss: -358.3216247558594\n",
      "loss: -531.320556640625\n",
      "loss: -217.99696350097656\n",
      "loss: -579.5901489257812\n",
      "loss: -695.9003295898438\n",
      "loss: -765.6597900390625\n",
      "loss: -529.9124145507812\n",
      "loss: -251.05345153808594\n",
      "loss: -329.31695556640625\n",
      "loss: -351.40899658203125\n",
      "loss: -405.11358642578125\n",
      "loss: -470.2186279296875\n",
      "loss: -863.1369018554688\n",
      "loss: -450.8671569824219\n",
      "loss: -532.188720703125\n",
      "loss: -659.3026123046875\n",
      "loss: -441.2687072753906\n",
      "loss: -570.1261596679688\n",
      "loss: -387.3684387207031\n",
      "loss: -368.2736511230469\n",
      "loss: -630.7234497070312\n",
      "loss: -764.5277099609375\n",
      "loss: -885.0216674804688\n",
      "loss: -530.2593994140625\n",
      "loss: -409.0463562011719\n",
      "loss: -382.4299011230469\n",
      "loss: -753.099365234375\n",
      "\n",
      "-------------Round number: 39-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -437.30\n",
      "Benign Averaged Test Recall: 51.46%\n",
      "Benign Std Test Recall: 45.58%\n",
      "Benign Averaged Test MRR: 29.84%\n",
      "Benign Std Test MRR: 34.90%\n",
      "loss: -251.08248901367188\n",
      "loss: -441.3000183105469\n",
      "loss: -570.2935791015625\n",
      "loss: -330.4544982910156\n",
      "loss: -378.0031433105469\n",
      "loss: -461.859375\n",
      "loss: -554.8741455078125\n",
      "loss: -379.77740478515625\n",
      "loss: -270.02459716796875\n",
      "loss: -764.5593872070312\n",
      "loss: -409.07672119140625\n",
      "loss: -352.0265808105469\n",
      "loss: -414.6226501464844\n",
      "loss: -569.37158203125\n",
      "loss: -418.75848388671875\n",
      "loss: -470.9176025390625\n",
      "loss: -565.8680419921875\n",
      "loss: -630.752685546875\n",
      "loss: -590.189453125\n",
      "loss: -885.0799560546875\n",
      "loss: -532.212646484375\n",
      "loss: -276.9193115234375\n",
      "loss: -607.2711791992188\n",
      "loss: -351.47943115234375\n",
      "loss: -315.4355163574219\n",
      "loss: -665.1146240234375\n",
      "loss: -387.41455078125\n",
      "loss: -489.3179931640625\n",
      "loss: -374.054443359375\n",
      "loss: -887.1181640625\n",
      "loss: -590.2705078125\n",
      "loss: -452.8940124511719\n",
      "loss: -659.3314819335938\n",
      "loss: -450.9081115722656\n",
      "loss: -344.38507080078125\n",
      "loss: -462.7511291503906\n",
      "loss: -368.29620361328125\n",
      "loss: -529.9456176757812\n",
      "loss: -339.7877197265625\n",
      "loss: -407.25079345703125\n",
      "loss: -329.3544921875\n",
      "loss: -530.2913818359375\n",
      "loss: -765.6914672851562\n",
      "loss: -531.3453979492188\n",
      "loss: -440.73516845703125\n",
      "loss: -425.85296630859375\n",
      "loss: -695.9216918945312\n",
      "loss: -492.43878173828125\n",
      "loss: -363.0801086425781\n",
      "loss: -607.177490234375\n",
      "loss: -438.14874267578125\n",
      "loss: -887.034912109375\n",
      "\n",
      "-------------Round number: 40-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -436.62\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.64%\n",
      "Benign Std Test MRR: 35.19%\n",
      "loss: -659.3582153320312\n",
      "loss: -570.4532470703125\n",
      "loss: -315.45654296875\n",
      "loss: -530.3212890625\n",
      "loss: -531.36865234375\n",
      "loss: -477.0998229980469\n",
      "loss: -479.1757507324219\n",
      "loss: -871.4097900390625\n",
      "loss: -887.1383056640625\n",
      "loss: -387.4577941894531\n",
      "loss: -764.5897827148438\n",
      "loss: -765.7214965820312\n",
      "loss: -489.34857177734375\n",
      "loss: -274.54931640625\n",
      "loss: -656.8902587890625\n",
      "loss: -352.0676574707031\n",
      "loss: -409.1048889160156\n",
      "loss: -885.1351318359375\n",
      "loss: -400.8870544433594\n",
      "loss: -395.6646423339844\n",
      "loss: -379.8499450683594\n",
      "loss: -452.926025390625\n",
      "loss: -339.8534240722656\n",
      "loss: -630.7806396484375\n",
      "loss: -450.9463195800781\n",
      "loss: -565.9173583984375\n",
      "loss: -695.9415893554688\n",
      "loss: -351.5447082519531\n",
      "loss: -329.38934326171875\n",
      "loss: -426.24151611328125\n",
      "loss: -703.04736328125\n",
      "loss: -330.4888610839844\n",
      "loss: -451.45806884765625\n",
      "loss: -401.82525634765625\n",
      "loss: -668.8484497070312\n",
      "loss: -529.976806640625\n",
      "loss: -590.3043212890625\n",
      "loss: -368.3175048828125\n",
      "loss: -590.2210083007812\n",
      "loss: -441.328857421875\n",
      "loss: -425.868408203125\n",
      "loss: -251.10910034179688\n",
      "loss: -532.234375\n",
      "loss: -344.3985290527344\n",
      "loss: -438.17803955078125\n",
      "loss: -887.0587768554688\n",
      "loss: -665.1380615234375\n",
      "loss: -270.0664367675781\n",
      "loss: -374.1054992675781\n",
      "loss: -407.34075927734375\n",
      "loss: -440.7643127441406\n",
      "loss: -462.78009033203125\n",
      "\n",
      "-------------Round number: 41-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -431.10\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 29.64%\n",
      "Benign Std Test MRR: 35.19%\n",
      "loss: -379.917724609375\n",
      "loss: -425.8828125\n",
      "loss: -251.13339233398438\n",
      "loss: -630.8072509765625\n",
      "loss: -665.1602172851562\n",
      "loss: -469.8157958984375\n",
      "loss: -469.8110046386719\n",
      "loss: -658.6722412109375\n",
      "loss: -887.1575927734375\n",
      "loss: -407.4239501953125\n",
      "loss: -530.349853515625\n",
      "loss: -438.20477294921875\n",
      "loss: -315.4760437011719\n",
      "loss: -274.4538879394531\n",
      "loss: -658.79443359375\n",
      "loss: -885.1874389648438\n",
      "loss: -489.3773498535156\n",
      "loss: -765.7501220703125\n",
      "loss: -450.705810546875\n",
      "loss: -490.2345275878906\n",
      "loss: -530.006103515625\n",
      "loss: -531.390625\n",
      "loss: -270.1054992675781\n",
      "loss: -330.5210876464844\n",
      "loss: -659.3833618164062\n",
      "loss: -532.2544555664062\n",
      "loss: -764.619140625\n",
      "loss: -437.2372131347656\n",
      "loss: -766.2211303710938\n",
      "loss: -374.1533508300781\n",
      "loss: -352.1063232421875\n",
      "loss: -441.3558044433594\n",
      "loss: -590.2507934570312\n",
      "loss: -590.3364868164062\n",
      "loss: -468.5721130371094\n",
      "loss: -393.1891784667969\n",
      "loss: -854.5841674804688\n",
      "loss: -570.6054077148438\n",
      "loss: -887.0814208984375\n",
      "loss: -462.80731201171875\n",
      "loss: -344.41119384765625\n",
      "loss: -368.33734130859375\n",
      "loss: -329.4216613769531\n",
      "loss: -452.9557800292969\n",
      "loss: -409.1308288574219\n",
      "loss: -695.9602661132812\n",
      "loss: -339.9140319824219\n",
      "loss: -387.4989318847656\n",
      "loss: -450.9819641113281\n",
      "loss: -440.7916259765625\n",
      "loss: -351.6055603027344\n",
      "loss: -565.964111328125\n",
      "\n",
      "-------------Round number: 42-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -443.63\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -469.8227233886719\n",
      "loss: -877.8211669921875\n",
      "loss: -530.0340576171875\n",
      "loss: -630.8328247070312\n",
      "loss: -452.983642578125\n",
      "loss: -659.4068603515625\n",
      "loss: -765.7775268554688\n",
      "loss: -425.896484375\n",
      "loss: -887.1029052734375\n",
      "loss: -409.1553039550781\n",
      "loss: -531.4115600585938\n",
      "loss: -330.55126953125\n",
      "loss: -407.50152587890625\n",
      "loss: -462.8333435058594\n",
      "loss: -451.0155334472656\n",
      "loss: -387.53814697265625\n",
      "loss: -590.2789916992188\n",
      "loss: -590.3668823242188\n",
      "loss: -440.8175354003906\n",
      "loss: -344.42315673828125\n",
      "loss: -379.9813232421875\n",
      "loss: -570.7516479492188\n",
      "loss: -270.1419372558594\n",
      "loss: -507.95245361328125\n",
      "loss: -416.5307312011719\n",
      "loss: -879.0274658203125\n",
      "loss: -244.0023193359375\n",
      "loss: -543.3710327148438\n",
      "loss: -887.17578125\n",
      "loss: -352.14312744140625\n",
      "loss: -566.0087280273438\n",
      "loss: -885.2371826171875\n",
      "loss: -381.7209167480469\n",
      "loss: -442.3363342285156\n",
      "loss: -695.9778442382812\n",
      "loss: -665.1812133789062\n",
      "loss: -764.6473999023438\n",
      "loss: -374.1988220214844\n",
      "loss: -352.6208190917969\n",
      "loss: -603.942138671875\n",
      "loss: -691.1363525390625\n",
      "loss: -530.3768310546875\n",
      "loss: -329.4520263671875\n",
      "loss: -441.3810729980469\n",
      "loss: -351.66241455078125\n",
      "loss: -315.4945068359375\n",
      "loss: -368.356201171875\n",
      "loss: -489.4045104980469\n",
      "loss: -251.15602111816406\n",
      "loss: -532.2730712890625\n",
      "loss: -438.23004150390625\n",
      "loss: -339.970458984375\n",
      "\n",
      "-------------Round number: 43-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -437.52\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -440.8419189453125\n",
      "loss: -270.1760559082031\n",
      "loss: -329.4804382324219\n",
      "loss: -374.2416687011719\n",
      "loss: -665.2010498046875\n",
      "loss: -368.373779296875\n",
      "loss: -330.579833984375\n",
      "loss: -398.55877685546875\n",
      "loss: -595.5632934570312\n",
      "loss: -489.4302978515625\n",
      "loss: -453.0093994140625\n",
      "loss: -887.1932373046875\n",
      "loss: -387.5754089355469\n",
      "loss: -407.5741882324219\n",
      "loss: -765.8035278320312\n",
      "loss: -531.4313354492188\n",
      "loss: -532.2904052734375\n",
      "loss: -421.22210693359375\n",
      "loss: -434.0780029296875\n",
      "loss: -881.4724731445312\n",
      "loss: -530.4022827148438\n",
      "loss: -451.04718017578125\n",
      "loss: -590.3056640625\n",
      "loss: -400.80438232421875\n",
      "loss: -473.389892578125\n",
      "loss: -735.3156127929688\n",
      "loss: -695.9946899414062\n",
      "loss: -630.8575439453125\n",
      "loss: -462.85791015625\n",
      "loss: -344.43426513671875\n",
      "loss: -590.3958740234375\n",
      "loss: -315.5118103027344\n",
      "loss: -409.1778564453125\n",
      "loss: -251.17689514160156\n",
      "loss: -885.284423828125\n",
      "loss: -265.5676574707031\n",
      "loss: -547.9918212890625\n",
      "loss: -887.123291015625\n",
      "loss: -441.40484619140625\n",
      "loss: -352.1780700683594\n",
      "loss: -425.9092102050781\n",
      "loss: -530.0604858398438\n",
      "loss: -566.0513916015625\n",
      "loss: -340.0232238769531\n",
      "loss: -351.7156982421875\n",
      "loss: -659.428955078125\n",
      "loss: -570.8915405273438\n",
      "loss: -764.6749267578125\n",
      "loss: -380.04132080078125\n",
      "loss: -438.25347900390625\n",
      "loss: -414.41949462890625\n",
      "loss: -569.3759155273438\n",
      "\n",
      "-------------Round number: 44-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -436.66\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -885.32958984375\n",
      "loss: -315.5280456542969\n",
      "loss: -251.19610595703125\n",
      "loss: -441.42706298828125\n",
      "loss: -407.6418151855469\n",
      "loss: -400.94927978515625\n",
      "loss: -466.2296447753906\n",
      "loss: -402.26708984375\n",
      "loss: -531.4501953125\n",
      "loss: -887.2099609375\n",
      "loss: -765.8287963867188\n",
      "loss: -887.1429443359375\n",
      "loss: -696.0101928710938\n",
      "loss: -566.09228515625\n",
      "loss: -387.6109313964844\n",
      "loss: -530.0858764648438\n",
      "loss: -451.0770568847656\n",
      "loss: -412.6695251464844\n",
      "loss: -362.46026611328125\n",
      "loss: -440.8650207519531\n",
      "loss: -340.072265625\n",
      "loss: -453.0336608886719\n",
      "loss: -590.3312377929688\n",
      "loss: -344.4447937011719\n",
      "loss: -532.3062744140625\n",
      "loss: -330.6065979003906\n",
      "loss: -448.5736999511719\n",
      "loss: -521.33642578125\n",
      "loss: -270.2080078125\n",
      "loss: -425.9212341308594\n",
      "loss: -463.1253967285156\n",
      "loss: -392.3595886230469\n",
      "loss: -816.5977783203125\n",
      "loss: -329.50714111328125\n",
      "loss: -530.427001953125\n",
      "loss: -462.8816223144531\n",
      "loss: -352.2112121582031\n",
      "loss: -351.7655029296875\n",
      "loss: -489.4547424316406\n",
      "loss: -374.2824401855469\n",
      "loss: -571.0267944335938\n",
      "loss: -368.39068603515625\n",
      "loss: -380.0980224609375\n",
      "loss: -659.44970703125\n",
      "loss: -409.1993408203125\n",
      "loss: -665.2199096679688\n",
      "loss: -630.8814697265625\n",
      "loss: -764.7015991210938\n",
      "loss: -590.4234619140625\n",
      "loss: -438.2755432128906\n",
      "loss: -234.96505737304688\n",
      "loss: -654.8446044921875\n",
      "\n",
      "-------------Round number: 45-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -429.82\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -315.5432434082031\n",
      "loss: -489.4778747558594\n",
      "loss: -441.4481506347656\n",
      "loss: -425.9324035644531\n",
      "loss: -765.8530883789062\n",
      "loss: -330.6318359375\n",
      "loss: -415.56671142578125\n",
      "loss: -785.6629638671875\n",
      "loss: -340.1179504394531\n",
      "loss: -374.3208923339844\n",
      "loss: -530.1099853515625\n",
      "loss: -887.2258911132812\n",
      "loss: -566.1315307617188\n",
      "loss: -532.3211059570312\n",
      "loss: -440.88677978515625\n",
      "loss: -449.1094970703125\n",
      "loss: -453.9104309082031\n",
      "loss: -832.9423828125\n",
      "loss: -630.9044189453125\n",
      "loss: -409.2193908691406\n",
      "loss: -887.1616821289062\n",
      "loss: -368.40655517578125\n",
      "loss: -344.4547119140625\n",
      "loss: -438.29620361328125\n",
      "loss: -590.44970703125\n",
      "loss: -571.1569213867188\n",
      "loss: -380.1517333984375\n",
      "loss: -530.4506225585938\n",
      "loss: -453.05609130859375\n",
      "loss: -885.3727416992188\n",
      "loss: -387.64501953125\n",
      "loss: -462.9042663574219\n",
      "loss: -270.2381896972656\n",
      "loss: -431.7023620605469\n",
      "loss: -355.4331970214844\n",
      "loss: -269.6985168457031\n",
      "loss: -877.96630859375\n",
      "loss: -451.10504150390625\n",
      "loss: -764.7275390625\n",
      "loss: -590.3557739257812\n",
      "loss: -351.8125915527344\n",
      "loss: -696.0250854492188\n",
      "loss: -373.26220703125\n",
      "loss: -485.0484924316406\n",
      "loss: -718.977294921875\n",
      "loss: -531.4680786132812\n",
      "loss: -329.5323181152344\n",
      "loss: -407.70477294921875\n",
      "loss: -352.24273681640625\n",
      "loss: -665.2379150390625\n",
      "loss: -659.4694213867188\n",
      "loss: -251.21380615234375\n",
      "\n",
      "-------------Round number: 46-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -442.56\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -294.21356201171875\n",
      "loss: -477.50335693359375\n",
      "loss: -770.0987548828125\n",
      "loss: -409.2382507324219\n",
      "loss: -270.26641845703125\n",
      "loss: -764.75244140625\n",
      "loss: -380.0135498046875\n",
      "loss: -502.33367919921875\n",
      "loss: -407.7643127441406\n",
      "loss: -885.4140625\n",
      "loss: -630.9265747070312\n",
      "loss: -571.2828979492188\n",
      "loss: -887.179931640625\n",
      "loss: -590.4747924804688\n",
      "loss: -438.3155822753906\n",
      "loss: -352.2726745605469\n",
      "loss: -404.4498291015625\n",
      "loss: -874.2649536132812\n",
      "loss: -226.2634735107422\n",
      "loss: -508.27947998046875\n",
      "loss: -696.0390014648438\n",
      "loss: -590.3790893554688\n",
      "loss: -315.557373046875\n",
      "loss: -368.421875\n",
      "loss: -530.1331787109375\n",
      "loss: -441.4677734375\n",
      "loss: -765.87646484375\n",
      "loss: -531.485107421875\n",
      "loss: -453.07708740234375\n",
      "loss: -380.2027587890625\n",
      "loss: -344.4640197753906\n",
      "loss: -489.4996643066406\n",
      "loss: -374.3578796386719\n",
      "loss: -340.16046142578125\n",
      "loss: -665.2550048828125\n",
      "loss: -351.8568420410156\n",
      "loss: -887.2411499023438\n",
      "loss: -532.3345336914062\n",
      "loss: -530.4732055664062\n",
      "loss: -451.13177490234375\n",
      "loss: -330.6557312011719\n",
      "loss: -419.74981689453125\n",
      "loss: -406.5852355957031\n",
      "loss: -868.8607177734375\n",
      "loss: -659.4879760742188\n",
      "loss: -425.94293212890625\n",
      "loss: -387.6776123046875\n",
      "loss: -566.1691284179688\n",
      "loss: -462.9259338378906\n",
      "loss: -440.9073791503906\n",
      "loss: -329.5559997558594\n",
      "loss: -251.23023986816406\n",
      "\n",
      "-------------Round number: 47-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -434.00\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -887.1973876953125\n",
      "loss: -590.498779296875\n",
      "loss: -352.3013000488281\n",
      "loss: -635.9634399414062\n",
      "loss: -535.5922241210938\n",
      "loss: -880.26220703125\n",
      "loss: -659.5057983398438\n",
      "loss: -330.6780700683594\n",
      "loss: -630.9484252929688\n",
      "loss: -315.57049560546875\n",
      "loss: -329.5783386230469\n",
      "loss: -696.0521240234375\n",
      "loss: -441.48614501953125\n",
      "loss: -270.2930908203125\n",
      "loss: -665.2714233398438\n",
      "loss: -531.5012817382812\n",
      "loss: -428.1661682128906\n",
      "loss: -439.6682434082031\n",
      "loss: -491.8997497558594\n",
      "loss: -374.3925476074219\n",
      "loss: -765.8987426757812\n",
      "loss: -265.3373107910156\n",
      "loss: -550.3309326171875\n",
      "loss: -438.33367919921875\n",
      "loss: -407.8200988769531\n",
      "loss: -440.9269104003906\n",
      "loss: -530.1549682617188\n",
      "loss: -590.4011840820312\n",
      "loss: -409.2558288574219\n",
      "loss: -387.70880126953125\n",
      "loss: -425.9528503417969\n",
      "loss: -324.46417236328125\n",
      "loss: -484.23699951171875\n",
      "loss: -489.5203552246094\n",
      "loss: -453.0968933105469\n",
      "loss: -464.19732666015625\n",
      "loss: -537.7637939453125\n",
      "loss: -380.2511901855469\n",
      "loss: -887.2557373046875\n",
      "loss: -885.4534912109375\n",
      "loss: -462.94647216796875\n",
      "loss: -530.4947509765625\n",
      "loss: -368.4361267089844\n",
      "loss: -566.2052612304688\n",
      "loss: -344.47296142578125\n",
      "loss: -340.20025634765625\n",
      "loss: -532.3472290039062\n",
      "loss: -764.776611328125\n",
      "loss: -251.2454833984375\n",
      "loss: -571.4046630859375\n",
      "loss: -351.898681640625\n",
      "loss: -451.1570739746094\n",
      "\n",
      "-------------Round number: 48-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -440.30\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "loss: -257.08343505859375\n",
      "loss: -736.489013671875\n",
      "loss: -368.45013427734375\n",
      "loss: -374.4264221191406\n",
      "loss: -489.5401611328125\n",
      "loss: -251.25953674316406\n",
      "loss: -571.523193359375\n",
      "loss: -441.5033264160156\n",
      "loss: -438.3507995605469\n",
      "loss: -887.2697143554688\n",
      "loss: -270.3183288574219\n",
      "loss: -885.4910888671875\n",
      "loss: -329.59967041015625\n",
      "loss: -451.18121337890625\n",
      "loss: -387.73858642578125\n",
      "loss: -531.5164184570312\n",
      "loss: -696.0643920898438\n",
      "loss: -590.4222412109375\n",
      "loss: -665.2868041992188\n",
      "loss: -380.29754638671875\n",
      "loss: -590.521728515625\n",
      "loss: -530.51513671875\n",
      "loss: -409.2724304199219\n",
      "loss: -453.1152648925781\n",
      "loss: -566.239990234375\n",
      "loss: -449.4878845214844\n",
      "loss: -514.9789428710938\n",
      "loss: -532.358642578125\n",
      "loss: -462.96630859375\n",
      "loss: -344.4813537597656\n",
      "loss: -405.72998046875\n",
      "loss: -449.7820129394531\n",
      "loss: -829.0885009765625\n",
      "loss: -351.93817138671875\n",
      "loss: -659.5222778320312\n",
      "loss: -887.214111328125\n",
      "loss: -764.8004150390625\n",
      "loss: -368.7729797363281\n",
      "loss: -475.9286804199219\n",
      "loss: -630.9691772460938\n",
      "loss: -340.23760986328125\n",
      "loss: -381.58087158203125\n",
      "loss: -453.6031494140625\n",
      "loss: -512.5458984375\n",
      "loss: -765.9204711914062\n",
      "loss: -440.94537353515625\n",
      "loss: -315.5828857421875\n",
      "loss: -352.32830810546875\n",
      "loss: -530.1759033203125\n",
      "loss: -330.699462890625\n",
      "loss: -425.9620361328125\n",
      "loss: -407.87261962890625\n",
      "\n",
      "-------------Round number: 49-------------\n",
      "\n",
      "Evaluate personalized models for training clients.\n",
      "Benign Averaged Train Loss: -439.05\n",
      "Benign Averaged Test Recall: 50.49%\n",
      "Benign Std Test Recall: 45.74%\n",
      "Benign Averaged Test MRR: 30.13%\n",
      "Benign Std Test MRR: 36.50%\n",
      "\n",
      "Final Average Personalized Recall: [1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.38461538461538464, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
      "\n",
      "Average Recall for All Users: 0.5213776963776964\n",
      "\n",
      "Final Average Personalized Recall: [0.41666666666666663, 0.1111111111111111, 0.75, 0.06666666666666667, 0.5, 0.3333333333333333, 0.25, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.1111111111111111, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.23076923076923078, 0.0, 1.0, 0.07619047619047618, 0.5, 0.2, 0.0, 0.75, 0.32499999999999996, 1.0, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.5]\n",
      "\n",
      "Average MRR for All Users: 0.3341670058336725\n",
      "\n",
      "Time cost: 3.6min.\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "print(\"Creating server and clients ...\")\n",
    "start = time.time()\n",
    "# model = HARCNN(in_channels=3, num_classes=num_classes, dim=3008).to(device)\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers).to(DEVICE)\n",
    "\n",
    "print(model)\n",
    "\n",
    "server = FedCHAR(model)\n",
    "server.train()\n",
    "# server.save_results()\n",
    "print(f\"\\nTime cost: {round((time.time()-start)/60, 2)}min.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
