{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(f'./train_data_diginetica.npy', allow_pickle=True)\n",
    "valid_data = np.load(f'./test_data_diginetica.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'diginetica'\n",
    "attack_type = 'B' # A1: label_poison, A2: gaussian_attack, A3: scaling_attack, A4: reverse_attack\n",
    "local_learning_rate = 0.01\n",
    "local_steps= 1\n",
    "data_path= f\".\"\n",
    "learning_rate_decay_gamma= 0.99\n",
    "learning_rate_decay= False\n",
    "future_test= False\n",
    "mu= 1\n",
    "global_rounds= 100\n",
    "num_clients= len(valid_data)\n",
    "join_ratio= 1.0\n",
    "attack_ratio= 0.0\n",
    "algorithm= \"FedCHAR\"\n",
    "future_ratio= 0.0\n",
    "finetune_rounds= 0\n",
    "eval_gap= 1\n",
    "detailed_info= False\n",
    "partition= \"nature\"\n",
    "initial_rounds= 10\n",
    "n_clusters= 3\n",
    "metric= 'cosine'\n",
    "linkage= 'complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter for recommender system\n",
    "input_size = 889\n",
    "hidden_size = 100\n",
    "output_size = input_size\n",
    "batch_size = 32\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all train data as one dataframe\n",
    "train_combined = np.concatenate(train_data)\n",
    "#convert to dataframe\n",
    "train_combined = pd.DataFrame(train_combined)\n",
    "train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique item IDs from the combined DataFrame\n",
    "all_unique_items = train_combined[2].unique()\n",
    "\n",
    "# Step 2: Create a universal item index mapping\n",
    "universal_item_map = pd.DataFrame({\n",
    "    'item_idx': np.arange(len(all_unique_items)),\n",
    "    'itemId': all_unique_items\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUDataset(Dataset):\n",
    "    def __init__(self, data, itemmap, session_key='sessionId', item_key='itemId', time_key='time'):\n",
    "        self.data = data\n",
    "        self.itemmap = itemmap\n",
    "        self.session_key = session_key\n",
    "        self.item_key = item_key\n",
    "        self.time_key = time_key\n",
    "\n",
    "        # Map items to indices\n",
    "        self.data = pd.merge(self.data, self.itemmap, on=self.item_key, how='inner')\n",
    "\n",
    "        # Sort by session and time\n",
    "        self.data.sort_values([self.session_key, self.time_key], inplace=True)\n",
    "\n",
    "        # Group data by session and collect item indices\n",
    "        self.sessions = self.data.groupby(self.session_key)['item_idx'].apply(list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        session_items = self.sessions.iloc[index]\n",
    "        sequence = torch.tensor(session_items[:-1], dtype=torch.long)\n",
    "        target = torch.tensor(session_items[1:], dtype=torch.long)\n",
    "        return sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=-1)\n",
    "    return sequences_padded, targets_padded\n",
    "\n",
    "def get_loader(data, itemmap, batch_size=32, shuffle=True):\n",
    "    dataset = GRUDataset(data, itemmap=itemmap)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # test get_loader\n",
    "# train_loader = get_loader(train_data[0], universal_item_map, batch_size=batch_size, shuffle=True)\n",
    "# x, y = next(iter(train_loader))\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbedGradientDescent(Optimizer):\n",
    "  def __init__(self, params, lr=0.01, mu=0.0):\n",
    "    default = dict(lr=lr, mu=mu)\n",
    "    super().__init__(params, default)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def step(self, global_params, device):\n",
    "    for group in self.param_groups:\n",
    "      for p, g in zip(group['params'], global_params):\n",
    "        g = g.to(device)\n",
    "        d_p = p.grad.data + group['mu'] * (p.data - g.data)\n",
    "        p.data.add_(d_p, alpha=-group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initialize the GRU model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of expected features in the input `x`\n",
    "            hidden_size (int): The number of features in the hidden state `h`\n",
    "            output_size (int): The size of the output layer (number of items)\n",
    "            num_layers (int, optional): Number of recurrent layers. Default: 1\n",
    "        \"\"\"\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Args:\n",
    "            x: Input data\n",
    "            hidden: Hidden state\n",
    "\n",
    "        Returns:\n",
    "            Output and new hidden state\n",
    "        \"\"\"\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # GRU\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        # Predict next item\n",
    "        output = self.fc(output[:, -1, :])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state of the GRU.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The size of the batch\n",
    "\n",
    "        Returns:\n",
    "            Initial hidden state\n",
    "        \"\"\"\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOP1MaxLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TOP1MaxLoss, self).__init__()\n",
    "\n",
    "    def forward(self, scores, targets):\n",
    "        # Initialize loss\n",
    "        loss = 0.0\n",
    "\n",
    "        # Loop over each element in the batch\n",
    "        for i in range(scores.size(0)):  # Loop over batch\n",
    "            for j in range(targets.size(1)):  # Loop over sequence\n",
    "                if targets[i, j] == -1:  # Skip padding\n",
    "                    continue\n",
    "\n",
    "                # Get the score of the target item\n",
    "                pos_score = scores[i, targets[i, j]]\n",
    "\n",
    "                # Calculate the difference with all other items\n",
    "                diff = -torch.sigmoid(pos_score - scores[i])\n",
    "\n",
    "                # Exclude the positive item from the loss\n",
    "                diff[targets[i, j]] = 0\n",
    "\n",
    "                # Add to the total loss\n",
    "                loss += torch.sum(diff)\n",
    "\n",
    "        # Average the loss\n",
    "        loss = loss / (scores.size(0) * targets.size(1))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "  \"\"\"\n",
    "  Base class for clients in federated learning.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, model, id, malicious, **kwargs):\n",
    "    self.model = copy.deepcopy(model)\n",
    "    self.dataset = dataset\n",
    "    self.device = DEVICE\n",
    "    self.id = id\n",
    "    self.malicious = malicious\n",
    "    self.attack_type = attack_type\n",
    "    self.num_classes = output_size\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = local_learning_rate\n",
    "    self.local_steps = local_steps\n",
    "    self.data_path = data_path\n",
    "    self.learning_rate_decay = learning_rate_decay\n",
    "    self.future_test = future_test\n",
    "\n",
    "\n",
    "    # check BatchNorm\n",
    "    self.has_BatchNorm = False\n",
    "    for layer in self.model.children():\n",
    "      if isinstance(layer, nn.BatchNorm2d):\n",
    "        self.has_BatchNorm = True\n",
    "        break\n",
    "\n",
    "    self.loss = TOP1MaxLoss()  # Replace with your loss function\n",
    "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate) # momentum=0.9, weight_decay=1e-4\n",
    "    self.learning_rate_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "      optimizer=self.optimizer,\n",
    "      gamma=learning_rate_decay_gamma\n",
    "    )\n",
    "\n",
    "  def load_train_data(self, batch_size=None):\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    train_data = get_loader(train_data[self.id], itemmap=universal_item_map, batch_size=batch_size)\n",
    "\n",
    "    # label poison attack\n",
    "    if self.malicious and self.attack_type == 'A1':\n",
    "      for idx in range(len(train_data)):\n",
    "        train_data[idx][1] = self.num_classes - train_data[idx][1] - 1\n",
    "    self.train_samples = len(train_data)\n",
    "    return train_data\n",
    "\n",
    "  def load_test_data(self, batch_size=None):\n",
    "    \"\"\"\n",
    "    fine-tunes the model using the loaded training data\n",
    "    \"\"\"\n",
    "    if batch_size == None:\n",
    "      batch_size = self.batch_size\n",
    "    test_data = get_loader(valid_data[self.id], itemmap=universal_item_map, batch_size=batch_size)\n",
    "    return test_data\n",
    "  \n",
    "  def set_parameters(self, model):\n",
    "    for new_param, old_param in zip(model.parameters(), self.model.parameters()):\n",
    "      old_param.data = new_param.data.clone()\n",
    "\n",
    "  def fine_tuning(self):\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.train()\n",
    "\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "      # if type(x) == type([]):\n",
    "      #   x[0] = x[0].to(self.device)\n",
    "      # else:\n",
    "      #   x = x.to(self.device)\n",
    "      x = x.to(self.device)\n",
    "      y = y.to(self.device)\n",
    "      self.optimizer.zero_grad()\n",
    "      hidden = self.model.init_hidden(x.size(0))\n",
    "      output, _ = self.model(x, hidden)\n",
    "      # output = self.model(x)\n",
    "      loss = self.loss(output, y)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "  def new_test_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's performance on test data, particularly its accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    testloaderfull = self.load_test_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    test_num = 0\n",
    "    y_prob = [] #model outputs or probabilities\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in testloaderfull:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        # output = self.model(x)\n",
    "        output, _ = self.model(x, hidden)\n",
    "\n",
    "        # Select top-k items\n",
    "        _, top_k_indices = torch.topk(output, K, dim=1)\n",
    "\n",
    "        # test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        # test_num += y.shape[0]\n",
    "\n",
    "        # Calculate recall and MRR for each batch\n",
    "        for i in range(x.size(0)):\n",
    "          for y_item in y[i]:\n",
    "            if y_item == -1:\n",
    "              continue\n",
    "            target_item_scalar = y_item.item()\n",
    "            top_k_items = top_k_indices[i].tolist()\n",
    "\n",
    "            # Calculate Recall@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              total_recall += 1\n",
    "\n",
    "            # Calculate MRR@k\n",
    "            if target_item_scalar in top_k_items:\n",
    "              rank = top_k_items.index(target_item_scalar)\n",
    "              total_mrr += 1 / (rank + 1)\n",
    "          \n",
    "          test_num += len(y[i][y[i] != -1])  # Count non-padding elements\n",
    "\n",
    "        y_prob.append(output.detach().cpu().numpy())\n",
    "        nc = self.num_classes\n",
    "        if self.num_classes == 2:\n",
    "          nc += 1\n",
    "        lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))\n",
    "        if self.num_classes == 2:\n",
    "          lb = lb[:, :2]\n",
    "        y_true.append(lb)\n",
    "\n",
    "    y_prob = np.concatenate(y_prob, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "\n",
    "    return total_recall, total_mrr, test_num\n",
    "\n",
    "  def new_train_metrics(self):\n",
    "    \"\"\"\n",
    "    evaluates the model's loss on the training data.\n",
    "    \"\"\"\n",
    "\n",
    "    trainloader = self.load_train_data()\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0.0\n",
    "    with torch.no_grad():\n",
    "      for x, y in trainloader:\n",
    "        # if type(x) == type([]):\n",
    "        #   x[0] = x[0].to(self.device)\n",
    "        # else:\n",
    "        #   x = x.to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        hidden = self.model.init_hidden(x.size(0))\n",
    "        output, _ = self.model(x, hidden)\n",
    "        # output = self.model(x)\n",
    "        # calculate losses\n",
    "        loss = self.loss(output, y)\n",
    "        train_num += y.shape[0]\n",
    "        losses += loss * y.shape[0]\n",
    "        # loss = self.loss(output, y)\n",
    "        # train_num += y.shape[0]\n",
    "        # losses += loss.item() * y.shape[0]\n",
    "\n",
    "    return losses, train_num\n",
    "\n",
    "  def test_metrics_personalized(self):\n",
    "    testloaderfull = self.load_test_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    test_acc = 0\n",
    "    test_num = 0\n",
    "    y_prob = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in testloaderfull:\n",
    "        if type(x) == type([]):\n",
    "          x[0] = x[0].to(self.device)\n",
    "        else:\n",
    "          x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        output = self.model(x)\n",
    "\n",
    "        test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()\n",
    "        test_num += y.shape[0]\n",
    "\n",
    "        y_prob.append(output.detach().cpu().numpy())\n",
    "        nc = self.num_classes\n",
    "        if self.num_classes == 2:\n",
    "          nc += 1\n",
    "        lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))\n",
    "        if self.num_classes == 2:\n",
    "          lb = lb[:, :2]\n",
    "        y_true.append(lb)\n",
    "\n",
    "    y_prob = np.concatenate(y_prob, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "    return test_acc, test_num\n",
    "\n",
    "  def train_metrics_personalized(self):\n",
    "    trainloader = self.load_train_data()\n",
    "\n",
    "    self.model.eval()\n",
    "\n",
    "    train_num = 0\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "      for x, y in trainloader:\n",
    "        if type(x) == type([]):\n",
    "          x[0] = x[0].to(self.device)\n",
    "        else:\n",
    "          x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        output = self.model(x)\n",
    "        loss = self.loss(output, y)\n",
    "        train_num += y.shape[0]\n",
    "        losses += loss.item() * y.shape[0]\n",
    "\n",
    "    return losses, train_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
